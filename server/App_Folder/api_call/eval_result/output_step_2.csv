Paper_ID,Title_En,Content_En,Categories,Authors,Pdf_url,Published,Title_Ja,Content_Ja,Content_plain,Keywords,Time
http://arxiv.org/abs/2307.09998v1,Generating Mathematical Derivations with Large Language Models,"The derivation of mathematical results in specialised fields using LargeLanguage Models (LLMs) is an emerging research direction that can help identifymodels' limitations, and potentially support mathematical discovery. In thispaper, we leverage a symbolic engine to generate derivations of equations atscale, and investigate the capabilities of LLMs when deriving goal equationsfrom premises. Specifically, we employ in-context learning for GPT andfine-tune a range of T5 models to compare the robustness and generalisation ofpre-training strategies to specialised models. Empirical results show thatfine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static andout-of-distribution test sets in terms of absolute performance. However, anin-depth analysis reveals that the fine-tuned models are more sensitive toperturbations involving unseen symbols and (to a lesser extent) changes toequation structure. In addition, we analyse 1.7K equations and over 200derivations to highlight common reasoning errors such as the inclusion ofincorrect, irrelevant, and redundant equations, along with the tendency to skipderivation steps. Finally, we explore the suitability of existing metrics forevaluating mathematical derivations finding evidence that, while they capturegeneral properties such as sensitivity to perturbations, they fail to highlightfine-grained reasoning errors and essential differences between models.Overall, this work demonstrates that training models on synthetic data canimprove their mathematical capabilities beyond larger architectures.","['Computation and Language', 'History and Overview']","['Jordan Meadows', 'Marco Valentino', 'Andre Freitas']",http://arxiv.org/pdf/2307.09998v1,2023-07-19 14:13:02+00:00,大規模言語モデルによる数学的導出の生成,大規模言語モデル(LLM)を用いた専門分野における数学的結果の導出は、モデルの限界を明らかにし、数学的発見をサポートする可能性のある新たな研究方向である。本論文では、記号エンジンを活用して大規模な方程式の導出を生成し、前提からゴール方程式を導出する際のLLMの能力を調査する。具体的には、GPTにインコンテキスト学習を採用し、様々なT5モデルのファインチューニングを行うことで、特殊なモデルに対する事前学習戦略の頑健性と一般性を比較する。実証的な結果から、ファインチューニングされたFLAN-T5-large（MathT5）は、すべての静的テストセットと分布外テストセットにおいて、絶対的な性能の点でGPTモデルを上回ることが示された。しかし、詳細な分析により、ファインチューニングされたモデルは、未見の記号を含む摂動や、方程式の構造の変化（程度は低い）に対してより敏感であることが明らかになった。さらに、1.7K方程式と200以上の派生を分析し、間違った方程式、無関係な方程式、冗長な方程式の包含、派生ステップのスキップ傾向などの一般的な推論エラーを浮き彫りにした。最後に、数学的導出を評価するための既存のメトリクスの適合性を調査し、摂動に対する感度のような一般的な特性を捉える一方で、きめ細かな推論エラーやモデル間の本質的な差異を強調することができないという証拠を発見した。,大規模な言語モデルを使って、専門的な数学の結果を見つけることは、新しい研究の方向です。この論文では、特殊なモデルの能力を調べるために、大きな方程式を作って、目標の方程式を見つける方法を調べました。実験の結果、特定のモデルは他のモデルよりも優れた性能を示しましたが、新しい記号や方程式の変化には敏感でした。また、間違った方程式や関係のない方程式などのエラーも見つかりました。最後に、既存の評価方法では、細かいエラーやモデル間の違いを正確に評価することができないことがわかりました。,"[{'Keyword': '大規模言語モデル', 'Description': '大規模言語モデルは、巨大なテキストデータセットを使用してトレーニングされた言語モデルです。'}, {'Keyword': '専門分野', 'Description': '専門分野は、特定の知識やスキルが必要な特定の領域を指します。'}, {'Keyword': '数学的結果', 'Description': '数学的結果は、数学的な計算や証明によって得られる結論や解です。'}, {'Keyword': '記号エンジン', 'Description': '記号エンジンは、数学的な記号や式を処理し、計算や解析を行うソフトウェアです。'}, {'Keyword': '方程式', 'Description': '方程式は、未知の変数を含む数学的な等式であり、解を求めるために使用されます。'}]",15.503675699234009
http://arxiv.org/abs/2307.08974v1,"Development of the ChatGPT, Generative Artificial Intelligence and Natural Large Language Models for Accountable Reporting and Use (CANGARU) Guidelines","The swift progress and ubiquitous adoption of Generative AI (GAI), GenerativePre-trained Transformers (GPTs), and large language models (LLMs) like ChatGPT,have spurred queries about their ethical application, use, and disclosure inscholarly research and scientific productions. A few publishers and journalshave recently created their own sets of rules; however, the absence of aunified approach may lead to a 'Babel Tower Effect,' potentially resulting inconfusion rather than desired standardization. In response to this, we presentthe ChatGPT, Generative Artificial Intelligence, and Natural Large LanguageModels for Accountable Reporting and Use Guidelines (CANGARU) initiative, withthe aim of fostering a cross-disciplinary global inclusive consensus on theethical use, disclosure, and proper reporting of GAI/GPT/LLM technologies inacademia. The present protocol consists of four distinct parts: a) an ongoingsystematic review of GAI/GPT/LLM applications to understand the linked ideas,findings, and reporting standards in scholarly research, and to formulateguidelines for its use and disclosure, b) a bibliometric analysis of existingauthor guidelines in journals that mention GAI/GPT/LLM, with the goal ofevaluating existing guidelines, analyzing the disparity in theirrecommendations, and identifying common rules that can be brought into theDelphi consensus process, c) a Delphi survey to establish agreement on theitems for the guidelines, ensuring principled GAI/GPT/LLM use, disclosure, andreporting in academia, and d) the subsequent development and dissemination ofthe finalized guidelines and their supplementary explanation and elaborationdocuments.","['Artificial Intelligence', 'Computers and Society']","['Giovanni E. Cacciamani', 'Michael B. Eppler', 'Conner Ganjavi', 'Asli Pekan', 'Brett Biedermann', 'Gary S. Collins', 'Inderbir S. Gill']",http://arxiv.org/pdf/2307.08974v1,2023-07-18 05:12:52+00:00,ChatGPT、Generative Artificial Intelligence and Natural Large Language Models for Accountable Reporting and Use（CANGARU）ガイドラインの開発,"Generative AI（GAI）、GenerativePre-trained Transformers（GPT）、ChatGPTのような大規模言語モデル（LLM）の急速な進歩とユビキタスな採用は、学術研究や科学的生産物における倫理的な適用、使用、開示に関する問い合わせに拍車をかけている。しかし、統一されたアプローチがないため、「バベルタワー効果」が生じ、標準化よりも混乱が生じる可能性がある。これに対して我々は、学術分野におけるGAI/GPT/LLM技術の倫理的な使用、開示、適切な報告に関する分野横断的でグローバルな包括的コンセンサスを醸成することを目的として、ChatGPT, Generative Artificial Intelligence, and Natural Large LanguageModels for Accountable Reporting and Use Guidelines (CANGARU)イニシアチブを提示する。このプロトコルは、以下の4つの部分から構成されている：a) GAI/GPT/LLMアプリケーションの継続的な体系的レビューにより、学術研究における関連するアイデア、知見、報告基準を理解し、その使用と開示に関するガイドラインを策定すること b) GAI/GPT/LLMに言及しているジャーナルにおける既存の著者ガイドラインの書誌学的分析を行い、既存のガイドラインを評価し、その推奨の格差を分析すること、c）デルファイ調査により、ガイドラインの項目に関する合意を確立し、学術界における原則的なGAI/GPT/LLMの使用、開示、報告を確保する。",ジェネレーティブAI（GAI）、ジェネレーティブプリトレーニングトランスフォーマー（GPT）、ChatGPTなどの大きな言語モデルの進歩は、研究や科学の成果物での倫理的な使用や開示についての質問を増やしています。しかし、統一されたアプローチがないため、混乱が生じる可能性があります。そこで、ChatGPT、ジェネレーティブ人工知能、そして責任ある報告と使用のための自然言語モデルのガイドライン（CANGARU）イニシアチブを提案します。このプロトコルは、以下の4つの部分で構成されています：a) 研究者が関連するアイデアや報告基準を理解し、使用と開示に関するガイドラインを作成するためのレビュー、b) 既存のガイドラインを分析し、推奨事項の差異を評価するためのジャーナルの著者ガイドラインの分析、c) デルファイ法による合意形成を通じて、学術界でのGAI/GPT/LLMの使用、開示、報告の原則を確立します。,"[{'Keyword': 'Generative AI', 'Description': '生成型人工知能'}, {'Keyword': 'GPT', 'Description': '事前学習済みトランスフォーマー'}, {'Keyword': 'ChatGPT', 'Description': 'GPTによるチャットボット'}, {'Keyword': 'LLM', 'Description': '大規模言語モデル'}, {'Keyword': 'CANGARU', 'Description': 'CANGARUは、責任ある報告と使用ガイドラインのためのChatGPT、生成型人工知能、および自然言語処理の大規模言語モデルを組み合わせたものです'}]",16.793177843093872
http://arxiv.org/abs/2307.08691v1,FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning,"Scaling Transformers to longer sequence lengths has been a major problem inthe last several years, promising to improve performance in language modelingand high-resolution image understanding, as well as to unlock new applicationsin code, audio, and video generation. The attention layer is the mainbottleneck in scaling to longer sequences, as its runtime and memory increasequadratically in the sequence length. FlashAttention exploits the asymmetricGPU memory hierarchy to bring significant memory saving (linear instead ofquadratic) and runtime speedup (2-4$\times$ compared to optimized baselines),with no approximation. However, FlashAttention is still not nearly as fast asoptimized matrix-multiply (GEMM) operations, reaching only 25-40\% of thetheoretical maximum FLOPs/s. We observe that the inefficiency is due tosuboptimal work partitioning between different thread blocks and warps on theGPU, causing either low-occupancy or unnecessary shared memory reads/writes. Wepropose FlashAttention-2, with better work partitioning to address theseissues. In particular, we (1) tweak the algorithm to reduce the number ofnon-matmul FLOPs (2) parallelize the attention computation, even for a singlehead, across different thread blocks to increase occupancy, and (3) within eachthread block, distribute the work between warps to reduce communication throughshared memory. These yield around 2$\times$ speedup compared to FlashAttention,reaching 50-73\% of the theoretical maximum FLOPs/s on A100 and getting closeto the efficiency of GEMM operations. We empirically validate that when usedend-to-end to train GPT-style models, FlashAttention-2 reaches training speedof up to 225 TFLOPs/s per A100 GPU (72\% model FLOPs utilization).",['Machine Learning'],['Tri Dao'],http://arxiv.org/pdf/2307.08691v1,2023-07-17 17:50:36+00:00,FlashAttention-2：並列性とワーク・パーティショニングの向上によるアテンションの高速化,Transformerをより長いシーケンス長に拡張することは、ここ数年の大きな問題であり、言語モデリングや高解像度画像理解における性能向上や、コード、オーディオ、ビデオ生成における新しいアプリケーションの開拓が期待されている。アテンション・レイヤーは、シーケンス長に比例して実行時間とメモリが増加するため、より長いシーケンスへのスケーリングにおける主なボトルネックとなっている。FlashAttentionは、非対称GPUメモリ階層を利用することで、大幅なメモリ節約（2次関数ではなく線形）と実行時間の高速化（最適化されたベースラインと比較して2-4$倍$）をもたらします。しかし、FlashAttentionは、まだ最適化された行列乗算（GEMM）演算ほど高速ではなく、理論的な最大FLOPs/sの25-40%にしか達しない。この非効率性は、異なるスレッドブロック間の最適でない作業分割とGPU上のワープによるものであり、低占有率または不要な共有メモリの読み書きによるものであることがわかりました。これらの問題に対処するため、より優れたワーク・パーティショニングを備えたFlashAttention-2を提案する。特に、(1)アルゴリズムを微調整して、非マットマルFLOP数を減らす。(2)シングルヘッドであっても、異なるスレッドブロック間でアテンション計算を並列化し、占有率を上げる。(3)各スレッドブロック内で、ワープ間で作業を分散し、共有メモリを介した通信を減らす。これらにより、FlashAttentionと比較して約2$倍$の高速化を達成し、A100で理論最大FLOPs/sの50-73%に達し、GEMM演算の効率に近づいた。GPTスタイルのモデルを訓練するためにエンドツーエンドで使用した場合、FlashAttention-2はA100 GPUあたり最大225 TFLOPs/sの訓練速度に達することを実証的に検証しました（モデルFLOPs利用率は72%）。,トランスフォーマーをより長い文章に使うことは、最近の大きな問題です。これにより、言語モデルや高解像度の画像の理解などの性能が向上し、新しいアプリケーションの開発が期待されています。しかし、文章が長くなると、処理時間やメモリの使用量も増えてしまいます。そこで、FlashAttentionという技術が開発されました。これは、特殊なメモリを使うことで、メモリの使用量を減らし、処理時間を速くすることができます。ただし、まだ完璧ではなく、最大の効率には達していません。そこで、FlashAttention-2という改良版が提案されました。これにより、さらに高速化が可能になり、理論上の最大性能の50-73%に近づくことができます。FlashAttention-2を使って、GPTスタイルのモデルを訓練すると、最大225 TFLOPs/sの速度で訓練することができます。,"[{'Keyword': 'Transformer', 'Description': 'Transformerは、自然言語処理タスクにおいて非常に効果的なモデルです。'}, {'Keyword': 'シーケンス長', 'Description': 'シーケンス長は、データセット内のシーケンスの長さを指します。'}, {'Keyword': 'アテンション・レイヤー', 'Description': 'アテンション・レイヤーは、Transformerモデルにおいて重要な役割を果たします。'}, {'Keyword': 'FlashAttention', 'Description': 'FlashAttentionは、高速なアテンション機構を提供するモデルです。'}, {'Keyword': 'GEMM演算', 'Description': 'GEMM演算は、行列の積を効率的に計算するための手法です。'}]",14.030170917510986
http://arxiv.org/abs/2307.08674v2,"TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT","Tables are prevalent in real-world databases, requiring significant time andeffort for humans to analyze and manipulate. The advancements in large languagemodels (LLMs) have made it possible to interact with tables using naturallanguage input, bringing this capability closer to reality. In this paper, wepresent TableGPT, a unified fine-tuned framework that enables LLMs tounderstand and operate on tables using external functional commands. Itintroduces the capability to seamlessly interact with tables, enabling a widerange of functionalities such as question answering, data manipulation (e.g.,insert, delete, query, and modify operations), data visualization, analysisreport generation, and automated prediction. TableGPT aims to provideconvenience and accessibility to users by empowering them to effortlesslyleverage tabular data. At the core of TableGPT lies the novel concept of globaltabular representations, which empowers LLMs to gain a comprehensiveunderstanding of the entire table beyond meta-information. By jointly trainingLLMs on both table and text modalities, TableGPT achieves a deep understandingof tabular data and the ability to perform complex operations on tables throughchain-of-command instructions. Importantly, TableGPT offers the advantage ofbeing a self-contained system rather than relying on external API interfaces.Moreover, it supports efficient data process flow, query rejection (whenappropriate) and private deployment, enabling faster domain data fine-tuningand ensuring data privacy, which enhances the framework's adaptability tospecific use cases.","['Artificial Intelligence', 'Machine Learning']","['Liangyu Zha', 'Junlin Zhou', 'Liyao Li', 'Rui Wang', 'Qingyi Huang', 'Saisai Yang', 'Jing Yuan', 'Changbao Su', 'Xiang Li', 'Aofeng Su', 'Tao Zhang', 'Chen Zhou', 'Kaizhe Shou', 'Miao Wang', 'Wufang Zhu', 'Guoshan Lu', 'Chao Ye', 'Yali Ye', 'Wentao Ye', 'Yiming Zhang', 'Xinglong Deng', 'Jie Xu', 'Haobo Wang', 'Gang Chen', 'Junbo Zhao']",http://arxiv.org/pdf/2307.08674v2,2023-07-17 17:36:09+00:00,TableGPT：テーブル、自然言語、コマンドを1つのGPTに統一するために,表は現実のデータベースに広く存在し、人間が分析・操作するには多大な時間と労力を要する。大規模言語モデル(LLM)の進歩により、自然言語入力を用いてテーブルと対話することが可能となり、この能力が現実に近づいてきた。本論文では、LLMが外部関数コマンドを使用して表を理解し操作できるようにする、統一された微調整されたフレームワークであるTableGPTを紹介する。TableGPTは、テーブルとシームレスに対話する機能を導入し、質問応答、データ操作（挿入、削除、クエリ、変更操作など）、データ可視化、分析レポート生成、自動予測などの幅広い機能を実現する。TableGPTは、表形式のデータを簡単に活用できるようにすることで、ユーザーに利便性とアクセシビリティを提供することを目的としています。TableGPTの中核には、メタ情報を超えて表全体の包括的な理解をLLMに与える、グローバルな表形式という新しい概念がある。TableGPTは、LLMを表とテキストの両方のモダリティで共同学習させることで、表データを深く理解し、コマンド命令によって表に対して複雑な操作を実行する能力を実現します。さらに、効率的なデータ処理フロー、クエリの拒否（適切な場合）、プライベートなデプロイメントをサポートすることで、より迅速なドメインデータの微調整とデータプライバシーの確保を可能にし、特定のユースケースへの適応性を高めている。,"テーブルとは、たくさんのデータが入っているデータベースの中のものです。人がテーブルを分析したり操作したりするのは、時間と労力がたくさん必要です。でも、最近の技術の進歩によって、自然な言葉でテーブルと話すことができるようになりました。この技術は、テーブルとの対話が現実のものに近づいてきたことを意味します。

この論文では、新しいフレームワークであるTableGPTを紹介します。TableGPTは、テーブルとスムーズに対話することができる機能を持っています。例えば、質問に答えたり、データを操作したり、データを見やすく表示したり、分析レポートを作ったり、自動的に予測したりすることができます。TableGPTは、テーブルのデータを使いやすくすることで、ユーザーに便利さと使いやすさを提供することを目指しています。

TableGPTの中心には、テーブル全体を理解するための新しい概念があります。また、TableGPTは、テーブルとテキストの両方の情報を学ぶことで、テーブルのデータを深く理解し、複雑な操作を行うことができます。

さらに、TableGPTは、効率的なデータ処理やデータのプライバシーを守るための機能も持っています。これによって、ドメインのデータを早く使えるようになったり、プライベートな状態で使えるようになったりします。TableGPTは、特定の場面に合わせて使えるようになっています。","[{'Keyword': '大規模言語モデル', 'Description': '大規模な言語モデルは、巨大なデータセットを使用してトレーニングされた人工知能モデルです。自然言語の理解や生成に使用され、様々なタスクに応用されます。'}, {'Keyword': '自然言語入力', 'Description': '自然言語入力は、人間の言語をコンピュータが理解できる形式に変換するプロセスです。テキストや音声などの入力を解析し、意味や情報を抽出します。'}, {'Keyword': '外部関数コマンド', 'Description': '外部関数コマンドは、プログラム内で外部の関数やコマンドを呼び出すための仕組みです。他のプログラムやライブラリの機能を利用することができます。'}, {'Keyword': 'TableGPT', 'Description': 'TableGPTは、表形式のデータを処理するための人工知能モデルです。表の内容を理解し、質問に対する回答や予測を行うことができます。'}, {'Keyword': 'メタ情報', 'Description': 'メタ情報は、データや情報に関する補足的な情報のことです。例えば、データの作成者や更新日時などが含まれます。'}]",18.481514930725098
http://arxiv.org/abs/2307.08576v1,A Study on the Performance of Generative Pre-trained Transformer (GPT) in Simulating Depressed Individuals on the Standardized Depressive Symptom Scale,"Background: Depression is a common mental disorder with societal and economicburden. Current diagnosis relies on self-reports and assessment scales, whichhave reliability issues. Objective approaches are needed for diagnosingdepression. Objective: Evaluate the potential of GPT technology in diagnosingdepression. Assess its ability to simulate individuals with depression andinvestigate the influence of depression scales. Methods: Threedepression-related assessment tools (HAMD-17, SDS, GDS-15) were used. Twoexperiments simulated GPT responses to normal individuals and individuals withdepression. Compare GPT's responses with expected results, assess itsunderstanding of depressive symptoms, and performance differences underdifferent conditions. Results: GPT's performance in depression assessment wasevaluated. It aligned with scoring criteria for both individuals withdepression and normal individuals. Some performance differences were observedbased on depression severity. GPT performed better on scales with highersensitivity. Conclusion: GPT accurately simulates individuals with depressionand normal individuals during depression-related assessments. Deviations occurwhen simulating different degrees of depression, limiting understanding of mildand moderate cases. GPT performs better on scales with higher sensitivity,indicating potential for developing more effective depression scales. GPT hasimportant potential in depression assessment, supporting clinicians andpatients.","['Neurons and Cognition', 'Machine Learning']","['Sijin Cai', 'Nanfeng Zhang', 'Jiaying Zhu', 'Yanjie Liu', 'Yongjin Zhou']",http://arxiv.org/pdf/2307.08576v1,2023-07-17 15:44:13+00:00,標準化抑うつ症状尺度における生成的事前訓練変換器(GPT)の抑うつ状態シミュレーション性能に関する研究,背景うつ病は社会的・経済的負担の大きい一般的な精神疾患である。現在の診断は、信頼性に問題のある自己申告や評価尺度に依存している。うつ病の診断には客観的なアプローチが必要である。目的うつ病診断におけるGPT技術の可能性を評価する。うつ病患者をシミュレートする能力を評価し、うつ病尺度の影響を調査する。方法3種類のうつ病関連評価ツール（HAMD-17、SDS、GDS-15）を使用した。2つの実験では、健常者とうつ病患者に対するGPTの反応をシミュレートした。GPTの反応を期待される結果と比較し、GPTの抑うつ症状に対する理解、異なる条件下でのパフォーマンスの違いを評価する。結果うつ病評価におけるGPTの性能を評価した。その結果、GPTは、うつ病患者および健常者の採点基準と一致した。うつ病の重症度により、いくつかの成績差が観察された。GPTは、感度の高い尺度において良好な成績を示した。結論GPTは、うつ病関連評価において、うつ病患者と健常者を正確にシミュレートする。異なる程度のうつ病をシミュレートする際に偏差が生じ、軽度および中等度のケースの理解が制限される。GPTは感度の高い尺度においてより良い結果を示し、より効果的なうつ病尺度の開発の可能性を示す。GPTはうつ病評価において重要な可能性を持っており、臨床家と患者をサポートする。,うつ病は、とても大変で、社会やお金にも負担をかける病気です。現在の診断方法は、自分で話すことや評価の尺度に頼っているので、信頼性が問題です。うつ病の診断には、客観的な方法が必要です。この研究では、GPTという技術を使って、うつ病の診断に役立つか評価しました。うつ病の症状をシミュレートする能力や、うつ病の尺度にどのような影響があるかを調べました。実験では、健康な人とうつ病の人に対して、GPTの反応を調べました。GPTの反応を予想される結果と比べて、うつ病の症状を理解することや、異なる状況でのパフォーマンスの違いを評価しました。結果として、GPTはうつ病の評価において、うつ病の人と健康な人の評価基準と一致しました。うつ病の重症度によっては、いくつかの違いが見られました。GPTは感度の高い尺度として良い結果を示しました。結論として、GPTはうつ病の評価において役立ち、うつ病の人と健康な人を正確にシミュレートすることができます。ただし、うつ病の程度が違う場合には、正確な結果が出にくくなることがあります。GPTは感度の高い尺度として良い結果を示し、より効果的なうつ病の評価方法の開発の可能性を示しています。GPTは、臨床家や患者のサポートに役立つ重要な技術です。,"[{'Keyword': 'うつ病', 'Description': 'うつ病は心の病気であり、悲しみや無気力感などの症状があります。'}, {'Keyword': '診断', 'Description': '診断は医師が患者の症状や心理的な状態を評価するプロセスです。'}, {'Keyword': 'アプローチ', 'Description': 'アプローチはうつ病の治療やケアの方法や手段を指します。'}, {'Keyword': '尺度', 'Description': '尺度はうつ病の症状や重症度を測定するための基準やスケールです。'}, {'Keyword': '感度', 'Description': '感度は尺度やテストの正確さや敏感さを表す指標です。'}]",21.760522842407227
http://arxiv.org/abs/2307.08191v1,Unleashing the Potential of LLMs for Quantum Computing: A Study in Quantum Architecture Design,"Large Language Models (LLMs) contribute significantly to the development ofconversational AI and has great potentials to assist the scientific research invarious areas. This paper attempts to address the following questions: Whatopportunities do the current generation of generative pre-trained transformers(GPTs) offer for the developments of noisy intermediate-scale quantum (NISQ)technologies? Additionally, what potentials does the forthcoming generation ofGPTs possess to push the frontier of research in fault-tolerant quantumcomputing (FTQC)? In this paper, we implement a QGAS model, which can rapidlypropose promising ansatz architectures and evaluate them with applicationbenchmarks including quantum chemistry and quantum finance tasks. Our resultsdemonstrate that after a limited number of prompt guidelines and iterations, wecan obtain a high-performance ansatz which is able to produce comparableresults that are achieved by state-of-the-art quantum architecture searchmethods. This study provides a simple overview of GPT's capabilities insupporting quantum computing research while highlighting the limitations of thecurrent GPT at the same time. Additionally, we discuss futuristic applicationsfor LLM in quantum research.",['Quantum Physics'],"['Zhiding Liang', 'Jinglei Cheng', 'Rui Yang', 'Hang Ren', 'Zhixin Song', 'Di Wu', 'Xuehai Qian', 'Tongyang Li', 'Yiyu Shi']",http://arxiv.org/pdf/2307.08191v1,2023-07-17 01:39:38+00:00,量子コンピューティングのためのLLMの可能性を解き放つ：量子アーキテクチャ設計の研究,大規模言語モデル（LLM）は会話AIの発展に大きく貢献し、様々な分野の科学研究を支援する大きな可能性を秘めている。本稿では、以下の問いを解決することを試みる：現在の世代の生成的事前訓練変換器（GPT）は、ノイズの多い中間量子（NISQ）技術の開発にどのような機会を提供するのか？さらに、来るべき世代のGPTは、耐故障量子計算（FTQC）研究のフロンティアを押し広げる可能性があるのか？本論文では、QGASモデルを実装し、有望なアンサッツアーキテクチャを迅速に提案し、量子化学や量子ファイナンスなどのアプリケーションベンチマークで評価する。その結果、限られた回数の迅速なガイドラインと反復により、最先端の量子アーキテクチャ探索手法と同等の結果を得ることができる高性能なアサッツを得ることができることを実証する。本研究では、量子コンピュータ研究を支援するGPTの機能を簡単に概観すると同時に、現在のGPTの限界を明らかにする。さらに、量子研究におけるLLMの将来的な応用についても議論する。,大きな言葉のモデル（LLM）は、話す人工知能（AI）の進歩に大いに役立ち、さまざまな科学研究の手助けになる可能性があります。この論文では、次の質問に答えようとします：現在のAIの開発は、どのようにして新しい技術の開発に役立つのでしょうか？また、将来のAIは、新しい研究のフロンティアを広げることができるのでしょうか？この論文では、新しいモデルを使って、素早く提案し、評価する方法を紹介します。その結果、少ない時間と繰り返しで、最新の技術を使った素晴らしい結果が得られることを示します。この研究では、AIの機能を簡単に説明し、現在の限界を明らかにするだけでなく、将来の研究にどのように役立つかも議論します。,"[{'Keyword': '大規模言語モデル（LLM）', 'Description': '大規模言語モデル（LLM）は、巨大なデータセットを使用してトレーニングされた言語モデルです。'}, {'Keyword': '生成的事前訓練変換器（GPT）', 'Description': '生成的事前訓練変換器（GPT）は、トランスフォーマーモデルを使用して生成されたテキストを生成するモデルです。'}, {'Keyword': '中間量子（NISQ）技術', 'Description': '中間量子（NISQ）技術は、現在の量子コンピュータの制約を考慮した技術です。'}, {'Keyword': '耐故障量子計算（FTQC）研究', 'Description': '耐故障量子計算（FTQC）研究は、エラー訂正技術を使用して信頼性の高い量子計算を実現する研究です。'}, {'Keyword': 'QGASモデル', 'Description': 'QGASモデルは、量子コンピュータを使用して生成的対抗ネットワークをトレーニングするモデルです。'}]",21.422166109085083
http://arxiv.org/abs/2307.07982v1,A Survey of Techniques for Optimizing Transformer Inference,"Recent years have seen a phenomenal rise in performance and applications oftransformer neural networks. The family of transformer networks, includingBidirectional Encoder Representations from Transformer (BERT), GenerativePretrained Transformer (GPT) and Vision Transformer (ViT), have shown theireffectiveness across Natural Language Processing (NLP) and Computer Vision (CV)domains. Transformer-based networks such as ChatGPT have impacted the lives ofcommon men. However, the quest for high predictive performance has led to anexponential increase in transformers' memory and compute footprint. Researchershave proposed techniques to optimize transformer inference at all levels ofabstraction. This paper presents a comprehensive survey of techniques foroptimizing the inference phase of transformer networks. We survey techniquessuch as knowledge distillation, pruning, quantization, neural architecturesearch and lightweight network design at the algorithmic level. We furtherreview hardware-level optimization techniques and the design of novel hardwareaccelerators for transformers. We summarize the quantitative results on thenumber of parameters/FLOPs and accuracy of several models/techniques toshowcase the tradeoff exercised by them. We also outline future directions inthis rapidly evolving field of research. We believe that this survey willeducate both novice and seasoned researchers and also spark a plethora ofresearch efforts in this field.","['Machine Learning', 'Hardware Architecture', 'Computation and Language', 'Computer Vision and Pattern Recognition']","['Krishna Teja Chitty-Venkata', 'Sparsh Mittal', 'Murali Emani', 'Venkatram Vishwanath', 'Arun K. Somani']",http://arxiv.org/pdf/2307.07982v1,2023-07-16 08:50:50+00:00,トランス推論を最適化する技術のサーベイ,近年、変換器ニューラルネットワークの性能と応用が驚異的に向上している。BERT（トランスフォーマーからの双方向エンコーダ表現）、GPT（GenerativePretrained Transformer）、ViT（Vision Transformer）などのトランスフォーマーネットワークファミリーは、自然言語処理（NLP）およびコンピュータビジョン（CV）ドメインにわたってその有効性を示している。ChatGPTのようなTransformerベースのネットワークは、庶民の生活に影響を与えてきた。しかし、高い予測性能を追求するあまり、トランスフォーマーのメモリと計算フットプリントは指数関数的に増加している。研究者たちは、あらゆる抽象化レベルでトランスフォーマの推論を最適化する技術を提案してきた。本稿では、変圧器ネットワークの推論フェーズを最適化する技術の包括的なサーベイを行う。知識抽出、刈り込み、量子化、ニューラルアーキテクチャ探索、アルゴリズムレベルでの軽量ネットワーク設計などの技術を調査する。さらに、ハードウェアレベルでの最適化技術や、トランスフォーマー用の新しいハードウェアアクセラレータの設計についてもレビューする。いくつかのモデル/手法のパラメータ数/FLOPsと精度に関する定量的な結果をまとめ、それらのトレードオフを示す。また、急速に発展しているこの研究分野における将来の方向性についても概説する。我々は、この調査が初心者と熟練研究者の両方を教育し、またこの分野における多くの研究努力を喚起すると信じている。,最近、変換器ニューラルネットワークの性能がとても良くなってきています。これは、言葉や画像を理解するための技術です。たくさんの新しい技術が開発されてきました。例えば、BERTやGPT、ViTなどです。これらの技術は、文章や画像の処理に役立っています。私たちの日常生活にも影響を与えています。しかし、これらの技術は、とても複雑で、たくさんの計算を必要とします。研究者たちは、これらの技術をもっと効率的にする方法を考えています。この論文では、さまざまな方法を調査しました。例えば、情報の取り出しや、計算を減らす方法、新しいハードウェアの設計などです。また、これらの方法の利点と欠点もまとめました。さらに、今後の研究の方向性についても話しました。この論文は、初心者の人にも、専門家の人にも役立つと思います。そして、これからもたくさんの研究が進むことを期待しています。,"[{'Keyword': '変換器ニューラルネットワーク', 'Description': '変換器ニューラルネットワークは、自然言語処理のための強力なモデルです。トランスフォーマーネットワークファミリーの一部であり、テキストの変換や生成に使用されます。'}, {'Keyword': 'トランスフォーマーネットワークファミリー', 'Description': 'トランスフォーマーネットワークファミリーは、自然言語処理のための革新的なモデルです。変換器ニューラルネットワークを含み、テキストの処理や生成に優れた性能を発揮します。'}, {'Keyword': '自然言語処理', 'Description': '自然言語処理は、人間の言語をコンピュータが理解し、処理するための技術です。テキストの解析、機械翻訳、感情分析などに応用されます。'}, {'Keyword': 'コンピュータビジョン', 'Description': 'コンピュータビジョンは、コンピュータが画像やビデオを解析し、理解するための技術です。物体検出、顔認識、画像分類などに応用されます。'}, {'Keyword': '最適化技術', 'Description': '最適化技術は、問題の制約条件下で最適な解を見つけるための手法です。数理最適化、進化アルゴリズム、勾配降下法などが一般的な最適化技術です。'}]",24.1573429107666
http://arxiv.org/abs/2307.07930v1,GeoGPT: Understanding and Processing Geospatial Tasks through An Autonomous GPT,"Decision-makers in GIS need to combine a series of spatial algorithms andoperations to solve geospatial tasks. For example, in the task of facilitysiting, the Buffer tool is usually first used to locate areas close or awayfrom some specific entities; then, the Intersect or Erase tool is used toselect candidate areas satisfied multiple requirements. Though professionalscan easily understand and solve these geospatial tasks by sequentiallyutilizing relevant tools, it is difficult for non-professionals to handle theseproblems. Recently, Generative Pre-trained Transformer (e.g., ChatGPT) presentsstrong performance in semantic understanding and reasoning. Especially, AutoGPTcan further extend the capabilities of large language models (LLMs) byautomatically reasoning and calling externally defined tools. Inspired by thesestudies, we attempt to lower the threshold of non-professional users to solvegeospatial tasks by integrating the semantic understanding ability inherent inLLMs with mature tools within the GIS community. Specifically, we develop a newframework called GeoGPT that can conduct geospatial data collection,processing, and analysis in an autonomous manner with the instruction of onlynatural language. In other words, GeoGPT is used to understand the demands ofnon-professional users merely based on input natural language descriptions, andthen think, plan, and execute defined GIS tools to output final effectiveresults. Several cases including geospatial data crawling, spatial query,facility siting, and mapping validate the effectiveness of our framework.Though limited cases are presented in this paper, GeoGPT can be furtherextended to various tasks by equipping with more GIS tools, and we think theparadigm of ""foundational plus professional"" implied in GeoGPT provides aneffective way to develop next-generation GIS in this era of large foundationmodels.","['Computation and Language', 'Artificial Intelligence']","['Yifan Zhang', 'Cheng Wei', 'Shangyou Wu', 'Zhengting He', 'Wenhao Yu']",http://arxiv.org/pdf/2307.07930v1,2023-07-16 03:03:59+00:00,GeoGPT：自律型GPTによる地理空間タスクの理解と処理,GISの意思決定者は、地理空間タスクを解決するために、一連の空間アルゴリズムと操作を組み合わせる必要がある。例えば、施設立地のタスクでは、通常、最初にバッファツールを使用して、特定のエンティティに近い、または特定のエンティティから離れた領域を特定し、次に、交差または消去ツールを使用して、複数の要件を満たす候補領域を選択する。専門家であれば、これらの地理空間タスクを理解し、関連するツールを順次使用することで解決することは容易であるが、専門家でない人がこれらの問題を処理することは困難である。近年、Generative Pre-trained Transformer (例えば、ChatGPT) は、意味理解と推論において強力な性能を示している。特に、AutoGPTは、自動的に推論し、外部で定義されたツールを呼び出すことによって、大規模言語モデル（LLM）の機能をさらに拡張することができる。これらの研究に触発され、我々は、LLMに内在する意味理解能力をGISコミュニティ内の成熟したツールと統合することにより、非専門家ユーザが地理空間タスクを解決するための敷居を下げることを試みる。具体的には、GeoGPTと呼ばれる新しいフレームワークを開発し、自然言語のみの指示で自律的に地理空間データの収集、処理、分析を行うことができる。言い換えれば、GeoGPTは、入力された自然言語記述に基づくだけで、専門家ではないユーザの要求を理解し、最終的に効果的な結果を出力するために、定義されたGISツールを考え、計画し、実行するために使用される。本稿では、限られたケースを紹介したが、GeoGPT は、より多くの GIS ツールを装備することで、様々なタスクにさらに拡張することが可能であり、GeoGPT に含意される「基礎＋専門」のパラダイムは、大規模な基礎モデルの時代において、次世代 GIS を開発するための効果的な方法を提供すると考える。,GISの意思決定者は、地理空間の問題を解決するために、いくつかの手順や道具を使います。例えば、建物を建てる場所を決めるときは、まず特定の場所からある距離内のエリアを見つけます。それから、いくつかの条件を満たす候補地を選びます。専門家はこれらの手順を知っていて、簡単に解決できますが、専門家でない人にとっては難しいです。最近、新しい技術が開発されています。それは自動的に問題を解決することができます。私たちは、この技術を使って、専門家でない人でも地理空間の問題を解決できるようにしようとしています。具体的には、新しいフレームワークを作りました。それは自然な言葉だけで地理空間のデータを集めたり処理したり分析したりできます。つまり、専門家でない人の要求を理解し、最終的に効果的な結果を出すために、特定の道具を使って計画したり実行したりすることができます。このフレームワークは、さまざまな問題に対応することができます。そして、次世代の地理情報システムの開発に役立つと考えています。,"[{'Keyword': '地理空間タスク', 'Description': '地理的な情報やデータを扱うタスク'}, {'Keyword': 'バッファツール', 'Description': '特定のエンティティに近い、または特定のエンティティから離れた領域を特定するためのツール'}, {'Keyword': '交差または消去ツール', 'Description': '複数の要件を満たす候補領域を選択するためのツール'}, {'Keyword': 'Generative Pre-trained Transformer', 'Description': '事前学習されたモデルであり、意味理解と推論において強力な性能を示す'}, {'Keyword': 'GeoGPT', 'Description': '自然言語のみの指示で自律的に地理空間データの収集、処理、分析を行うフレームワーク'}]",20.378801822662354
http://arxiv.org/abs/2307.07359v1,From Multilayer Perceptron to GPT: A Reflection on Deep Learning Research for Wireless Physical Layer,"Most research studies on deep learning (DL) applied to the physical layer ofwireless communication do not put forward the critical role of theaccuracy-generalization trade-off in developing and evaluating practicalalgorithms. To highlight the disadvantage of this common practice, we revisit adata decoding example from one of the first papers introducing DL-basedend-to-end wireless communication systems to the research community andpromoting the use of artificial intelligence (AI)/DL for the wireless physicallayer. We then put forward two key trade-offs in designing DL models forcommunication, namely, accuracy versus generalization and compression versuslatency. We discuss their relevance in the context of wireless communicationsuse cases using emerging DL models including large language models (LLMs).Finally, we summarize our proposed evaluation guidelines to enhance theresearch impact of DL on wireless communications. These guidelines are anattempt to reconcile the empirical nature of DL research with the rigorousrequirement metrics of wireless communications systems.","['Information Theory', 'Information Theory']","['Mohamed Akrout', 'Amine Mezghani', 'Ekram Hossain', 'Faouzi Bellili', 'Robert W. Heath']",http://arxiv.org/pdf/2307.07359v1,2023-07-14 14:04:01+00:00,多層パーセプトロンからGPTへ：無線物理層のためのディープラーニング研究の考察,無線通信の物理層に適用される深層学習（DL）に関する研究のほとんどは、実用的なアルゴリズムの開発と評価において、精度と汎化のトレードオフの重要な役割を提唱していない。この一般的な慣行の欠点を強調するために、DLベースのエンド・ツー・エンドの無線通信システムを研究コミュニティに紹介し、無線物理層への人工知能（AI）/DLの利用を促進した最初の論文の1つから、データ復号の例を再検討する。次に、通信のためのDLモデル設計における2つの重要なトレードオフ、すなわち、精度対汎化、圧縮対遅延を提唱する。最後に、無線通信におけるDLの研究効果を高めるために提案する評価ガイドラインについてまとめる。これらのガイドラインは、DL研究の経験的性質と無線通信システムの厳密な要件測定基準との調和を図る試みである。,ほとんどの無線通信の研究は、深層学習（DL）という技術を使っています。でも、この技術には問題があります。実際に使うためのアルゴリズムを作るときに、正確さと汎用性のバランスをとることが難しいんです。この問題を解決するために、私たちはDLを使った無線通信システムを研究しました。そして、データの復号という例を使って、そのシステムを紹介しました。また、DLを使った通信モデルを作るときに、正確さと圧縮のバランス、そして遅延の問題についても考える必要があります。最後に、DLの研究を進めるための評価ガイドラインを提案しました。これらのガイドラインは、DLの研究と無線通信システムの要件を合わせるためのものです。,"[{'Keyword': '深層学習', 'Description': 'ディープラーニングの一種で、多層のニューラルネットワークを用いて高度なパターン認識を行う手法。'}, {'Keyword': '物理層', 'Description': '通信システムの階層構造の一部であり、データの物理的な伝送を担当する層。'}, {'Keyword': 'アルゴリズム', 'Description': '問題を解決するための手順や方法のことで、コンピュータプログラムの基礎となる。'}, {'Keyword': '人工知能', 'Description': 'コンピュータが人間のような知的な行動をすることを目指す研究分野。'}, {'Keyword': 'データ復号', 'Description': '暗号化されたデータを元の形に戻すこと。暗号解読やデータの復元に使用される。'}]",16.762826919555664
http://arxiv.org/abs/2307.07262v1,MorphPiece : Moving away from Statistical Language Representation,"Tokenization is a critical part of modern NLP pipelines. However,contemporary tokenizers for Large Language Models are based on statisticalanalysis of text corpora, without much consideration to the linguisticfeatures. We propose a linguistically motivated tokenization scheme,MorphPiece, which is based partly on morphological segmentation of theunderlying text. A GPT-style causal language model trained on this tokenizer(called MorphGPT) shows superior convergence compared to the same architecturetrained on a standard BPE tokenizer. Specifically we get Language Modelingperformance comparable to a 6 times larger model. Additionally, we evaluateMorphGPT on a variety of NLP tasks in supervised and unsupervised settings andfind superior performance across the board, compared to GPT-2 model.",['Computation and Language'],['Haris Jabbar'],http://arxiv.org/pdf/2307.07262v1,2023-07-14 10:35:04+00:00,MorphPiece : 統計的言語表現からの脱却,トークン化は現代の自然言語処理パイプラインの重要な部分である。しかし、最近の大規模言語モデル用のトークン化は、テキストコーパスの統計的分析に基づいており、言語的特徴はあまり考慮されていない。我々は言語学的に動機づけられたトークン化スキームであるMorphPieceを提案する。このトークナイザで学習したGPTスタイルの因果言語モデル（MorphGPTと呼ぶ）は、標準的なBPEトークナイザで学習した同じアーキテクチャと比較して、優れた収束性を示す。具体的には、6倍大きなモデルに匹敵する言語モデリング性能が得られる。さらに、教師あり・教師なし設定の様々なNLPタスクでMorphGPTを評価したところ、GPT-2モデルと比較して、全体的に優れた性能が得られました。,トークン化は、現代の言語処理の大切な部分です。最近の大きな言語モデルでは、テキストの統計的な分析を使ってトークン化をしていますが、言語の特徴を考慮することはあまりありません。私たちは、言語学の考え方に基づいたトークン化方法であるMorphPieceを提案します。このトークン化方法を使って学習したMorphGPTという言語モデルは、通常のBPEトークン化を使った同じモデルと比べて、とても良い結果を出します。具体的には、6倍も大きなモデルに匹敵する性能があります。さらに、様々なNLPのタスクでMorphGPTを評価した結果、GPT-2モデルと比べて全体的に優れた性能が得られました。,"[{'Keyword': 'トークン化', 'Description': 'トークン化は、テキストを単語や文字などの小さな単位に分割する処理です。'}, {'Keyword': '自然言語処理パイプライン', 'Description': '自然言語処理パイプラインは、テキストデータを受け取り、トークン化、品詞タグ付け、構文解析などの処理を行う一連の処理の流れです。'}, {'Keyword': '言語モデル', 'Description': '言語モデルは、自然言語の文法や意味を学習し、テキスト生成や文の評価などのタスクに使用されるモデルです。'}, {'Keyword': 'トークナイザ', 'Description': 'トークナイザは、テキストをトークンに分割するツールやアルゴリズムのことです。'}, {'Keyword': '言語モデリング性能', 'Description': '言語モデリング性能は、言語モデルの予測精度や生成能力などの性能を評価する指標です。'}]",16.528757095336914
http://arxiv.org/abs/2307.06524v1,Agreement Tracking for Multi-Issue Negotiation Dialogues,"Automated negotiation support systems aim to help human negotiators reachmore favorable outcomes in multi-issue negotiations (e.g., an employer and acandidate negotiating over issues such as salary, hours, and promotions beforea job offer). To be successful, these systems must accurately track agreementsreached by participants in real-time. Existing approaches either focus ontask-oriented dialogues or produce unstructured outputs, rendering themunsuitable for this objective. Our work introduces the novel task of agreementtracking for two-party multi-issue negotiations, which requires continuousmonitoring of agreements within a structured state space. To address thescarcity of annotated corpora with realistic multi-issue negotiation dialogues,we use GPT-3 to build GPT-Negochat, a synthesized dataset that we make publiclyavailable. We present a strong initial baseline for our task bytransfer-learning a T5 model trained on the MultiWOZ 2.4 corpus. Pre-trainingT5-small and T5-base on MultiWOZ 2.4's DST task enhances results by 21% and 9%respectively over training solely on GPT-Negochat. We validate our method'ssample-efficiency via smaller training subset experiments. By releasingGPT-Negochat and our baseline models, we aim to encourage further research inmulti-issue negotiation dialogue agreement tracking.",['Computation and Language'],"['Amogh Mannekote', 'Bonnie J. Dorr', 'Kristy Elizabeth Boyer']",http://arxiv.org/pdf/2307.06524v1,2023-07-13 02:00:27+00:00,複数イシューの交渉ダイアログにおける合意追跡,自動化された交渉支援システムは、複数の問題を抱える交渉（例えば、内定前に給与、勤務時間、昇進などの問題をめぐって雇用主と候補者が交渉する場合）において、人間の交渉者がより有利な結果に到達するのを支援することを目的としている。成功するためには、これらのシステムは、リアルタイムで参加者によって達成された合意を正確に追跡しなければならない。既存のアプローチは、タスク指向の対話に重点を置くか、構造化されていない出力を生成するかのどちらかであり、この目的には適していない。これは、構造化された状態空間内での合意の継続的な監視を必要とする。現実的なマルチイシュー交渉対話の注釈付きコーパスの希少性に対処するため、GPT-3を用いてGPT-Negochatを構築し、その合成データセットを公開する。我々は、MultiWOZ 2.4コーパスで訓練されたT5モデルを転送学習することにより、我々のタスクのための強力な初期ベースラインを提示する。T5-smallとT5-baseをMultiWOZ 2.4のDSTタスクで事前学習することで、GPT-Negochatのみで学習するよりも、それぞれ21%と9%結果が向上する。また、GPT-Negochatのみでの学習と比較して、21%と9%向上しました。GPT-Negochatと我々のベースラインモデルを公開することで、マルチイシュー交渉対話合意追跡のさらなる研究を促進することを目指す。,自動化された交渉支援システムは、人々がお金や働く時間、昇進などの問題を話し合う時に、人間の交渉者がより良い結果を得るために使われます。このシステムは、参加者が合意した内容を正確に追跡する必要があります。これまでの方法では、問題解決の会話に重点を置いたり、整理されていない回答を出したりすることがありましたが、この目的には適していませんでした。私たちは、GPT-3という技術を使ってGPT-Negochatというシステムを作り、実際の交渉のデータを公開しました。また、MultiWOZ 2.4というデータを使ってT5モデルを訓練し、強力なベースラインを作りました。GPT-Negochatを使って学習すると、結果が21%から9%向上しました。私たちは、GPT-Negochatとベースラインモデルを公開し、さらなる研究を進めることを目指しています。,"[{'Keyword': '自動化された交渉支援システム', 'Description': '自動化された交渉支援システムは、交渉プロセスを自動化し、効率的な交渉をサポートするシステムです。'}, {'Keyword': '交渉', 'Description': '交渉は異なる意見や要求を調整し、合意を形成するプロセスです。'}, {'Keyword': '合意', 'Description': '合意は交渉の結果として達成される合意や合意です。'}, {'Keyword': 'マルチイシュー交渉対話', 'Description': 'マルチイシュー交渉対話は、複数の問題に関連する交渉の対話です。'}, {'Keyword': 'タスク指向の対話', 'Description': 'タスク指向の対話は、特定の目標やタスクに関連する対話です。'}]",14.785988092422485
http://arxiv.org/abs/2307.06218v1,Ashaar: Automatic Analysis and Generation of Arabic Poetry Using Deep Learning Approaches,"Poetry holds immense significance within the cultural and traditional fabricof any nation. It serves as a vehicle for poets to articulate their emotions,preserve customs, and convey the essence of their culture. Arabic poetry is noexception, having played a cherished role in the heritage of the Arabiccommunity throughout history and maintaining its relevance in the present era.Typically, comprehending Arabic poetry necessitates the expertise of a linguistwho can analyze its content and assess its quality. This paper presents theintroduction of a framework called \textit{Ashaar}https://github.com/ARBML/Ashaar, which encompasses a collection of datasets andpre-trained models designed specifically for the analysis and generation ofArabic poetry. The pipeline established within our proposed approachencompasses various aspects of poetry, such as meter, theme, and eraclassification. It also incorporates automatic poetry diacritization, enablingmore intricate analyses like automated extraction of the \textit{Arudi} style.Additionally, we explore the feasibility of generating conditional poetrythrough the pre-training of a character-based GPT model. Furthermore, as partof this endeavor, we provide four datasets: one for poetry generation, anotherfor diacritization, and two for Arudi-style prediction. These datasets aim tofacilitate research and development in the field of Arabic poetry by enablingresearchers and enthusiasts to delve into the nuances of this rich literarytradition.",['Computation and Language'],"['Zaid Alyafeai', 'Maged S. Al-Shaibani', 'Moataz Ahmed']",http://arxiv.org/pdf/2307.06218v1,2023-07-12 15:07:16+00:00,アシャールディープラーニングアプローチによるアラビア語詩の自動解析と生成,詩は、どの国の文化や伝統的な構造においても、計り知れない重要性を持っている。詩は、詩人たちが自分たちの感情を表現し、習慣を守り、文化の本質を伝える手段として機能している。アラビア語の詩も例外ではなく、歴史を通じてアラビア語コミュニティの遺産として大切な役割を果たし、現代においてもその関連性を維持している。通常、アラビア語の詩を理解するには、その内容を分析し、その質を評価できる言語学者の専門知識が必要である。本論文では、アラビア語の詩の分析と生成のために特別に設計されたデータセットと事前に訓練されたモデルのコレクションを包含する、୧⃛(๑⃙⃘⁼̴̀꒳⁼̴́๑⃙⃘)୨⃛https://github.com/ARBML/Ashaar。私たちの提案するアプローチで確立されたパイプラインは、メーター、テーマ、エラ分類など、詩のさまざまな側面を含んでいます。さらに、文字ベースのGPTモデルの事前学習を通して、条件付き詩の生成の可能性を探る。さらに、この試みの一環として、4つのデータセットを提供する。1つは詩の生成用、もう1つは発音区分用、そして2つはアルディ風の予測用である。これらのデータセットは、研究者や愛好家がこの豊かな文学的伝統のニュアンスを掘り下げることを可能にすることで、アラビア語詩の分野における研究開発を促進することを目的としています。,詩は、言葉で感情を表現する素敵なものです。詩は、文化や伝統に関係なく、大切な存在です。アラビア語の詩も、たくさんの人々に大切にされています。アラビア語の詩を理解するのは難しいですが、言語学者の専門知識があれば、詩の内容や質を評価することができます。この論文では、アラビア語の詩を分析し、生成するためのデータセットとモデルが紹介されています。また、詩のリズムやテーマなど、詩のさまざまな側面も含まれています。さらに、詩を作るためのデータセットも提供されています。これらのデータセットを使って、アラビア語の詩の研究や開発が進められることを目指しています。,"[{'Keyword': '詩', 'Description': '詩は言葉の響きやリズムを使って表現される文学の形式です。感情や思考を表現するために使用されます。'}, {'Keyword': 'アラビア語', 'Description': 'アラビア語は、アラビア半島で話されるセム語派の言語です。アラビア文字で書かれ、イスラム教の聖典であるコーランもアラビア語で書かれています。'}, {'Keyword': 'データセット', 'Description': 'データセットは、情報やデータの集合体です。研究や分析のために使用され、機械学習や人工知能のモデルのトレーニングにも利用されます。'}, {'Keyword': 'モデル', 'Description': 'モデルは、現実世界の対象やシステムを表現するために使用される抽象的な概念です。機械学習や人工知能の分野では、データからパターンや関係性を学習するための数学的な表現を指します。'}, {'Keyword': '言語学者', 'Description': '言語学者は、言語やその構造、使用法、変化などを研究する学者です。言語の起源や発展、文法や音韻論などを研究し、言語の理解や解釈に貢献します。'}]",19.14508867263794
http://arxiv.org/abs/2307.06187v1,Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems,"In autonomic computing, self-adaptation has been proposed as a fundamentalparadigm to manage the complexity of multiagent systems (MASs). This achievedby extending a system with support to monitor and adapt itself to achievespecific concerns of interest. Communication in these systems is key given thatin scenarios involving agent interaction, it enhances cooperation and reducescoordination challenges by enabling direct, clear information exchange.However, improving the expressiveness of the interaction communication withMASs is not without challenges. In this sense, the interplay betweenself-adaptive systems and effective communication is crucial for future MASadvancements. In this paper, we propose the integration of large languagemodels (LLMs) such as GPT-based technologies into multiagent systems. We anchorour methodology on the MAPE-K model, which is renowned for its robust supportin monitoring, analyzing, planning, and executing system adaptations inresponse to dynamic environments. We also present a practical illustration ofthe proposed approach, in which we implement and assess a basic MAS-basedapplication. The approach significantly advances the state-of-the-art ofself-adaptive systems by proposing a new paradigm for MAS self-adaptation ofautonomous systems based on LLM capabilities.","['Multiagent Systems', 'Artificial Intelligence', 'Computation and Language']","['Nathalia Nascimento', 'Paulo Alencar', 'Donald Cowan']",http://arxiv.org/pdf/2307.06187v1,2023-07-12 14:26:46+00:00,自己適応型大規模言語モデル（LLM）に基づくマルチエージェントシステム,オートノミックコンピューティングでは、マルチエージェントシステム（MAS）の複雑性を管理するための基本的なパラダイムとして自己適応が提案されている。これは、関心のある特定の関心事を達成するために、それ自身を監視し適応させるサポートによってシステムを拡張することによって達成される。これらのシステムにおけるコミュニケーションは、エージェントの相互作用を含むシナリオにおいて、直接的で明確な情報交換を可能にすることで協力を強化し、調整の課題を軽減することを考えると、重要な鍵となる。この意味で、自己適応システムと効果的なコミュニケーションの相互作用は、将来のMASの進歩にとって極めて重要である。本論文では、GPTに基づく技術のような大規模言語モデル（LLM）をマルチエージェントシステムに統合することを提案する。本論文では、動的環境に対応したシステム適応の監視、分析、計画、実行をロバストにサポートすることで有名なMAPE-Kモデルを基礎とした手法を提案する。また、基本的なMASベースのアプリケーションを実装し評価することで、提案するアプローチの実用的な例証を示す。本アプローチは、LLM能力に基づく自律システムのMAS自己適応のための新しいパラダイムを提案することにより、自己適応システムの最先端を大きく前進させる。,"オートノミックコンピューティングでは、マルチエージェントシステム（MAS）の複雑さを管理するために、自己適応という考え方が提案されています。これは、特定の目標を達成するために、システムが自分自身を監視し、必要に応じて変化することで実現されます。このシステムでは、エージェント同士のコミュニケーションがとても重要で、お互いに情報を交換することで協力し、調整の問題を解決します。このような自己適応システムと効果的なコミュニケーションの組み合わせは、将来のマルチエージェントシステムの進歩にとって非常に重要です。

この論文では、大規模な言語モデル（LLM）をマルチエージェントシステムに組み込む方法を提案しています。具体的には、動的な環境に対応するためのシステムの監視、分析、計画、実行をサポートするMAPE-Kモデルという手法を使います。また、実際にこの手法を使って基本的なマルチエージェントシステムを作り、評価することで、提案したアプローチの実用的な例を示します。このアプローチによって、自律的なシステムの自己適応において、大きな進歩ができると期待されています。","[{'Keyword': 'オートノミックコンピューティング', 'Description': 'オートノミックコンピューティングは、システムが自己管理、自己設定、自己修復の能力を持つことを指します。'}, {'Keyword': 'マルチエージェントシステム', 'Description': 'マルチエージェントシステムは、複数の独立したエージェントが相互に協力し、目標を達成するために相互作用するシステムです。'}, {'Keyword': '自己適応', 'Description': '自己適応は、環境の変化に応じて自己を調整し、最適な状態に適応する能力を指します。'}, {'Keyword': 'コミュニケーション', 'Description': 'コミュニケーションは、情報や意見を伝えるための相互作用のプロセスです。人間だけでなく、コンピュータやエージェント間でも行われます。'}, {'Keyword': '言語モデル', 'Description': '言語モデルは、自然言語の文法や意味を表現するためのモデルです。機械翻訳や自動要約などの自然言語処理タスクに使用されます。'}]",18.300005197525024
http://arxiv.org/abs/2307.05782v1,Large Language Models,"Artificial intelligence is making spectacular progress, and one of the bestexamples is the development of large language models (LLMs) such as OpenAI'sGPT series. In these lectures, written for readers with a background inmathematics or physics, we give a brief history and survey of the state of theart, and describe the underlying transformer architecture in detail. We thenexplore some current ideas on how LLMs work and how models trained to predictthe next word in a text are able to perform other tasks displayingintelligence.","['Computation and Language', 'High Energy Physics - Theory', 'History and Overview', 'Computational Physics']",['Michael R. Douglas'],http://arxiv.org/pdf/2307.05782v1,2023-07-11 20:21:02+00:00,大規模言語モデル,人工知能は目覚ましい進歩を遂げているが、その最たる例の一つがOpenAIのGPTシリーズのような大規模言語モデル（LLM）の開発である。本講演では、数学または物理学のバックグラウンドを持つ読者向けに、その歴史と現状を簡単に説明し、基礎となる変換器アーキテクチャについて詳しく説明する。さらに、LLMがどのように機能するのか、また、テキストの次の単語を予測するように訓練されたモデルが、どのように知性を示す他のタスクを実行することができるのかについて、現在のアイデアをいくつか紹介する。,人工知能はすごい進化を遂げています。その中でも、OpenAIのGPTシリーズという大きな言語モデルの開発は特にすごいです。この講演では、数学や物理学に詳しくない人でもわかるように、その歴史や現状を簡単に説明します。そして、基礎となる変換器アーキテクチャについても詳しく説明します。さらに、この言語モデルはどのように機能し、次の単語を予測するだけでなく、他の知的なタスクもできるのかについて、いくつかのアイデアを紹介します。,"[{'Keyword': '人工知能', 'Description': '人工知能は、コンピューターシステムが人間のような知的なタスクを実行する能力を指します。'}, {'Keyword': '大規模言語モデル', 'Description': '大規模言語モデルは、膨大な量のテキストデータを学習して、自然言語処理のタスクを実行するためのモデルです。'}, {'Keyword': '変換器アーキテクチャ', 'Description': '変換器アーキテクチャは、入力データを変換して出力データを生成するための機械学習モデルの構造や設計を指します。'}, {'Keyword': '予測', 'Description': '予測は、過去のデータや現在の状況から将来の出来事や結果を推測することを指します。'}, {'Keyword': '知性', 'Description': '知性は、知識や理解、学習、推論、問題解決などの能力を持つことを指します。'}]",15.483277082443237
http://arxiv.org/abs/2307.07420v1,Named entity recognition using GPT for identifying comparable companies,"For both public and private firms, comparable companies analysis is widelyused as a method for company valuation. In particular, the method is of greatvalue for valuation of private equity companies. The several approaches to thecomparable companies method usually rely on a qualitative approach toidentifying similar peer companies, which tends to use established industryclassification schemes and/or analyst intuition and knowledge. However, morequantitative methods have started being used in the literature and in theprivate equity industry, in particular, machine learning clustering, andnatural language processing (NLP). For NLP methods, the process consists ofextracting product entities from e.g., the company's website or companydescriptions from some financial database system and then to perform similarityanalysis. Here, using companies descriptions/summaries from publicly availablecompanies' Wikipedia websites, we show that using large language models (LLMs),such as GPT from openaAI, has a much higher precision and success rate thanusing the standard named entity recognition (NER) which uses manual annotation.We demonstrate quantitatively a higher precision rate, and show that,qualitatively, it can be used to create appropriate comparable companies peergroups which can then be used for equity valuation.","['Computation and Language', 'Artificial Intelligence', 'Neural and Evolutionary Computing']",['Eurico Covas'],http://arxiv.org/pdf/2307.07420v1,2023-07-11 16:48:16+00:00,類似企業識別のためのGPTを用いた固有表現認識,類似企業比較分析は、公開企業、非公開企業を問わず、企業評価の手法として広く利用されている。特に、プライベート・エクイティ企業のバリュエーションにおいて大きな価値を持つ。類似会社比較法へのいくつかのアプローチは、通常、類似同業他社を特定するための定性的アプローチに依存しており、確立された業界分類スキームやアナリストの直感や知識を使用する傾向がある。しかし、文献やプライベート・エクイティ業界では、より定量的な手法、特に機械学習によるクラスタリングや自然言語処理（NLP）が使用され始めている。NLP法では、例えば企業のウェブサイトや金融データベース・システムからの企業説明から製品エンティティを抽出し、類似性分析を行う。ここでは、公開されている企業のウィキペディアのウェブサイトから企業の説明／要約を使用し、openaAIのGPTのような大規模言語モデル（LLM）を使用することで、手動アノテーションを使用する標準的な名前付きエンティティ認識（NER）を使用するよりもはるかに高い精度と成功率を持つことを示す。,似たような会社同士を比べる分析は、企業の評価方法として、上場している会社や非上場の会社を問わず、広く使われています。特に、プライベート・エクイティ（個人の資金を使って会社を買い取ること）の会社の価値を評価する際に役立ちます。類似会社比較法では、通常、似たような業界の他の会社を見つけるために、業界の分類やアナリストの知識を使って分析します。しかし、最近では、より数値的な手法が使われるようになってきました。例えば、機械学習や自然言語処理（NLP）を使って、企業のウェブサイトや金融データベースから情報を抽出し、類似性を分析します。この研究では、ウィキペディアの企業の説明を使って、大規模な言語モデルを使うことで、手動で行う通常の分析よりも高い精度で成功することを示しています。,"[{'Keyword': '類似企業比較分析', 'Description': '類似企業の比較分析'}, {'Keyword': 'プライベート・エクイティ企業', 'Description': 'プライベート・エクイティ企業'}, {'Keyword': '類似会社比較法', 'Description': '類似会社の比較法'}, {'Keyword': '機械学習', 'Description': '機械学習'}, {'Keyword': '自然言語処理', 'Description': '自然言語処理'}]",14.32583212852478
http://arxiv.org/abs/2307.05081v1,Argumentative Segmentation Enhancement for Legal Summarization,"We use the combination of argumentative zoning [1] and a legal argumentativescheme to create legal argumentative segments. Based on the argumentativesegmentation, we propose a novel task of classifying argumentative segments oflegal case decisions. GPT-3.5 is used to generate summaries based onargumentative segments. In terms of automatic evaluation metrics, our methodgenerates higher quality argumentative summaries while leaving out lessrelevant context as compared to GPT-4 and non-GPT models.",['Computation and Language'],"['Huihui Xu', 'Kevin Ashley']",http://arxiv.org/pdf/2307.05081v1,2023-07-11 07:29:18+00:00,法的要約のための論証的セグメンテーションの強化,本稿では、論証ゾーニング[1]と法的論証スキームを組み合わせて、法的論証セグメントを作成する。このargumentative segmentationに基づき、判例のargumentative segmentを分類するという新しいタスクを提案する。GPT-3.5は論証セグメントに基づいて要約を生成するために使用される。自動評価指標の観点から、本手法はGPT-4や非GPTモデルと比較して、関連性の低い文脈を省きつつ、より質の高い論証的要約を生成する。,この論文では、法律の議論を分ける方法と、それを使って判例を分類する方法について説明しています。そして、GPT-3.5というコンピュータプログラムを使って、法律の要点をまとめる方法も提案しています。この方法は、他のプログラムと比べて、関係のない部分を省いて、より良いまとめができると評価されています。,"[{'Keyword': '論証ゾーニング', 'Description': '論証ゾーニングは、論証をセグメントに分割する手法です。'}, {'Keyword': '法的論証スキーム', 'Description': '法的論証スキームは、法的論証を構造化するための枠組みです。'}, {'Keyword': 'argumentative segmentation', 'Description': 'argumentative segmentationは、判例の論証セグメントを分類するタスクです。'}, {'Keyword': 'GPT-3.5', 'Description': 'GPT-3.5は、論証セグメントに基づいて要約を生成するために使用されるモデルです。'}, {'Keyword': '論証的要約', 'Description': '論証的要約は、関連性の高い文脈を省きつつ、質の高い要約を生成することです。'}]",18.322428226470947
http://arxiv.org/abs/2307.05628v1,DNAGPT: A Generalized Pretrained Tool for Multiple DNA Sequence Analysis Tasks,"The success of the GPT series proves that GPT can extract general informationfrom sequences, thereby benefiting all downstream tasks. This motivates us touse pre-trained models to explore the hidden information in DNA sequences.However, data and task requirements in DNA sequence analysis are complexity anddiversity as DNA relevant data includes different types of information, such assequences, expression levels, etc, while there is currently no modelspecifically designed for these characteristics. Hereby, we present DNAGPT, ageneralized foundation model pre-trained on over 10 billion base pairs from 9species which can be fine-tuned for any DNA sequence analysis task. Our modelcan simultaneously process or output DNA sequences and numbers. In addition,our unique token design allows users to design prompts according to their owntask requirements, making it applicable to any type of task. We have evaluatedour model on classification, regression, and generation tasks. We demonstratethat DNAGPT benefits from pre-training, and therefore can bring performancegains to any downstream task. Our model is not only a new attempt in the fieldof genomes analysis, but also provides a new direction for the application offoundation models in biology.","['Genomics', 'Machine Learning']","['Daoan Zhang', 'Weitong Zhang', 'Bing He', 'Jianguo Zhang', 'Chenchen Qin', 'Jianhua Yao']",http://arxiv.org/pdf/2307.05628v1,2023-07-11 06:30:43+00:00,DNAGPT：複数のDNA配列解析タスクのための一般化された事前学習ツール,GPTシリーズの成功は、GPTが配列から一般的な情報を抽出できることを証明しており、それによって下流のすべてのタスクに利益をもたらす。しかし、DNA配列解析におけるデータおよびタスクの要件は、DNA関連データには配列、発現レベルなどの様々なタイプの情報が含まれるため、複雑かつ多様である。本論文では、9種100億塩基対以上で事前学習された一般化基礎モデルDNAGPTを紹介する。このモデルはDNA配列と数値を同時に処理・出力することができる。また、独自のトークン設計により、ユーザは自分のタスク要件に応じてプロンプトを設計することができ、あらゆるタイプのタスクに適用可能です。このモデルを分類、回帰、生成タスクで評価した。その結果、DNAGPTは事前学習から恩恵を受け、あらゆる下流タスクに性能向上をもたらすことが実証された。我々のモデルは、ゲノム解析の分野での新しい試みであるだけでなく、生物学における基礎モデルの応用に新しい方向性を与えるものである。,GPTシリーズは、すごいモデルで、いろんな情報を抽出できるんだ。それができるおかげで、たくさんのタスクがうまくできるようになるんだよ。でも、DNAのデータを解析するときは、いろんな情報が含まれていて、ちょっと難しいんだ。この論文では、DNAのモデル「DNAGPT」を紹介するよ。このモデルは、DNAの情報と数字を一緒に処理できるんだ。それに、ユーザーは自分のタスクに合わせてプロンプトを作ることができるから、いろんなタスクに使えるんだ。このモデルは、いろんなタスクで試してみたよ。その結果、DNAGPTはすごく役に立って、どんなタスクでもうまくできることがわかったんだ。このモデルは、ゲノム解析の分野で新しい試みだけじゃなくて、生物学の基礎モデルにも新しい方向性をもたらすんだよ。,"[{'Keyword': 'GPTシリーズ', 'Description': 'GPTシリーズは、自然言語処理のための先進的なモデルです。'}, {'Keyword': 'DNA配列解析', 'Description': 'DNA配列解析は、DNAの情報を解読し、意味を理解するプロセスです。'}, {'Keyword': 'DNAGPT', 'Description': 'DNAGPTは、GPTシリーズを用いたDNA配列解析の手法です。'}, {'Keyword': 'プロンプト', 'Description': 'プロンプトは、GPTシリーズに与えられる入力の一部であり、タスクの指示を与えます。'}, {'Keyword': 'ゲノム解析', 'Description': 'ゲノム解析は、生物のゲノム情報を解析し、遺伝子の機能や関連性を調査するプロセスです。'}]",12.767341136932373
http://arxiv.org/abs/2307.04858v1,AmadeusGPT: a natural language interface for interactive animal behavioral analysis,"The process of quantifying and analyzing animal behavior involves translatingthe naturally occurring descriptive language of their actions intomachine-readable code. Yet, codifying behavior analysis is often challengingwithout deep understanding of animal behavior and technical machine learningknowledge. To limit this gap, we introduce AmadeusGPT: a natural languageinterface that turns natural language descriptions of behaviors intomachine-executable code. Large-language models (LLMs) such as GPT3.5 and GPT4allow for interactive language-based queries that are potentially well suitedfor making interactive behavior analysis. However, the comprehension capabilityof these LLMs is limited by the context window size, which prevents it fromremembering distant conversations. To overcome the context window limitation,we implement a novel dual-memory mechanism to allow communication betweenshort-term and long-term memory using symbols as context pointers for retrievaland saving. Concretely, users directly use language-based definitions ofbehavior and our augmented GPT develops code based on the core AmadeusGPT API,which contains machine learning, computer vision, spatio-temporal reasoning,and visualization modules. Users then can interactively refine results, andseamlessly add new behavioral modules as needed. We benchmark AmadeusGPT andshow we can produce state-of-the-art performance on the MABE 2022 behaviorchallenge tasks. Note, an end-user would not need to write any code to achievethis. Thus, collectively AmadeusGPT presents a novel way to merge deepbiological knowledge, large-language models, and core computer vision modulesinto a more naturally intelligent system. Code and demos can be found at:https://github.com/AdaptiveMotorControlLab/AmadeusGPT.","['Human-Computer Interaction', 'Computer Vision and Pattern Recognition', 'Neurons and Cognition']","['Shaokai Ye', 'Jessy Lauer', 'Mu Zhou', 'Alexander Mathis', 'Mackenzie W. Mathis']",http://arxiv.org/pdf/2307.04858v1,2023-07-10 19:15:17+00:00,AmadeusGPT：対話型動物行動分析のための自然言語インターフェース,動物の行動を定量化し分析するプロセスでは、自然界に存在する動物の行動の記述言語を、機械が読み取り可能なコードに変換する必要がある。しかし、行動分析をコード化することは、動物の行動に対する深い理解と機械学習の技術的知識がなければ困難な場合が多い。このギャップをなくすために、我々はAmadeusGPTを紹介する。AmadeusGPTは、行動の自然言語記述を機械で実行可能なコードに変換する自然言語インターフェースである。GPT3.5やGPT4のような大規模言語モデル（LLM）は、対話的な言語ベースのクエリーを可能にし、対話的な行動分析を行うのに適している可能性があります。しかし、これらのLLMの理解能力はコンテキストウィンドウのサイズによって制限されており、遠くの会話を記憶することができない。コンテキストウィンドウの制限を克服するために、我々は、検索と保存のためのコンテキストポインタとしてシンボルを用いて、短期記憶と長期記憶の間の通信を可能にする新しいデュアルメモリ機構を実装する。具体的には、ユーザーは言語ベースの行動定義を直接使用し、我々の拡張GPTは、機械学習、コンピュータビジョン、時空間推論、および視覚化モジュールを含むコアAmadeusGPT APIに基づいてコードを開発します。ユーザーは結果をインタラクティブに改良し、必要に応じて新しい行動モジュールをシームレスに追加することができます。AmadeusGPT のベンチマークを行い、MABE 2022 ビヘイビアチャレンジタスクで最先端のパフォーマンスを発揮できることを示しました。なお、エンドユーザーはこれを達成するためにコードを書く必要はありません。このように、アマデウスGPTは、深い生物学的知識、大規模な言語モデル、およびコアコンピュータビジョンモジュールを、より自然なインテリジェントシステムに統合する新しい方法を提示しています。コードとデモはhttps://github.com/AdaptiveMotorControlLab/AmadeusGPT。,動物の行動を調べるためには、動物の行動をコンピュータが理解できるコードに変換する必要があります。しかし、それは難しいことです。そのため、私たちはAmadeusGPTという新しいシステムを開発しました。AmadeusGPTは、人間の言葉で動物の行動を説明することができるシステムです。大きな言語モデルを使って、私たちのシステムは対話的に質問に答えたり、行動を分析したりすることができます。しかし、このシステムには制限もあります。遠い過去のことを覚えることはできません。そのため、私たちは新しいメモリ機能を開発しました。これにより、長期的な情報を保持しながら、対話的に行動を分析することができます。私たちのシステムは、機械学習やコンピュータビジョンなどのモジュールを組み合わせて動作します。ユーザーはこのシステムを使って、動物の行動を研究したり、新しい行動モジュールを追加したりすることができます。私たちのシステムは、MABE 2022 ビヘイビアチャレンジタスクで優れたパフォーマンスを発揮しました。エンドユーザーはコードを書く必要はありません。AmadeusGPTは、生物学の知識や言語モデル、コンピュータビジョンなどを組み合わせて、より自然なインテリジェントシステムを作るための新しい方法を提案しています。詳しくはhttps://github.com/AdaptiveMotorControlLab/AmadeusGPTをご覧ください。,"[{'Keyword': '行動分析', 'Description': '行動を定量化し分析するプロセス'}, {'Keyword': '自然言語インターフェース', 'Description': '行動の自然言語記述を機械で実行可能なコードに変換するインターフェース'}, {'Keyword': '大規模言語モデル', 'Description': 'GPT3.5やGPT4のような大規模な言語モデル'}, {'Keyword': 'コンテキストウィンドウ', 'Description': 'LLMの理解能力が制限されるコンテキストの範囲'}, {'Keyword': 'デュアルメモリ機構', 'Description': '短期記憶と長期記憶の間の通信を可能にする機構'}]",19.92951774597168
http://arxiv.org/abs/2307.04346v1,Can Large Language Models Write Good Property-Based Tests?,"Property-based testing (PBT), while an established technique in the softwaretesting research community, is still relatively underused in real-worldsoftware. Pain points in writing property-based tests include implementingdiverse random input generators and thinking of meaningful properties to test.Developers, however, are more amenable to writing documentation; plenty oflibrary API documentation is available and can be used as natural languagespecifications for property-based tests. As large language models (LLMs) haverecently shown promise in a variety of coding tasks, we explore the potentialof using LLMs to synthesize property-based tests. We call our approach PBT-GPT,and propose three different strategies of prompting the LLM for PBT. Wecharacterize various failure modes of PBT-GPT and detail an evaluationmethodology for automatically synthesized property-based tests. PBT-GPTachieves promising results in our preliminary studies on sample Python libraryAPIs in $\texttt{numpy}$, $\texttt{networkx}$, and $\texttt{datetime}$.",['Software Engineering'],"['Vasudev Vikram', 'Caroline Lemieux', 'Rohan Padhye']",http://arxiv.org/pdf/2307.04346v1,2023-07-10 05:09:33+00:00,大規模言語モデルは優れた特性テストを書けるか？,プロパティベースのテスト（PBT）は、ソフトウェアテストの研究コミュニティでは確立された手法ですが、実世界のソフトウェアではまだあまり使われていません。しかし、開発者は、ドキュメントを書くことに従順である。多くのライブラリAPIドキュメントが利用可能であり、プロパティベースのテストのための自然言語仕様として使用することができる。最近、大規模言語モデル（LLM）が様々なコーディングタスクにおいて有望であることが示されたので、我々は、プロパティベースのテストを合成するためにLLMを使用する可能性を探る。我々のアプローチをPBT-GPTと呼び、PBTのためにLLMを促す3つの異なる戦略を提案する。PBT-GPTの様々な失敗モードを特徴付け、自動的に合成された特性ベースのテストの評価方法を詳述する。PBT-GPTは、$texttt{numpy}$、$texttt{networkx}$、$texttt{datetime}$のサンプルPythonライブラリAPIに対する予備研究で有望な結果を得た。,プロパティベースのテスト（PBT）は、ソフトウェアのテスト方法の一つです。でも、まだあまり使われていないんだよ。でも、開発者はドキュメントを書くのが得意なんだ。たくさんのドキュメントがあって、それを使ってプロパティベースのテストをすることができるんだよ。最近、大規模な言語モデル（LLM）がいろんなコーディングの仕事に使えることがわかったから、PBTにも使えるかもしれないって研究しているんだ。私たちのアプローチをPBT-GPTと呼んで、3つの異なる戦略を提案しているよ。PBT-GPTのいろんな失敗の仕方を調べて、自動的に作られたテストの評価方法も詳しく説明しているんだ。PBT-GPTは、numpyやnetworkx、datetimeというPythonのライブラリに対して、予備研究でいい結果が出たんだ。,"[{'Keyword': 'プロパティベースのテスト', 'Description': 'プロパティベースのテストは、プログラムの特性や振る舞いをテストする手法です。ランダムな入力を生成し、プロパティが満たされているかどうかを検証します。'}, {'Keyword': 'ソフトウェアテスト', 'Description': 'ソフトウェアテストは、ソフトウェアの品質を確保するために行われる活動です。機能やパフォーマンスなどの要件を満たしているかを検証し、問題を特定して修正します。'}, {'Keyword': '自然言語仕様', 'Description': '自然言語仕様は、人間が理解しやすい形式でソフトウェアの要件や仕様を記述する方法です。自然言語を使用することで、開発者と利害関係者のコミュニケーションを円滑にし、誤解やミスを防ぎます。'}, {'Keyword': '大規模言語モデル', 'Description': '大規模言語モデルは、膨大な量のテキストデータを学習して生成される言語モデルです。自然言語処理のタスクにおいて高い性能を発揮し、文章生成や機械翻訳などに利用されます。'}, {'Keyword': '特性ベースのテスト', 'Description': '特性ベースのテストは、ソフトウェアの特性や要件をテストケースとして定義し、それに基づいてテストを実施する手法です。特性の正確性や完全性を確認することで、ソフトウェアの品質を向上させます。'}]",22.269875049591064
http://arxiv.org/abs/2307.03489v1,Every non-signalling channel is common-cause realizable,"In this work we show that the set of non-signalling resources of alocally-tomographic generalised probabilistic theory (GPT), such as quantum andclassical theory, coincides with its set of GPT-common-cause realizableresources, where the common causes come from an associated GPT. From a causalperspective, this result provides a reason for, in the study of resourcetheories of common-cause processes, taking the non-signalling channels as theresources of the enveloping theory. This answers a critical open question inRef.~\cite{schmid2020postquantum}. An immediate corollary of our result is thatevery non-signalling assemblage is realizable in a GPT, answering in theaffirmative the question posed in Ref.~\cite{cavalcanti2022post}.",['Quantum Physics'],"['Paulo J. Cavalcanti', 'John H. Selby', 'Ana Belén Sainz']",http://arxiv.org/pdf/2307.03489v1,2023-07-07 09:56:14+00:00,すべての非シグナリングチャネルは共通原因実現可能,本研究では、量子論や古典論のような局所的トモグラフィーの一般化確率論(GPT)の非シグナリング資源の集合は、GPT-共通原因実現可能資源の集合と一致することを示す。この結果は、因果論的な観点から、共通原因過程のリソース理論の研究において、非シグナリングチャネルを包絡理論のリソースとする理由を与える。これは、Ref.~cite{schmid2020postquantum}における重要な未解決問題の答えである。この結果の直接的な帰結は、すべての非シグナリング集合がGPTで実現可能であるということであり、Ref.~cite{cavalcanti2022post}で提起された疑問の肯定的な答えとなります。,この研究では、量子力学や古典物理学のようなものを一般化した確率の理論（GPT）において、特定の方法で情報を送ることができるリソースの集合があります。このリソースの集合は、共通の原因によって起こる現象を説明することができます。この研究の結果は、非常に重要で、どのようなリソースを使っても情報を送ることができることを示しています。これは、以前の研究で提起された疑問に対する肯定的な答えとなります。,"[{'Keyword': '局所的トモグラフィー', 'Description': '局所的トモグラフィーは、量子論や古典論のような物理理論において、局所的な操作と測定によって系の状態を特定する手法です。'}, {'Keyword': '一般化確率論', 'Description': '一般化確率論（Generalized Probabilistic Theories, GPT）は、量子論や古典論を含むあらゆる物理理論を統一的に記述する枠組みです。'}, {'Keyword': '非シグナリング資源', 'Description': '非シグナリング資源は、情報の伝達においてシグナリング（信号の送信）を行わない資源のことであり、量子通信や量子情報処理において重要な役割を果たします。'}, {'Keyword': '共通原因実現可能資源', 'Description': '共通原因実現可能資源は、因果論的な観点から、共通原因過程のリソース理論において使用される資源の集合です。'}, {'Keyword': '包絡理論', 'Description': '包絡理論は、物理現象を包絡するような理論であり、非シグナリングチャネルを包絡理論のリソースとして扱います。'}]",32.68080377578735
http://arxiv.org/abs/2307.03351v1,Augmented Reality for Maintenance Tasks with ChatGPT for Automated Text-to-Action,"Advancements in sensor technology, artificial intelligence (AI), andaugmented reality (AR) have unlocked opportunities across various domains. ARand large language models like GPT have witnessed substantial progress and areincreasingly being employed in diverse fields. One such promising applicationis in operations and maintenance (O&M). O&M tasks often involve complexprocedures and sequences that can be challenging to memorize and executecorrectly, particularly for novices or under high-stress situations. Bymarrying the advantages of superimposing virtual objects onto the physicalworld, and generating human-like text using GPT, we can revolutionize O&Moperations. This study introduces a system that combines AR, Optical CharacterRecognition (OCR), and the GPT language model to optimize user performancewhile offering trustworthy interactions and alleviating workload in O&M tasks.This system provides an interactive virtual environment controlled by the Unitygame engine, facilitating a seamless interaction between virtual and physicalrealities. A case study (N=15) is conducted to illustrate the findings andanswer the research questions. The results indicate that users can completesimilarly challenging tasks in less time using our proposed AR and AI system.Moreover, the collected data also suggests a reduction in cognitive load and anincrease in trust when executing the same operations using the AR and AIsystem.",['Human-Computer Interaction'],"['Fang Xu', 'Tri Nguyen', 'Jing Du']",http://arxiv.org/pdf/2307.03351v1,2023-07-07 02:18:17+00:00,ChatGPTによるテキストからアクションへの自動化により、メンテナンスタスクの拡張現実を実現,センサー技術、人工知能(AI)、拡張現実(AR)の進歩は、様々な領域でチャンスを引き出している。ARやGPTのような大規模言語モデルは大きな進歩を遂げ、様々な分野で採用されるようになってきている。そのような有望なアプリケーションの1つは、運用と保守（O&M）である。O&Mタスクは、複雑な手順やシーケンスを含むことが多く、特に初心者や高ストレス状況下では、記憶し、正しく実行することが困難な場合がある。物理世界に仮想物体を重ね合わせ、GPTを用いて人間のようなテキストを生成するという利点を生かすことで、O&M業務に革命をもたらすことができる。本研究では、AR、光学式文字認識(OCR)、GPT言語モデルを組み合わせることで、ユーザのパフォーマンスを最適化しつつ、信頼できるインタラクションを提供し、O&M作業における作業負荷を軽減するシステムを紹介する。このシステムは、Unitygameエンジンによって制御されるインタラクティブな仮想環境を提供し、仮想現実と物理現実の間のシームレスなインタラクションを促進する。本システムは、Unityゲームエンジンによって制御されるインタラクティブな仮想環境を提供し、仮想現実と物理現実のシームレスなインタラクションを促進する。その結果、提案するAR・AIシステムを用いることで、ユーザはより短時間で同様の難易度のタスクを完了できることが示された。さらに、収集されたデータは、AR・AIシステムを用いて同じ操作を実行した場合の認知負荷の軽減と信頼感の増加も示唆している。,センサー技術、人工知能(AI)、拡張現実(AR)の進歩は、いろんな分野で新しいチャンスを作っています。ARやGPTのような言語モデルは、大きく進化し、いろんな場所で使われるようになりました。その中でも、運用と保守（O&M）という仕事には特に使えるんです。O&Mの仕事は、難しい手順や順番がたくさんあって、初心者やストレスのある状況では、覚えるのも実行するのも難しいことがあります。でも、ARを使って仮想のものを現実のものと重ね合わせたり、GPTを使って人間みたいなテキストを作ったりすることで、O&Mの仕事がとても楽になるんですよ。この研究では、AR、光学式文字認識(OCR)、GPT言語モデルを組み合わせたシステムを紹介します。このシステムは、ユーザーのパフォーマンスを良くしながら、信頼できるやり取りを提供し、O&Mの負担を減らすことができます。このシステムは、Unityというゲームエンジンを使って、仮想の環境を作り出し、仮想の世界と現実の世界の間でスムーズにやり取りできるようにします。このAR・AIシステムを使うと、ユーザーは同じ難しい仕事でも短い時間で終わらせることができました。また、収集したデータからも、このAR・AIシステムを使うと、仕事の負担が減り、信頼感が増すことが分かりました。,"[{'Keyword': 'センサー技術', 'Description': 'センサー技術は、物理的な環境からデータを収集し、それを解釈する技術です。センサーは、温度、湿度、位置などの情報を検出することができます。'}, {'Keyword': '人工知能', 'Description': '人工知能（AI）は、コンピューターシステムが人間のように知識を獲得し、問題を解決する能力を持つことを指します。AIは、自動運転、音声認識、画像分類などのさまざまなタスクに使用されています。'}, {'Keyword': '拡張現実', 'Description': '拡張現実（AR）は、現実の環境に仮想の要素を重ねる技術です。ARは、スマートフォンやヘッドセットを使用して、情報の表示やインタラクションを提供します。'}, {'Keyword': '大規模言語モデル', 'Description': '大規模言語モデルは、膨大な量のテキストデータを学習し、自然言語処理のタスクを実行するためのモデルです。これにより、文章生成、機械翻訳、質問応答などのタスクが可能になります。'}, {'Keyword': '光学式文字認識', 'Description': '光学式文字認識（OCR）は、印刷されたテキストをデジタルデータに変換する技術です。OCRは、スキャンやカメラで撮影した文書を解析し、テキストを抽出します。'}]",23.161049127578735
http://arxiv.org/abs/2307.03027v1,Improving Retrieval-Augmented Large Language Models via Data Importance Learning,"Retrieval augmentation enables large language models to take advantage ofexternal knowledge, for example on tasks like question answering and dataimputation. However, the performance of such retrieval-augmented models islimited by the data quality of their underlying retrieval corpus. In thispaper, we propose an algorithm based on multilinear extension for evaluatingthe data importance of retrieved data points. There are exponentially manyterms in the multilinear extension, and one key contribution of this paper is apolynomial time algorithm that computes exactly, given a retrieval-augmentedmodel with an additive utility function and a validation set, the dataimportance of data points in the retrieval corpus using the multilinearextension of the model's utility function. We further proposed an even moreefficient ({\epsilon}, {\delta})-approximation algorithm. Our experimentalresults illustrate that we can enhance the performance of large language modelsby only pruning or reweighting the retrieval corpus, without requiring furthertraining. For some tasks, this even allows a small model (e.g., GPT-JT),augmented with a search engine API, to outperform GPT-3.5 (without retrievalaugmentation). Moreover, we show that weights based on multilinear extensioncan be computed efficiently in practice (e.g., in less than ten minutes for acorpus with 100 million elements).","['Machine Learning', 'Computation and Language', 'Information Retrieval']","['Xiaozhong Lyu', 'Stefan Grafberger', 'Samantha Biegel', 'Shaopeng Wei', 'Meng Cao', 'Sebastian Schelter', 'Ce Zhang']",http://arxiv.org/pdf/2307.03027v1,2023-07-06 14:44:07+00:00,データ重要度学習による検索支援大規模言語モデルの改善,"検索補強は、例えば質問応答やデータ入力のようなタスクにおいて、大規模な言語モデルが外部の知識を利用することを可能にする。しかし、このような検索補強モデルの性能は、その基礎となる検索コーパスのデータ品質によって制限される。本論文では、検索されたデータ点のデータ重要度を評価するための、多重線形拡張に基づくアルゴリズムを提案する。多直線拡張には指数関数的に多くの項があり、本論文の重要な貢献の一つは、加法的効用関数を持つ検索補遺モデルと検証集合が与えられた場合に、モデルの効用関数の多直線拡張を用いて、検索コーパス中のデータ点のデータ重要度を正確に計算する多項式時間アルゴリズムである。さらに、さらに効率的な({epsilon}, {δ})近似アルゴリズムを提案した。我々の実験結果は、更なる学習を必要とせず、検索コーパスの刈り込みや重み付けを行うだけで、大規模言語モデルの性能を向上できることを示している。いくつかのタスクでは、これにより、検索エンジンAPIで拡張された小さなモデル（例えばGPT-JT）が、GPT-3.5（検索拡張なし）を上回ることさえできる。さらに、マルチリニア拡張に基づく重みは、実際に効率的に計算できることを示す（例えば、1億の要素を持つコーパスでは10分以内）。",検索補強とは、質問応答やデータ入力などの仕事で、大きな言語モデルが外部の知識を使うことができるようにすることです。でも、その性能は使うデータの品質によって制限されます。この論文では、データの重要度を評価するための新しい方法を提案しています。この方法を使うと、データの重要度を正確に計算することができます。さらに、効率的な方法も提案しています。実験の結果、この方法を使うと大きな言語モデルの性能が向上することがわかりました。いくつかの仕事では、小さなモデルでも大きなモデルよりも優れた結果が得られることもあります。また、この方法は実際に効率的に計算することができます。,"[{'Keyword': '検索補強', 'Description': '検索補強は、検索結果を改善するために使用される手法です。追加の情報やフィードバックを利用して、ユーザーの検索クエリに関連する結果を提供します。'}, {'Keyword': '言語モデル', 'Description': '言語モデルは、自然言語処理のための統計的なモデルです。文の生成や文の意味解析などのタスクに使用されます。'}, {'Keyword': '検索コーパス', 'Description': '検索コーパスは、検索エンジンのデータベースに格納されている文書の集合です。検索結果のランキングや情報検索のために使用されます。'}, {'Keyword': '多重線形拡張', 'Description': '多重線形拡張は、線形モデルを拡張して非線形な関係をモデル化する手法です。特徴量の組み合わせを考慮して、より高度な予測を行います。'}, {'Keyword': '効用関数', 'Description': '効用関数は、意思決定理論で使用される関数です。選択肢の価値を数値化し、最適な選択肢を決定するために使用されます。'}]",18.916386127471924
http://arxiv.org/abs/2307.04683v1,"CORE-GPT: Combining Open Access research and large language models for credible, trustworthy question answering","In this paper, we present CORE-GPT, a novel question-answering platform thatcombines GPT-based language models and more than 32 million full-text openaccess scientific articles from CORE. We first demonstrate that GPT3.5 and GPT4cannot be relied upon to provide references or citations for generated text. Wethen introduce CORE-GPT which delivers evidence-based answers to questions,along with citations and links to the cited papers, greatly increasing thetrustworthiness of the answers and reducing the risk of hallucinations.CORE-GPT's performance was evaluated on a dataset of 100 questions covering thetop 20 scientific domains in CORE, resulting in 100 answers and links to 500relevant articles. The quality of the provided answers and and relevance of thelinks were assessed by two annotators. Our results demonstrate that CORE-GPTcan produce comprehensive and trustworthy answers across the majority ofscientific domains, complete with links to genuine, relevant scientificarticles.","['Computation and Language', 'Artificial Intelligence']","['David Pride', 'Matteo Cancellieri', 'Petr Knoth']",http://arxiv.org/pdf/2307.04683v1,2023-07-06 13:41:36+00:00,CORE-GPT：オープンアクセスリサーチと大規模言語モデルを組み合わせて、信頼できる質問応答を実現する,"この論文では、GPTベースの言語モデルとCOREにある3,200万件以上のフルテキストのオープンアクセス科学論文を組み合わせた新しい質問応答プラットフォームであるCORE-GPTを紹介する。まず、GPT3.5とGPT4は、生成されたテキストの参考文献や引用文献を提供するのに信頼できないことを示す。CORE-GPTの性能は、COREの上位20の科学領域をカバーする100の質問からなるデータセットで評価され、その結果、100の回答と500の関連論文へのリンクが得られた。提供された回答の品質とリンクの関連性は、2人のアノテーターによって評価された。その結果、CORE-GPTは、大半の科学的ドメインにおいて、包括的で信頼できる回答を、本物の関連する科学論文へのリンクとともに作成できることが実証された。","この論文では、新しい質問応答プラットフォームであるCORE-GPTについて紹介します。CORE-GPTは、GPTベースの言語モデルと3,200万件以上の科学論文を組み合わせています。GPT3.5とGPT4は、生成されたテキストの参考文献や引用文献が信頼できないことを示しています。CORE-GPTの性能は、100の質問からなるデータセットで評価されました。その結果、100の回答と500の関連論文へのリンクが得られました。アノテーターによる評価では、CORE-GPTは多くの科学の分野で信頼できる回答を提供し、本物の科学論文へのリンクも作成できることが実証されました。","[{'Keyword': 'GPTベースの言語モデル', 'Description': 'GPT（Generative Pre-trained Transformer）とは、自然言語処理のタスクにおいて高い性能を発揮するニューラルネットワークモデルの一つです。'}, {'Keyword': 'オープンアクセス科学論文', 'Description': '誰でも自由にアクセスできるように公開された科学論文のことです。'}, {'Keyword': '質問応答プラットフォーム', 'Description': 'ユーザーが質問を投げるとそれに対して適切な回答を生成するシステムやサービスのことです。'}, {'Keyword': '参考文献', 'Description': '論文や書籍などの情報源を引用する際に参照する文献のことです。'}, {'Keyword': '関連論文', 'Description': '特定の研究テーマや論文と関連性のある他の論文のことです。'}]",25.48907995223999
http://arxiv.org/abs/2307.02779v1,Large Language Models Empowered Autonomous Edge AI for Connected Intelligence,"The evolution of wireless networks gravitates towards connected intelligence,a concept that envisions seamless interconnectivity among humans, objects, andintelligence in a hyper-connected cyber-physical world. Edge AI emerges as apromising solution to achieve connected intelligence by deliveringhigh-quality, low-latency, and privacy-preserving AI services at the networkedge. In this article, we introduce an autonomous edge AI system thatautomatically organizes, adapts, and optimizes itself to meet users' diverserequirements. The system employs a cloud-edge-client hierarchical architecture,where the large language model, i.e., Generative Pretrained Transformer (GPT),resides in the cloud, and other AI models are co-deployed on devices and edgeservers. By leveraging the powerful abilities of GPT in language understanding,planning, and code generation, we present a versatile framework thatefficiently coordinates edge AI models to cater to users' personal demandswhile automatically generating code to train new models via edge federatedlearning. Experimental results demonstrate the system's remarkable ability toaccurately comprehend user demands, efficiently execute AI models with minimalcost, and effectively create high-performance AI models through federatedlearning.","['Information Theory', 'Machine Learning', 'Networking and Internet Architecture', 'Signal Processing', 'Information Theory']","['Yifei Shen', 'Jiawei Shao', 'Xinjie Zhang', 'Zehong Lin', 'Hao Pan', 'Dongsheng Li', 'Jun Zhang', 'Khaled B. Letaief']",http://arxiv.org/pdf/2307.02779v1,2023-07-06 05:16:55+00:00,コネクテッド・インテリジェンスのための大規模言語モデルによる自律的エッジAI,ワイヤレス・ネットワークの進化はコネクテッド・インテリジェンス（超接続型サイバー・フィジカル世界における人間、モノ、インテリジェンス間のシームレスな相互接続を想定したコンセプト）に向かっています。エッジAIは、高品質、低遅延、プライバシー保護AIサービスをネットワークエッジで提供することで、コネクテッド・インテリジェンスを実現する有望なソリューションとして浮上している。本稿では、ユーザーの多様な要求を満たすために、自動的に組織化、適応、最適化を行う自律型エッジAIシステムを紹介する。このシステムは、クラウド-エッジ-クライアントの階層型アーキテクチャを採用しており、大規模な言語モデルであるGenerative Pretrained Transformer (GPT)はクラウドに存在し、その他のAIモデルはデバイスやエッジサーバーに共同配置される。言語理解、プランニング、コード生成におけるGPTの強力な能力を活用することで、エッジ連携学習によって新しいモデルを学習するためのコードを自動生成しながら、ユーザーの個人的な要求に応えるためにエッジAIモデルを効率的に調整する汎用的なフレームワークを提示する。実験結果は、システムがユーザの要求を正確に理解し、最小限のコストでAIモデルを効率的に実行し、連携学習を通じて高性能AIモデルを効率的に作成する顕著な能力を実証している。,ワイヤレス・ネットワークは、人々や物とつながる未来の世界を作るために進化しています。エッジAIという技術は、高品質で遅延が少なく、個人情報も守れるAIサービスを提供することで、この未来の世界を実現するための有望な解決策として注目されています。この記事では、さまざまな人々の要求に応えるために、自動的に順応し最適な結果を出すエッジAIシステムについて紹介します。このシステムは、クラウド、エッジサーバー、そしてデバイスという階層構造を持っており、大きな言語モデルはクラウドにあり、他のAIモデルはデバイスやエッジサーバーに入っています。言語理解や計画立案、コード生成などの能力を持つ言語モデルを活用しながら、新しいモデルを学習するためのコードを自動生成し、ユーザーの要求に合わせてエッジAIモデルを調整する方法を提案します。実験の結果、このシステムはユーザーの要求を正確に理解し、最小限のコストで効率的にAIモデルを実行し、高性能なAIモデルを作ることができることがわかりました。,"[{'Keyword': 'ワイヤレス・ネットワーク', 'Description': 'ワイヤレス・ネットワークは、ケーブルや有線接続を使用せずにデータを送受信するネットワークです。無線通信技術を利用して、携帯電話やWi-Fiなどのデバイスがインターネットに接続されます。'}, {'Keyword': 'コネクテッド・インテリジェンス', 'Description': 'コネクテッド・インテリジェンスは、インターネットを介して接続されたデバイスやシステムが自動的に情報を共有し、協調して動作する能力を指します。これにより、効率的なデータ収集や分析、意思決定が可能になります。'}, {'Keyword': 'エッジAI', 'Description': 'エッジAIは、デバイスやセンサーなどのエッジ（端末）でAI（人工知能）を実行する技術です。エッジAIは、リアルタイムのデータ処理や低遅延の応答を可能にし、クラウドへのデータ転送量を削減します。'}, {'Keyword': 'クラウド-エッジ-クライアントの階層型アーキテクチャ', 'Description': 'クラウド-エッジ-クライアントの階層型アーキテクチャは、クラウド、エッジ（端末）、クライアント（ユーザー）の3つのレベルでデータ処理とアプリケーション実行を分散するアーキテクチャです。これにより、効率的なデータ処理と低遅延の応答が実現されます。'}, {'Keyword': 'Generative Pretrained Transformer (GPT)', 'Description': 'Generative Pretrained Transformer（GPT）は、自然言語処理のための深層学習モデルです。大量のテキストデータを学習し、文章の生成や翻訳、要約などのタスクに使用されます。GPTは、高い表現力と柔軟性を持ち、さまざまな自然言語処理の問題に適用できます。'}]",27.141987085342407
http://arxiv.org/abs/2307.02514v1,Exploring Multimodal Approaches for Alzheimer's Disease Detection Using Patient Speech Transcript and Audio Data,"Alzheimer's disease (AD) is a common form of dementia that severely impactspatient health. As AD impairs the patient's language understanding andexpression ability, the speech of AD patients can serve as an indicator of thisdisease. This study investigates various methods for detecting AD usingpatients' speech and transcripts data from the DementiaBank Pitt database. Theproposed approach involves pre-trained language models and Graph Neural Network(GNN) that constructs a graph from the speech transcript, and extracts featuresusing GNN for AD detection. Data augmentation techniques, including synonymreplacement, GPT-based augmenter, and so on, were used to address the smalldataset size. Audio data was also introduced, and WavLM model was used toextract audio features. These features were then fused with text features usingvarious methods. Finally, a contrastive learning approach was attempted byconverting speech transcripts back to audio and using it for contrastivelearning with the original audio. We conducted intensive experiments andanalysis on the above methods. Our findings shed light on the challenges andpotential solutions in AD detection using speech and audio data.","['Audio and Speech Processing', 'Artificial Intelligence', 'Sound']","['Hongmin Cai', 'Xiaoke Huang', 'Zhengliang Liu', 'Wenxiong Liao', 'Haixing Dai', 'Zihao Wu', 'Dajiang Zhu', 'Hui Ren', 'Quanzheng Li', 'Tianming Liu', 'Xiang Li']",http://arxiv.org/pdf/2307.02514v1,2023-07-05 12:40:11+00:00,患者の発話記録と音声データを用いたアルツハイマー病検出のためのマルチモーダルアプローチの探求,アルツハイマー病（AD）は、患者の健康に深刻な影響を与える一般的な認知症である。ADは患者の言語理解と表現能力を低下させるため、AD患者の発話はこの疾患の指標となり得る。本研究では、DementiaBank Pittデータベースの患者の発話とトランスクリプトデータを用いて、ADを検出するための様々な方法を検討する。提案する手法は、事前に訓練された言語モデルとGraph Neural Network(GNN)を含み、発話記録からグラフを構築し、AD検出のためにGNNを用いて特徴を抽出する。また、同義語置換、GPTベースのオーグメンターなどのデータ補強技術により、データセットサイズの小ささに対応した。音声データも導入され、WavLMモデルが音声特徴の抽出に用いられた。これらの特徴は、様々な方法を用いてテキスト特徴と融合された。最後に、音声トランスクリプトを音声に変換し、元の音声との対比学習に使用することで、対比学習アプローチを試みた。我々は上記の方法について集中的な実験と分析を行った。その結果、音声・音声データを用いたAD検出における課題と潜在的な解決策が明らかになった。,アルツハイマー病（AD）は、人の頭の中で起こる病気で、記憶や話すことがうまくできなくなるんだよ。この研究では、ADを見つけるためのいろんな方法を考えているんだ。話す内容や記録を使って、特徴を見つけるためのモデルを使ったり、データを増やす技術を使ったりしているんだ。さらに、音声のデータも使って、音の特徴を見つける方法も試しているんだ。これらの特徴を組み合わせて、ADを見つける方法を考えているんだ。実験をたくさんして、どの方法が一番いいかを調べているんだ。その結果、音声や音声データを使ったADの見つけ方について、問題や解決策がわかってきたんだよ。,"[{'Keyword': 'アルツハイマー病', 'Description': 'アルツハイマー病は、認知機能の低下や記憶障害を引き起こす神経変性疾患です。'}, {'Keyword': '認知症', 'Description': '認知症は、脳の機能が低下し、日常生活に支障をきたす病気です。'}, {'Keyword': '発話', 'Description': '発話は、言葉を話す行為や音声の生成を指します。'}, {'Keyword': 'グラフニューラルネットワーク', 'Description': 'グラフニューラルネットワーク（GNN）は、グラフ構造を扱うための人工ニューラルネットワークの一種です。'}, {'Keyword': '音声トランスクリプト', 'Description': '音声トランスクリプトは、音声データをテキストに変換する処理を指します。'}]",16.93129587173462
http://arxiv.org/abs/2307.02502v1,"Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics","The advancement in generative AI could be boosted with more accessiblemathematics. Beyond human-AI chat, large language models (LLMs) are emerging inprogramming, algorithm discovery, and theorem proving, yet their genomicsapplication is limited. This project introduces Math Agents and mathematicalembedding as fresh entries to the ""Moore's Law of Mathematics"", using aGPT-based workflow to convert equations from literature into LaTeX and Pythonformats. While many digital equation representations exist, there's a lack ofautomated large-scale evaluation tools. LLMs are pivotal as linguistic userinterfaces, providing natural language access for human-AI chat and formallanguages for large-scale AI-assisted computational infrastructure. Given theinfinite formal possibility spaces, Math Agents, which interact with math,could potentially shift us from ""big data"" to ""big math"". Math, unlike the moreflexible natural language, has properties subject to proof, enabling its usebeyond traditional applications like high-validation math-certified icons forAI alignment aims. This project aims to use Math Agents and mathematicalembeddings to address the ageing issue in information systems biology byapplying multiscalar physics mathematics to disease models and genomic data.Generative AI with episodic memory could help analyse causal relations inlongitudinal health records, using SIR Precision Health models. Genomic data issuggested for addressing the unsolved Alzheimer's disease problem.","['Other Quantitative Biology', 'Artificial Intelligence', 'Computation and Language']","['Melanie Swan', 'Takashi Kido', 'Eric Roland', 'Renato P. dos Santos']",http://arxiv.org/pdf/2307.02502v1,2023-07-04 20:16:32+00:00,数学エージェント計算インフラ、数学的埋め込み、ゲノミクス,生成AIの進歩は、より利用しやすい数学によって後押しされる可能性がある。人間とAIのチャットを超えて、大規模言語モデル（LLM）はプログラミング、アルゴリズム発見、定理証明の分野で台頭しつつあるが、そのゲノム応用は限定的である。このプロジェクトでは、「数学のムーアの法則」に新たなエントリーとして数学エージェントと数学的埋め込みを導入し、文献からLaTeXとPythonフォーマットに方程式を変換するGPTベースのワークフローを使用する。多くのデジタル方程式表現が存在する一方で、自動化された大規模な評価ツールは不足している。LLMは言語的なユーザーインターフェースとして極めて重要であり、人間とAIとのチャットのための自然言語アクセスや、大規模なAI支援計算基盤のための形式言語を提供する。無限の形式的可能性空間を考えると、数学と対話する数学エージェントは、我々を「ビッグデータ」から「ビッグ数学」へとシフトさせる可能性がある。数学は、より柔軟な自然言語とは異なり、証明の対象となる特性を持っているため、AIのアライメント目的のための高検証数学認定アイコンのような従来の用途を超えて使用することができる。このプロジェクトは、情報システム生物学における加齢問題に対処するために、多次元物理数学を疾患モデルとゲノムデータに適用することにより、数学エージェントと数学的エンバデディングを使用することを目的としている。エピソード記憶を持つ生成AIは、SIRプレシジョンヘルスモデルを使用して、縦断的健康記録の因果関係を分析するのに役立つ可能性がある。ゲノムデータは、未解決のアルツハイマー病問題に対処するために提案されている。,AIの進化は、数学の使い方がより簡単になることで進む可能性があります。大きな言語モデルは、プログラミングやアルゴリズムの発見、定理の証明といった分野で重要な存在になっていますが、数学の応用はまだ限られています。このプロジェクトでは、新しい数学エージェントと数学的な埋め込みを導入し、文献から方程式を変換するためのワークフローを使っています。自動化された評価ツールが不足しているため、これは大きな進歩です。大規模な言語モデルは、人間とAIがコミュニケーションするための重要な役割を果たしており、自然言語でのアクセスや形式言語の提供などに活用されています。数学エージェントとの対話は、私たちを「ビッグデータ」から「ビッグ数学」へと導く可能性があります。数学は柔軟な自然言語とは異なりますが、AIの目的に合わせて使われることがあります。このプロジェクトでは、情報システム生物学の問題に数学的なアプローチを取り入れることで、加齢に関連する問題に取り組んでいます。また、生成AIは健康記録の分析に役立つ可能性があります。ゲノムデータは、アルツハイマー病の解明にも役立つことが期待されています。,"[{'Keyword': '生成AI', 'Description': '生成AIは、データから新しい情報を生成する人工知能の技術です。'}, {'Keyword': '大規模言語モデル（LLM）', 'Description': '大規模言語モデル（LLM）は、非常に大量のテキストデータを学習して、言語の理解や生成を行うモデルです。'}, {'Keyword': '数学エージェント', 'Description': '数学エージェントは、数学的な問題を解くために設計された人工知能のエージェントです。'}, {'Keyword': '数学的埋め込み', 'Description': '数学的埋め込みは、数学的なオブジェクトをベクトル空間に埋め込む手法です。'}, {'Keyword': 'GPTベースのワークフロー', 'Description': 'GPTベースのワークフローは、GPT（Generative Pre-trained Transformer）モデルを使用してタスクを実行するワークフローです。'}]",19.121968984603882
http://arxiv.org/abs/2307.00348v1,Lottery and Sprint: Generate a Board Game with Design Sprint Method on Auto-GPT,"In this paper, we present a novel approach using the Auto GPT systemalongside Design Sprint methodology to facilitate board game creation forinexperienced users. We introduce the implementation of Auto GPT for generatingdiverse board games and the subsequent optimization process through acustomized Design Sprint. A user study is conducted to investigate theplayability and enjoyment of the generated games, revealing both successes andchallenges in employing systems like Auto GPT for board game design. Insightsand future research directions are proposed to overcome identified limitationsand enhance computational-driven game creation.",['Human-Computer Interaction'],"['Maya Grace Torii', 'Takahito Murakami', 'Yoichi Ochiai']",http://arxiv.org/pdf/2307.00348v1,2023-07-01 14:09:55+00:00,抽選とスプリント：オートGPTでボードゲームをデザインスプリント方式で生成する,本論文では、Auto GPTシステムとDesign Sprint手法を併用することで、経験の浅いユーザーでもボードゲームを容易に作成できる新しいアプローチを紹介する。多様なボードゲームを生成するためのAuto GPTの実装と、それに続くカスタマイズされたDesign Sprintによる最適化プロセスを紹介する。生成されたゲームの遊びやすさと楽しさを調査するためにユーザー調査を実施し、ボードゲームデザインにAuto GPTのようなシステムを採用する際の成功と課題の両方を明らかにする。また、明らかになった限界を克服し、コンピュテーショナル主導のゲーム制作を強化するための洞察と今後の研究の方向性を提案する。,この論文では、初心者の人でも簡単にボードゲームを作る方法を紹介します。Auto GPTというシステムとDesign Sprintという手法を組み合わせることで、さまざまなボードゲームを作ることができます。私たちはユーザーの意見を聞いて、生成されたゲームがどれくらい楽しいかを調査しました。そして、システムを使う上での成功や問題点を明らかにしました。また、今後の研究の方向性についても提案しています。,"[{'Keyword': 'Auto GPTシステム', 'Description': 'Auto GPTシステムは、経験の浅いユーザーでもボードゲームを容易に作成できる新しいアプローチを提供するシステムです。'}, {'Keyword': 'Design Sprint手法', 'Description': 'Design Sprint手法は、ボードゲームの最適化プロセスに使用されるカスタマイズされた手法です。'}, {'Keyword': 'ユーザー調査', 'Description': 'ユーザー調査は、生成されたゲームの遊びやすさと楽しさを評価するために行われる調査です。'}, {'Keyword': 'ボードゲームデザイン', 'Description': 'ボードゲームデザインは、ボードゲームのルールやコンポーネントの設計を行うプロセスです。'}, {'Keyword': 'コンピュテーショナル主導のゲーム制作', 'Description': 'コンピュテーショナル主導のゲーム制作は、コンピュータが主導する方法でゲームを制作することを意味します。'}]",27.635967016220093
http://arxiv.org/abs/2307.00150v1,Large Language Models (GPT) for automating feedback on programming assignments,"Addressing the challenge of generating personalized feedback for programmingassignments is demanding due to several factors, like the complexity of codesyntax or different ways to correctly solve a task. In this experimental study,we automated the process of feedback generation by employing OpenAI's GPT-3.5model to generate personalized hints for students solving programmingassignments on an automated assessment platform. Students rated the usefulnessof GPT-generated hints positively. The experimental group (with GPT hintsenabled) relied less on the platform's regular feedback but performed better interms of percentage of successful submissions across consecutive attempts fortasks, where GPT hints were enabled. For tasks where the GPT feedback was madeunavailable, the experimental group needed significantly less time to solveassignments. Furthermore, when GPT hints were unavailable, students in theexperimental condition were initially less likely to solve the assignmentcorrectly. This suggests potential over-reliance on GPT-generated feedback.However, students in the experimental condition were able to correct reasonablyrapidly, reaching the same percentage correct after seven submission attempts.The availability of GPT hints did not significantly impact students' affectivestate.","['Human-Computer Interaction', 'Artificial Intelligence']","['Maciej Pankiewicz', 'Ryan S. Baker']",http://arxiv.org/pdf/2307.00150v1,2023-06-30 21:57:40+00:00,プログラミング課題のフィードバックを自動化する大規模言語モデル(GPT),プログラミング課題に対するパーソナライズされたフィードバックを生成するという課題に取り組むことは、コード構文の複雑さや課題を正しく解くためのさまざまな方法など、いくつかの要因のために困難である。この実験的研究では、OpenAIのGPT-3.5モデルを採用し、自動化された評価プラットフォーム上でプログラミング課題を解く学生のためにパーソナライズされたヒントを生成することで、フィードバック生成プロセスを自動化した。学生はGPTが生成したヒントの有用性を肯定的に評価した。実験グループ（GPTヒントを有効にした）は、プラットフォームの通常のフィードバックへの依存度は低かったが、GPTヒントを有効にしたタスクの連続試行における提出成功の割合に関しては、より良い成績を収めた。GPTのフィードバックが利用できない課題では、実験グループは課題解決に必要な時間が大幅に短縮された。さらに、GPTのヒントが利用できない場合、実験条件の学生は、当初、課題を正しく解く可能性が低かった。このことは、GPTが生成したフィードバックに過度に依存している可能性を示唆している。しかし、実験条件の学生は、適度に早く修正することができ、7回の提出試行後に同じ正答率に達した。GPTヒントの利用可能性は、学生の情動状態に有意な影響を与えなかった。,プログラミングの問題を解く時に、自分に合ったアドバイスがもらえることはとても難しいです。でも、この研究では、OpenAIのGPT-3.5モデルを使って、プログラミングの問題を解く時に、自動的にアドバイスをもらえるようにしました。学生たちは、GPTが出したアドバイスがとても役に立つと思いました。GPTのアドバイスを使ったグループは、通常のアドバイスを使ったグループよりも問題を解くのに成功しやすかったです。また、GPTのアドバイスが使えない問題では、GPTのアドバイスを使ったグループは問題を解くのにかなり早くなりました。ただし、GPTのアドバイスがない場合、最初は問題を解くのが難しかったですが、修正していくうちに同じくらいの正解率になりました。GPTのアドバイスの有無は、学生の気持ちには影響しなかったです。,"[{'Keyword': 'パーソナライズ', 'Description': 'ユーザーに合わせてカスタマイズすること。'}, {'Keyword': 'フィードバック', 'Description': 'ユーザーからの意見や感想を収集し、改善に活かすこと。'}, {'Keyword': 'GPT-3.5', 'Description': 'OpenAIが開発した自然言語処理モデル。'}, {'Keyword': '自動化', 'Description': 'タスクやプロセスを自動的に実行すること。'}, {'Keyword': '評価プラットフォーム', 'Description': '製品やサービスの品質や効果を評価するためのプラットフォーム。'}]",12.848065853118896
http://arxiv.org/abs/2306.17842v2,SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs,"In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enablingfrozen LLMs to perform both understanding and generation tasks involvingnon-linguistic modalities such as images or videos. SPAE converts between rawpixels and interpretable lexical tokens (or words) extracted from the LLM'svocabulary. The resulting tokens capture both the semantic meaning and thefine-grained details needed for visual reconstruction, effectively translatingthe visual content into a language comprehensible to the LLM, and empowering itto perform a wide array of multimodal tasks. Our approach is validated throughin-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse setof image understanding and generation tasks. Our method marks the firstsuccessful attempt to enable a frozen LLM to generate image content whilesurpassing state-of-the-art performance in image understanding tasks, under thesame setting, by over 25%.","['Computer Vision and Pattern Recognition', 'Computation and Language', 'Multimedia']","['Lijun Yu', 'Yong Cheng', 'Zhiruo Wang', 'Vivek Kumar', 'Wolfgang Macherey', 'Yanping Huang', 'David A. Ross', 'Irfan Essa', 'Yonatan Bisk', 'Ming-Hsuan Yang', 'Kevin Murphy', 'Alexander G. Hauptmann', 'Lu Jiang']",http://arxiv.org/pdf/2306.17842v2,2023-06-30 17:59:07+00:00,SPAE: 凍結LLMを用いたマルチモーダル生成のためのセマンティックピラミッドオートエンコーダ,本研究では、凍結LLMが画像や動画などの非言語的モダリティを含む理解と生成の両方のタスクを実行できるようにするためのSemantic Pyramid AutoEncoder (SPAE)を紹介する。SPAEは、生のピクセルと、LLMの語彙から抽出された解釈可能な語彙トークン（または単語）を変換する。結果として得られるトークンは、意味的な意味と視覚的再構成に必要なきめ細かい詳細の両方を捉え、視覚コンテンツをLLMが理解可能な言語に効果的に変換し、幅広いマルチモーダルタスクの実行を可能にする。本アプローチは、凍結されたPaLM 2とGPT 3.5を用いて、多様な画像理解・生成タスクのコンテクスト内学習実験により検証される。本手法は、フローズンLLMに画像コンテンツを生成させることに初めて成功したものであり、同時に、同じ設定において、画像理解タスクにおける最先端の性能を25%以上上回るものである。,この研究では、画像や動画などの絵や動くものを理解したり作ったりするための新しい技術について紹介します。この技術は、画像や動画の中にある言葉や意味を理解できるようにするための方法です。具体的には、画像のピクセルを言葉に変換することができます。この方法を使うと、言葉だけでなく、画像の細かい部分や意味も一緒に理解することができます。そして、言葉で理解できるように変換した画像を使って、いろいろなタスクを実行することができます。この技術は、実験を通じて検証され、他の技術よりも優れた性能を持っていることがわかりました。これにより、画像を使ったいろいろなことができるようになりました。,"[{'Keyword': '凍結LLM', 'Description': '凍結LLMは、言語モデルの学習中に一部のパラメータを固定することを指します。'}, {'Keyword': '非言語的モダリティ', 'Description': '非言語的モダリティは、言語以外の情報を含むモダリティを指します。'}, {'Keyword': 'Semantic Pyramid AutoEncoder (SPAE)', 'Description': 'Semantic Pyramid AutoEncoder (SPAE)は、意味的なピラミッド構造を持つ自己符号化器です。'}, {'Keyword': '解釈可能な語彙トークン', 'Description': '解釈可能な語彙トークンは、モデルの出力を解釈可能な単語やトークンに変換する手法です。'}, {'Keyword': 'マルチモーダルタスク', 'Description': 'マルチモーダルタスクは、複数のモダリティを組み合わせたタスクを指します。'}]",14.888849973678589
http://arxiv.org/abs/2306.16638v1,A negation detection assessment of GPTs: analysis with the xNot360 dataset,"Negation is a fundamental aspect of natural language, playing a critical rolein communication and comprehension. Our study assesses the negation detectionperformance of Generative Pre-trained Transformer (GPT) models, specificallyGPT-2, GPT-3, GPT-3.5, and GPT-4. We focus on the identification of negation innatural language using a zero-shot prediction approach applied to our customxNot360 dataset. Our approach examines sentence pairs labeled to indicatewhether the second sentence negates the first. Our findings expose aconsiderable performance disparity among the GPT models, with GPT-4 surpassingits counterparts and GPT-3.5 displaying a marked performance reduction. Theoverall proficiency of the GPT models in negation detection remains relativelymodest, indicating that this task pushes the boundaries of their naturallanguage understanding capabilities. We not only highlight the constraints ofGPT models in handling negation but also emphasize the importance of logicalreliability in high-stakes domains such as healthcare, science, and law.",['Computation and Language'],"['Ha Thanh Nguyen', 'Randy Goebel', 'Francesca Toni', 'Kostas Stathis', 'Ken Satoh']",http://arxiv.org/pdf/2306.16638v1,2023-06-29 02:27:48+00:00,GPTの否定検出評価：xNot360データセットによる分析,否定は自然言語の基本的な側面であり、コミュニケーションや理解において重要な役割を果たしている。本研究では、GPT-2、GPT-3、GPT-3.5、GPT-4といった生成的事前学習済み変換器（Generative Pre-trained Transformer: GPT）モデルの否定検出性能を評価する。我々のアプローチは、2番目の文が1番目の文を否定しているかどうかを示すためにラベル付けされた文のペアを調べる。その結果、GPT-4はGPT-3.5を上回り、GPT-3.5は著しく性能が低下した。否定検出におけるGPTモデルの全体的な習熟度は比較的低いままであり、このタスクがGPTモデルの自然言語理解能力の限界に挑戦していることを示している。我々は、否定を扱う際のGPTモデルの制約を強調するだけでなく、医療、科学、法律のような重要な領域における論理的信頼性の重要性を強調する。,否定は、言葉の基本的な要素であり、コミュニケーションや理解にとても大切な役割を果たしています。この研究では、GPT-2、GPT-3、GPT-3.5、GPT-4という特別なコンピューターモデルの否定を見つける能力を評価しました。私たちの方法は、2つの文章が互いに否定しているかどうかを調べるために、文章のペアを使いました。その結果、GPT-4はGPT-3.5よりも優れていて、GPT-3.5はかなり性能が低下しました。GPTモデルは否定を見つける能力がまだ十分に高くないことがわかりました。これは、GPTモデルの言葉の理解力にはまだ限界があることを示しています。私たちは、否定を扱う時にGPTモデルの制限を強調するだけでなく、医療、科学、法律などの重要な分野で論理的な信頼性がどれだけ大切かを強調しています。,"[{'Keyword': '否定', 'Description': '否定: 文章や文の中で、事実や意見を否定すること。'}, {'Keyword': '自然言語', 'Description': '自然言語: 人間が日常的に使用する言語。'}, {'Keyword': '生成的事前学習済み変換器', 'Description': '生成的事前学習済み変換器: テキスト生成のために事前に学習されたモデル。'}, {'Keyword': 'GPTモデル', 'Description': 'GPTモデル: Generative Pre-trained Transformerの略で、自然言語処理のためのモデル。'}, {'Keyword': '論理的信頼性', 'Description': '論理的信頼性: 論理的な根拠や証拠に基づいて信頼性を評価すること。'}]",14.202085018157959

Paper_ID,Title_En,Content_En,Categories,Authors,Pdf_url,Published,Title_Ja,Content_Ja,Content_plain,Keywords,Time
http://arxiv.org/abs/2307.11031v1,Embroid: Unsupervised Prediction Smoothing Can Improve Few-Shot Classification,"Recent work has shown that language models' (LMs) prompt-based learningcapabilities make them well suited for automating data labeling in domainswhere manual annotation is expensive. The challenge is that while writing aninitial prompt is cheap, improving a prompt is costly -- practitioners oftenrequire significant labeled data in order to evaluate the impact of promptmodifications. Our work asks whether it is possible to improve prompt-basedlearning without additional labeled data. We approach this problem byattempting to modify the predictions of a prompt, rather than the promptitself. Our intuition is that accurate predictions should also be consistent:samples which are similar under some feature representation should receive thesame prompt prediction. We propose Embroid, a method which computes multiplerepresentations of a dataset under different embedding functions, and uses theconsistency between the LM predictions for neighboring samples to identifymispredictions. Embroid then uses these neighborhoods to create additionalpredictions for each sample, and combines these predictions with a simplelatent variable graphical model in order to generate a final correctedprediction. In addition to providing a theoretical analysis of Embroid, weconduct a rigorous empirical evaluation across six different LMs and up to 95different tasks. We find that (1) Embroid substantially improves performanceover original prompts (e.g., by an average of 7.3 points on GPT-JT), (2) alsorealizes improvements for more sophisticated prompting strategies (e.g.,chain-of-thought), and (3) can be specialized to domains like law through theembedding functions.","['Machine Learning', 'Computation and Language']","['Neel Guha', 'Mayee F. Chen', 'Kush Bhatia', 'Azalia Mirhoseini', 'Frederic Sala', 'Christopher Ré']",http://arxiv.org/pdf/2307.11031v1,2023-07-20 17:07:28+00:00,エンブロイド教師なし予測平滑化は数ショット分類を改善できる,最近の研究により、言語モデル(LM)のプロンプトベースの学習能力は、手作業によるアノテーションが高価な領域におけるデータラベリングの自動化に適していることが示されている。課題は、プロンプトの初期作成は安価であるが、プロンプトの改良にはコストがかかることである。我々の研究は、ラベル付きデータを追加することなく、プロンプトベースの学習を改善することが可能かどうかを問うものである。我々は、プロンプトそのものではなく、プロンプトの予測を修正することを試みることで、この問題にアプローチする。我々の直感は、正確な予測はまた一貫しているべきであるということである：ある特徴表現の下で類似しているサンプルは、同じプロンプト予測を受けるべきである。Embroidは、異なる埋め込み関数の下でデータセットの複数の表現を計算し、近傍サンプルのLM予測間の矛盾を利用して、プロンプト予測を特定する手法である。そして、Embroidは、これらの近傍を使用して、各サンプルの追加予測を作成し、最終的な補正された予測を生成するために、これらの予測を単純な潜在変数グラフィカルモデルと結合する。Embroidの理論的な分析に加え、6つの異なるLMと最大95の異なるタスクに対して、厳密な経験的評価を実施する。その結果、(1)Embroidはオリジナルのプロンプトよりもパフォーマンスを大幅に改善すること（例えば、GPT-JTで平均7.3ポイント）、(2)より洗練されたプロンプト戦略（例えば、chain-of-thought）でも改善を実現すること、(3)埋め込み関数により法律のような領域に特化できることがわかった。,最近の研究では、言語モデル（LM）というものがあります。このLMは、高価なデータラベリングの手作業を自動化するのに役立つことがわかっています。ただし、LMの改良にはコストがかかります。そこで、私たちは新しい方法を試してみました。私たちは、プロンプト（ヒント）そのものではなく、プロンプトの予測を修正することで問題に取り組みました。私たちの方法では、似たような予測をするべきサンプルを見つけ、それを使って予測を修正します。私たちの方法を評価するために、いくつかの実験を行いました。その結果、私たちの方法は元のプロンプトよりも性能が向上し、さらに特定の領域に特化することもできることがわかりました。,"[{'Keyword': '言語モデル', 'Description': '言語モデル（LM）は、自然言語処理の分野で使用される統計的モデルです。テキストデータのパターンを学習し、次の単語や文を予測する能力を持ちます。'}, {'Keyword': 'プロンプトベースの学習', 'Description': 'プロンプトベースの学習は、教師なし学習の一種であり、テキスト生成モデルの学習においてプロンプト（入力文）を使用します。プロンプトを与えることで、モデルはそれに続く文を生成することができます。'}, {'Keyword': 'アノテーション', 'Description': 'アノテーションは、データに対してラベルやタグを付ける作業です。自然言語処理の研究では、テキストデータに対して意味や構文の情報を付与するために行われます。'}, {'Keyword': 'プロンプトの改良', 'Description': 'プロンプトの改良は、テキスト生成モデルにおいて、与えられたプロンプトに基づいてより正確な予測を行うための手法です。プロンプトの選択や修正により、モデルの性能を向上させることができます。'}, {'Keyword': 'Embroid', 'Description': 'Embroidは、プロンプトベースの学習を改善するための手法です。異なる埋め込み関数を使用してデータセットの表現を計算し、近傍サンプルの予測の矛盾を利用してプロンプト予測を特定します。さらに、予測を潜在変数グラフィカルモデルと結合して補正された予測を生成します。'}]",23.084002017974854
http://arxiv.org/abs/2307.10930v1,MediaGPT : A Large Language Model Target Chinese Media,"The development of large language models (LLMs) has seen rapid progress inrecent years. One of the most widely used LLMs is the Generative Pre-trainedTransformer (GPT) series, which has been applied in various fields, includingthe media domain. However, in practical applications, the differences betweenthe media's use cases and the general-purpose applications of LLMs have becomeincreasingly apparent, especially Chinese. As a result, there is a growing needto develop LLM that are specifically tailored to the unique requirements of themedia domain. In this paper, we present MediaGPT, a large language modeltraining on variety of media data and addressing the practical needs of Chinesemedia. We have designed a diverse set of task instruction types to cater to thespecific requirements of the domain. To further validate the effectiveness ofour proposed LLM, we have constructed unique datasets that are tailored to themedia domain and have also developed verification methods that are specificallydesigned for generative-type tasks. By doing so, we aim to bridge the gapbetween the general-purpose LLM and the requirements of the media domain, andto pave the way for more effective and efficient use of LLM in this field. Thispaper aims to explore the challenges and opportunities of developing LLM formedia applications and to propose potential solutions for addressing thesechallenges.","['Computation and Language', 'Artificial Intelligence']",['Zhonghao Wang'],http://arxiv.org/pdf/2307.10930v1,2023-07-20 14:59:02+00:00,MediaGPT : 中国メディアを対象とした大規模言語モデル,近年、大規模言語モデル（LLM）の開発が急速に進んでいる。最も広く利用されているLLMの1つにGPT(Generative Pre-trainedTransformer)シリーズがあり、メディア領域を含む様々な分野で応用されている。しかし、実用化においては、中国を中心に、メディアのユースケースとLLMの汎用的な応用との違いが顕在化してきている。その結果、メディア領域特有の要件に特化したLLMを開発する必要性が高まっている。本論文では、様々なメディアデータで学習し、中国メディアの実用的なニーズに対応する大規模言語モデルMediaGPTを紹介する。我々は、メディア領域特有の要件に対応するために、多様なタスク命令タイプを設計した。さらに、提案するLLMの有効性を検証するために、メディア領域に合わせた独自のデータセットを構築し、生成型タスクに特化した検証手法も開発した。これにより、汎用的なLLMとメディア領域の要求とのギャップを埋め、この分野でLLMをより効果的かつ効率的に利用する道を開くことを目指す。本稿の目的は、メディアアプリケーションをLLMで開発する際の課題と機会を探り、これらの課題に対処するための潜在的な解決策を提案することである。,最近、大きな言語モデル（LLM）の作り方が進化しています。その中でも、GPT（Generative Pre-trained Transformer）というモデルがよく使われていて、メディアなどいろいろな場所で使われています。でも、実際に使うとなると、中国をはじめとするメディアの使い方とLLMの使い方には違いが出てきます。それで、メディアに特化したLLMを作る必要が出てきました。この論文では、いろいろなメディアのデータを使って、中国のメディアのニーズに合った大きな言語モデル「MediaGPT」を紹介します。私たちは、メディアの要求に合わせて、いろいろなタスクの方法を考えました。さらに、提案したLLMの効果を確かめるために、メディアに合わせた独自のデータセットを作り、生成のテスト方法も開発しました。これで、普通のLLMとメディアの要求の違いを埋め、この分野で効果的にLLMを使う方法を見つけることが目標です。この論文の目的は、メディアのアプリケーションをLLMで作るときの問題やチャンスを探し、それに対する解決策を提案することです。,"[{'Keyword': '大規模言語モデル', 'Description': '大規模なデータセットで訓練された言語モデル。自然言語処理のタスクにおいて高い性能を発揮する。'}, {'Keyword': 'GPT', 'Description': 'Generative Pre-trained Transformerの略。大規模言語モデルの一つであり、様々な分野で応用されている。'}, {'Keyword': '汎用的な応用', 'Description': '広範な分野やタスクに適用可能な性質を持つこと。汎用的な応用を実現するためには、多様なデータで訓練する必要がある。'}, {'Keyword': 'メディア領域', 'Description': 'メディアに関連する分野や領域。メディアデータの特徴や要件に特化した言語モデルの開発が求められている。'}, {'Keyword': 'タスク命令タイプ', 'Description': '言語モデルに与えられるタスクの種類や指示の形式。メディア領域の要件に合わせて多様なタスク命令タイプを設計することが重要である。'}]",16.525123119354248
http://arxiv.org/abs/2307.10512v1,IvyGPT: InteractiVe Chinese pathwaY language model in medical domain,"General large language models (LLMs) such as ChatGPT have shown remarkablesuccess. However, such LLMs have not been widely adopted for medical purposes,due to poor accuracy and inability to provide medical advice. We proposeIvyGPT, an LLM based on LLaMA that is trained and fine-tuned with high-qualitymedical question-answer (QA) instances and Reinforcement Learning from HumanFeedback (RLHF). After supervised fine-tuning, IvyGPT has good multi-turnconversation capabilities, but it cannot perform like a doctor in otheraspects, such as comprehensive diagnosis. Through RLHF, IvyGPT can outputricher diagnosis and treatment answers that are closer to human. In thetraining, we used QLoRA to train 33 billion parameters on a small number ofNVIDIA A100 (80GB) GPUs. Experimental results show that IvyGPT has outperformedother medical GPT models.","['Computation and Language', 'Artificial Intelligence']","['Rongsheng Wang', 'Yaofei Duan', 'ChanTong Lam', 'Jiexi Chen', 'Jiangsheng Xu', 'Haoming Chen', 'Xiaohong Liu', 'Patrick Cheong-Iao Pang', 'Tao Tan']",http://arxiv.org/pdf/2307.10512v1,2023-07-20 01:11:14+00:00,IvyGPT: 医療分野における中国語パスウェイ対話言語モデル,ChatGPTのような一般的な大規模言語モデル(LLM)は顕著な成功を収めている。しかし，このようなLLMは，精度が低く，医療的なアドバイスができないため，医療目的には広く採用されていない。我々は，LLaMAに基づくLLMであるIvyGPTを提案する。LLaMAは，高品質の医療質問応答（QA）インスタンスと，人間のフィードバックからの強化学習（RLHF）を用いて学習され，微調整される。教師ありのファインチューニングの結果，IvyGPTは良好な多対話能力を持つようになったが，総合的な診断など他の面では医師のようなパフォーマンスは発揮できない。RLHFにより，IvyGPTはより人間に近い診断と治療の答えを出力できる。学習では，QLoRAを用いて，少数のNVIDIA A100 (80GB) GPU上で330億のパラメータを学習した。実験結果は，IvyGPT が他の医療 GPT モデルよりも優れていることを示している。,ChatGPTのような大きな言語モデルは、とても有名で成功しています。でも、このようなモデルは正確さが低くて、医療のアドバイスをすることができないため、医療の分野ではあまり使われていません。私たちは、医療の質問に答えるためのIvyGPTというモデルを提案します。IvyGPTは、医療の質問に対する高品質な回答を学習するために、人間のフィードバックを使って強化学習をしました。その結果、IvyGPTは多くの質問にうまく答えることができるようになりました。でも、医師のように総合的な診断をすることはできません。しかし、強化学習によって、IvyGPTは人間に近い診断や治療のアドバイスをすることができます。IvyGPTの学習には、特別なコンピューターを使って、たくさんのデータを学習しました。実験の結果、IvyGPTは他の医療のモデルよりも優れていることがわかりました。,"[{'Keyword': 'LLM', 'Description': '大規模言語モデル（Large Language Model）の略称。ChatGPTなどが該当する。'}, {'Keyword': '医療目的', 'Description': '医療分野において使用される目的や目標のこと。'}, {'Keyword': 'LLaMA', 'Description': 'Label Learning for Medical Adviceの略称。医療質問応答において強化学習を用いて学習する手法。'}, {'Keyword': 'IvyGPT', 'Description': 'LLaMAに基づく医療質問応答のための大規模言語モデル。医療的な診断や治療に関する回答を出力できる。'}, {'Keyword': 'RLHF', 'Description': 'Reinforcement Learning from Human Feedbackの略称。人間のフィードバックからの強化学習を指す。IvyGPTの学習に使用される。'}]",14.385209798812866
http://arxiv.org/abs/2307.09998v1,Generating Mathematical Derivations with Large Language Models,"The derivation of mathematical results in specialised fields using LargeLanguage Models (LLMs) is an emerging research direction that can help identifymodels' limitations, and potentially support mathematical discovery. In thispaper, we leverage a symbolic engine to generate derivations of equations atscale, and investigate the capabilities of LLMs when deriving goal equationsfrom premises. Specifically, we employ in-context learning for GPT andfine-tune a range of T5 models to compare the robustness and generalisation ofpre-training strategies to specialised models. Empirical results show thatfine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static andout-of-distribution test sets in terms of absolute performance. However, anin-depth analysis reveals that the fine-tuned models are more sensitive toperturbations involving unseen symbols and (to a lesser extent) changes toequation structure. In addition, we analyse 1.7K equations and over 200derivations to highlight common reasoning errors such as the inclusion ofincorrect, irrelevant, and redundant equations, along with the tendency to skipderivation steps. Finally, we explore the suitability of existing metrics forevaluating mathematical derivations finding evidence that, while they capturegeneral properties such as sensitivity to perturbations, they fail to highlightfine-grained reasoning errors and essential differences between models.Overall, this work demonstrates that training models on synthetic data canimprove their mathematical capabilities beyond larger architectures.","['Computation and Language', 'History and Overview']","['Jordan Meadows', 'Marco Valentino', 'Andre Freitas']",http://arxiv.org/pdf/2307.09998v1,2023-07-19 14:13:02+00:00,大規模言語モデルによる数学的導出の生成,大規模言語モデル(LLM)を用いた専門分野における数学的結果の導出は、モデルの限界を明らかにし、数学的発見をサポートする可能性のある新たな研究方向である。本論文では、記号エンジンを活用して大規模な方程式の導出を生成し、前提からゴール方程式を導出する際のLLMの能力を調査する。具体的には、GPTにインコンテキスト学習を採用し、様々なT5モデルのファインチューニングを行うことで、特殊なモデルに対する事前学習戦略の頑健性と一般性を比較する。実証的な結果から、ファインチューニングされたFLAN-T5-large（MathT5）は、すべての静的テストセットと分布外テストセットにおいて、絶対的な性能の点でGPTモデルを上回ることが示された。しかし、詳細な分析により、ファインチューニングされたモデルは、未見の記号を含む摂動や、方程式の構造の変化（程度は低い）に対してより敏感であることが明らかになった。さらに、1.7K方程式と200以上の派生を分析し、間違った方程式、無関係な方程式、冗長な方程式、派生ステップをスキップする傾向などの一般的な推論エラーを浮き彫りにした。最後に、数学的導出を評価するための既存のメトリクスの適合性を調査し、摂動に対する感度のような一般的な特性を捉える一方で、きめ細かな推論エラーやモデル間の本質的な差異を強調することができないという証拠を発見した。,大きな言葉で言うと、この論文は、特殊な分野の数学の結果を見つけるために、大きなコンピュータープログラムを使って調べたことを説明しています。このプログラムは、たくさんの数式を作り出し、問題を解くのに役立ちます。論文では、このプログラムの性能を評価しました。結果は、このプログラムが他のプログラムよりも優れていることを示しましたが、一部の問題には苦手なところもあります。また、詳しく分析すると、プログラムには間違いや余計なものがあることもわかりました。最後に、このプログラムを評価するための方法についても話しました。,"[{'Keyword': '大規模言語モデル(LLM)', 'Description': '大規模な言語モデルは、巨大なデータセットを用いてトレーニングされた機械学習モデルであり、自然言語処理のタスクにおいて高い性能を発揮します。LLMは、専門分野における数学的結果の導出など、さまざまな応用に活用されます。'}, {'Keyword': '記号エンジン', 'Description': '記号エンジンは、数学的な表現や計算を扱うためのソフトウェアツールです。大規模な方程式の導出や数学的な操作を自動化する際に使用されます。記号エンジンを活用することで、効率的かつ正確な数学的な処理が可能となります。'}, {'Keyword': 'インコンテキスト学習', 'Description': 'インコンテキスト学習は、コンテキストを無視して単語や文を独立して学習する手法です。GPTなどの大規模言語モデルにおいて、事前学習戦略として使用されます。インコンテキスト学習は、言語モデルの頑健性と一般性を向上させるための重要な手法となっています。'}, {'Keyword': 'ファインチューニング', 'Description': 'ファインチューニングは、事前学習済みのモデルを特定のタスクに適応させるための手法です。大規模な言語モデルを特定の専門分野に適用する際に使用されます。ファインチューニングにより、モデルの性能を向上させることができます。'}, {'Keyword': '推論エラー', 'Description': '推論エラーは、モデルが予測や推論を行う際に生じる誤りのことです。大規模な言語モデルにおいては、未見の記号や方程式の構造の変化などにより推論エラーが発生することがあります。推論エラーの解析は、モデルの改善や性能評価に重要な役割を果たします。'}]",27.766102075576782
http://arxiv.org/abs/2307.08974v1,"Development of the ChatGPT, Generative Artificial Intelligence and Natural Large Language Models for Accountable Reporting and Use (CANGARU) Guidelines","The swift progress and ubiquitous adoption of Generative AI (GAI), GenerativePre-trained Transformers (GPTs), and large language models (LLMs) like ChatGPT,have spurred queries about their ethical application, use, and disclosure inscholarly research and scientific productions. A few publishers and journalshave recently created their own sets of rules; however, the absence of aunified approach may lead to a 'Babel Tower Effect,' potentially resulting inconfusion rather than desired standardization. In response to this, we presentthe ChatGPT, Generative Artificial Intelligence, and Natural Large LanguageModels for Accountable Reporting and Use Guidelines (CANGARU) initiative, withthe aim of fostering a cross-disciplinary global inclusive consensus on theethical use, disclosure, and proper reporting of GAI/GPT/LLM technologies inacademia. The present protocol consists of four distinct parts: a) an ongoingsystematic review of GAI/GPT/LLM applications to understand the linked ideas,findings, and reporting standards in scholarly research, and to formulateguidelines for its use and disclosure, b) a bibliometric analysis of existingauthor guidelines in journals that mention GAI/GPT/LLM, with the goal ofevaluating existing guidelines, analyzing the disparity in theirrecommendations, and identifying common rules that can be brought into theDelphi consensus process, c) a Delphi survey to establish agreement on theitems for the guidelines, ensuring principled GAI/GPT/LLM use, disclosure, andreporting in academia, and d) the subsequent development and dissemination ofthe finalized guidelines and their supplementary explanation and elaborationdocuments.","['Artificial Intelligence', 'Computers and Society']","['Giovanni E. Cacciamani', 'Michael B. Eppler', 'Conner Ganjavi', 'Asli Pekan', 'Brett Biedermann', 'Gary S. Collins', 'Inderbir S. Gill']",http://arxiv.org/pdf/2307.08974v1,2023-07-18 05:12:52+00:00,ChatGPT、Generative Artificial Intelligence and Natural Large Language Models for Accountable Reporting and Use（CANGARU）ガイドラインの開発,"Generative AI（GAI）、GenerativePre-trained Transformers（GPT）、ChatGPTのような大規模言語モデル（LLM）の急速な進歩とユビキタスな採用は、学術研究や科学的生産物における倫理的な適用、使用、開示に関する問い合わせに拍車をかけている。しかし、統一されたアプローチがないため、「バベルタワー効果」が生じ、標準化よりも混乱が生じる可能性がある。これに対して我々は、学術分野におけるGAI/GPT/LLM技術の倫理的な使用、開示、適切な報告に関する分野横断的でグローバルな包括的コンセンサスを醸成することを目的として、ChatGPT, Generative Artificial Intelligence, and Natural Large LanguageModels for Accountable Reporting and Use Guidelines (CANGARU)イニシアチブを提示する。このプロトコルは、以下の4つの部分から構成されている：a) GAI/GPT/LLMアプリケーションの継続的な体系的レビューにより、学術研究における関連するアイデア、知見、報告基準を理解し、その使用と開示に関するガイドラインを策定すること b) GAI/GPT/LLMに言及しているジャーナルにおける既存の著者ガイドラインの書誌学的分析を行い、既存のガイドラインを評価し、その推奨の格差を分析すること、c）デルファイ調査により、ガイドラインの項目に関する合意を確立し、学術界における原則的なGAI/GPT/LLMの使用、開示、報告を確保する。",ジェネラティブAI（GAI）、ジェネラティブプリトレーニングトランスフォーマー（GPT）、チャットGPTなどの大きな言語モデル（LLM）が進化し、広く使われるようになっています。これは、学問や科学の成果物において、倫理的な使い方や情報公開についての問題を引き起こしています。しかし、統一されたアプローチがないため、混乱が生じる可能性もあります。そこで、私たちはGAI/GPT/LLM技術の倫理的な使い方や情報公開について、学問の分野を超えて国際的な合意を形成するためのCANGARUイニシアチブを提案します。このプロトコルは以下の4つのパートから構成されています：a）GAI/GPT/LLMのアプリケーションを定期的にレビューし、学問のアイデアや報告基準を理解し、使い方や情報公開のガイドラインを作成すること、b）既存のジャーナルの著者ガイドラインを分析し、現在のガイドラインを評価し、改善点を見つけること、c）デルファイ法を使って、ガイドラインの内容について合意を形成し、GAI/GPT/LLMの使い方や情報公開についての原則を確立すること。,"[{'Keyword': 'Generative AI（GAI）', 'Description': 'Generative AI（GAI）は、人工知能の一分野であり、AIシステムが自律的にデータから新しい情報やコンテンツを生成する能力を指す。GAIは、自己学習や進化的アルゴリズムを利用して、創造的な出力を生成することができる。'}, {'Keyword': 'GenerativePre-trained Transformers（GPT）', 'Description': 'GenerativePre-trained Transformers（GPT）は、自然言語処理のための深層学習モデルであり、大規模なトランスフォーマーネットワークを使用してテキストを生成する能力を持つ。GPTは、事前にトレーニングされたモデルを使用して、文章や対話の生成を行うことができる。'}, {'Keyword': 'ChatGPT', 'Description': 'ChatGPTは、オープンドメインでの対話生成を目的としたAIモデルであり、GPTの一種である。ChatGPTは、ユーザーとの対話を通じて自然な文章を生成し、質問に答えたり意見を述べたりすることができる。'}, {'Keyword': '大規模言語モデル（LLM）', 'Description': '大規模言語モデル（LLM）は、膨大な量のテキストデータをトレーニングして作成される自然言語処理モデルのことを指す。LLMは、文章の生成や文章の意味理解などのタスクにおいて高い性能を発揮する。'}, {'Keyword': 'CANGARUイニシアチブ', 'Description': 'CANGARUイニシアチブは、ChatGPT、Generative Artificial Intelligence、and Natural Large Language Models for Accountable Reporting and Use Guidelinesの略称であり、GAI/GPT/LLM技術の倫理的な使用、開示、報告に関する包括的なコンセンサスを醸成することを目的としている。'}]",22.898950815200806
http://arxiv.org/abs/2307.08691v1,FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning,"Scaling Transformers to longer sequence lengths has been a major problem inthe last several years, promising to improve performance in language modelingand high-resolution image understanding, as well as to unlock new applicationsin code, audio, and video generation. The attention layer is the mainbottleneck in scaling to longer sequences, as its runtime and memory increasequadratically in the sequence length. FlashAttention exploits the asymmetricGPU memory hierarchy to bring significant memory saving (linear instead ofquadratic) and runtime speedup (2-4$\times$ compared to optimized baselines),with no approximation. However, FlashAttention is still not nearly as fast asoptimized matrix-multiply (GEMM) operations, reaching only 25-40\% of thetheoretical maximum FLOPs/s. We observe that the inefficiency is due tosuboptimal work partitioning between different thread blocks and warps on theGPU, causing either low-occupancy or unnecessary shared memory reads/writes. Wepropose FlashAttention-2, with better work partitioning to address theseissues. In particular, we (1) tweak the algorithm to reduce the number ofnon-matmul FLOPs (2) parallelize the attention computation, even for a singlehead, across different thread blocks to increase occupancy, and (3) within eachthread block, distribute the work between warps to reduce communication throughshared memory. These yield around 2$\times$ speedup compared to FlashAttention,reaching 50-73\% of the theoretical maximum FLOPs/s on A100 and getting closeto the efficiency of GEMM operations. We empirically validate that when usedend-to-end to train GPT-style models, FlashAttention-2 reaches training speedof up to 225 TFLOPs/s per A100 GPU (72\% model FLOPs utilization).",['Machine Learning'],['Tri Dao'],http://arxiv.org/pdf/2307.08691v1,2023-07-17 17:50:36+00:00,FlashAttention-2：並列性とワーク・パーティショニングの向上によるアテンションの高速化,Transformerをより長いシーケンス長にスケーリングすることは、ここ数年の大きな課題であり、言語モデリングや高解像度画像理解における性能向上や、コード、オーディオ、ビデオ生成における新しいアプリケーションの開拓が期待されている。アテンション・レイヤーは、シーケンス長に比例して実行時間とメモリが増加するため、より長いシーケンスへのスケーリングにおける主なボトルネックとなっている。FlashAttentionは、非対称GPUメモリ階層を利用することで、大幅なメモリ節約（2次関数ではなく線形）と実行時間の高速化（最適化されたベースラインと比較して2-4$倍$）をもたらします。しかし、FlashAttentionは、まだ最適化された行列乗算（GEMM）演算ほど高速ではなく、理論的な最大FLOPs/sの25-40%にしか達しない。この非効率性は、異なるスレッドブロック間の最適でない作業分割とGPU上のワープによるものであり、低占有率または不要な共有メモリの読み書きによるものであることがわかりました。これらの問題に対処するため、より優れたワーク・パーティショニングを備えたFlashAttention-2を提案する。特に、(1)アルゴリズムを微調整して、非マットマルFLOP数を減らす。(2)シングルヘッドであっても、異なるスレッドブロック間でアテンション計算を並列化し、占有率を上げる。(3)各スレッドブロック内で、ワープ間で作業を分散し、共有メモリを介した通信を減らす。これらにより、FlashAttentionと比較して約2$倍$の高速化を達成し、A100で理論最大FLOPs/sの50-73%に達し、GEMM演算の効率に近づいた。GPTスタイルのモデルを訓練するためにエンドツーエンドで使用した場合、FlashAttention-2はA100 GPUあたり最大225 TFLOPs/sの訓練速度に達することを実証的に検証しました（モデルFLOPs利用率は72%）。,トランスフォーマーをより長い文章に対応できるようにすることは、最近の大きな課題です。これにより、言語モデルや高解像度の画像理解の性能が向上し、新しいアプリケーション（コード、音声、ビデオの生成など）の開発が期待されています。しかし、文章が長くなると、処理時間やメモリの使用量も増えてしまいます。FlashAttentionは、特別な方法を使って、メモリの使用量を減らし、処理時間を速くすることができます。しかし、まだ完璧ではなく、最大の性能には達していません。そのため、FlashAttention-2という新しい方法を提案します。FlashAttention-2は、より効率的な処理方法を使い、FlashAttentionよりも2倍速くなります。また、最大の性能にも近づくことができます。FlashAttention-2を使ってGPTスタイルのモデルを訓練すると、非常に高速に処理することができます。,"[{'Keyword': 'Transformer', 'Description': 'Transformerは、自然言語処理タスクにおいて非常に成功したモデルであり、シーケンスの長さにスケーリングする際の課題を解決するために開発されました。'}, {'Keyword': 'FlashAttention', 'Description': 'FlashAttentionは、非対称GPUメモリ階層を利用して、メモリ節約と実行時間の高速化を実現するアテンション・レイヤーの改良手法です。'}, {'Keyword': 'GEMM演算', 'Description': 'GEMM演算は、行列の乗算を行う計算処理の一つであり、FlashAttentionの最適化において高速化の課題となっています。'}, {'Keyword': 'FlashAttention-2', 'Description': 'FlashAttention-2は、FlashAttentionの問題点を改善するために提案された改良版であり、より高速な処理と効率的なメモリ使用を実現します。'}, {'Keyword': 'GPTスタイルのモデル', 'Description': 'GPTスタイルのモデルは、自然言語処理タスクにおいて広く使用されるモデルの一つであり、FlashAttention-2によって高速化された訓練が可能です。'}]",17.19020414352417
http://arxiv.org/abs/2307.08674v2,"TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT","Tables are prevalent in real-world databases, requiring significant time andeffort for humans to analyze and manipulate. The advancements in large languagemodels (LLMs) have made it possible to interact with tables using naturallanguage input, bringing this capability closer to reality. In this paper, wepresent TableGPT, a unified fine-tuned framework that enables LLMs tounderstand and operate on tables using external functional commands. Itintroduces the capability to seamlessly interact with tables, enabling a widerange of functionalities such as question answering, data manipulation (e.g.,insert, delete, query, and modify operations), data visualization, analysisreport generation, and automated prediction. TableGPT aims to provideconvenience and accessibility to users by empowering them to effortlesslyleverage tabular data. At the core of TableGPT lies the novel concept of globaltabular representations, which empowers LLMs to gain a comprehensiveunderstanding of the entire table beyond meta-information. By jointly trainingLLMs on both table and text modalities, TableGPT achieves a deep understandingof tabular data and the ability to perform complex operations on tables throughchain-of-command instructions. Importantly, TableGPT offers the advantage ofbeing a self-contained system rather than relying on external API interfaces.Moreover, it supports efficient data process flow, query rejection (whenappropriate) and private deployment, enabling faster domain data fine-tuningand ensuring data privacy, which enhances the framework's adaptability tospecific use cases.","['Artificial Intelligence', 'Machine Learning']","['Liangyu Zha', 'Junlin Zhou', 'Liyao Li', 'Rui Wang', 'Qingyi Huang', 'Saisai Yang', 'Jing Yuan', 'Changbao Su', 'Xiang Li', 'Aofeng Su', 'Tao Zhang', 'Chen Zhou', 'Kaizhe Shou', 'Miao Wang', 'Wufang Zhu', 'Guoshan Lu', 'Chao Ye', 'Yali Ye', 'Wentao Ye', 'Yiming Zhang', 'Xinglong Deng', 'Jie Xu', 'Haobo Wang', 'Gang Chen', 'Junbo Zhao']",http://arxiv.org/pdf/2307.08674v2,2023-07-17 17:36:09+00:00,TableGPT：テーブル、自然言語、コマンドを1つのGPTに統一するために,表は現実のデータベースに広く存在し、人間が分析・操作するには多大な時間と労力を必要とする。大規模言語モデル(LLM)の進歩により、自然言語入力を用いてテーブルと対話することが可能となり、この能力が現実に近づいてきた。本論文では、LLMが外部関数コマンドを使用して表を理解し操作できるようにする、統一された微調整されたフレームワークであるTableGPTを紹介する。TableGPTは、テーブルとシームレスに対話する機能を導入し、質問応答、データ操作（挿入、削除、クエリ、変更操作など）、データ可視化、分析レポート生成、自動予測などの幅広い機能を実現する。TableGPTは、表形式のデータを簡単に活用できるようにすることで、ユーザーに利便性とアクセシビリティを提供することを目的としています。TableGPTの中核には、メタ情報を超えて表全体の包括的な理解をLLMに与える、グローバルな表形式という新しい概念がある。TableGPTは、LLMを表とテキストの両方のモダリティで共同学習させることで、表データを深く理解し、コマンド命令によって表に対して複雑な操作を実行する能力を実現します。さらに、効率的なデータ処理フロー、クエリの拒否（適切な場合）、プライベートなデプロイメントをサポートすることで、より高速なドメインデータの微調整とデータプライバシーの確保を可能にし、特定のユースケースへの適応性を高めている。,表は、たくさんのデータが入っている場所で、人が分析や操作するのにはたくさんの時間と労力が必要です。でも、最近の技術のおかげで、自然な言葉で表と話すことができるようになりました。この技術は、表を使った質問やデータの操作、データの見え方を変えたり、レポートを作ったり、予測をしたりすることができます。この技術は、表のデータを使いやすくして、人々が便利に使えるようにすることが目標です。この技術では、表の中のデータを詳しく理解し、複雑な操作をすることができます。また、データの処理を効率的にし、プライバシーも守ることができます。さまざまな場面で使えるように、いろいろなことに対応できるようになっています。,"[{'Keyword': '大規模言語モデル', 'Description': '大規模なデータセットで訓練された機械学習モデルのこと。自然言語処理のタスクにおいて高い性能を発揮する。'}, {'Keyword': '外部関数コマンド', 'Description': 'テーブル操作を行うための外部関数。TableGPTでは、外部関数コマンドを使用してテーブルの理解と操作を実現する。'}, {'Keyword': 'TableGPT', 'Description': '統一された微調整されたフレームワークで、自然言語入力を用いてテーブルと対話する能力を提供する。質問応答、データ操作、データ可視化などの機能を実現する。'}, {'Keyword': 'メタ情報', 'Description': 'テーブル全体の包括的な理解を機械学習モデルに与えるための情報。TableGPTでは、メタ情報を使用してテーブルの理解を高める。'}, {'Keyword': 'モダリティ', 'Description': '情報の表現や伝達の方法。TableGPTでは、テキストと表の両方のモダリティを共同学習させることで、表データをより深く理解する。'}]",17.240273237228394
http://arxiv.org/abs/2307.08576v1,A Study on the Performance of Generative Pre-trained Transformer (GPT) in Simulating Depressed Individuals on the Standardized Depressive Symptom Scale,"Background: Depression is a common mental disorder with societal and economicburden. Current diagnosis relies on self-reports and assessment scales, whichhave reliability issues. Objective approaches are needed for diagnosingdepression. Objective: Evaluate the potential of GPT technology in diagnosingdepression. Assess its ability to simulate individuals with depression andinvestigate the influence of depression scales. Methods: Threedepression-related assessment tools (HAMD-17, SDS, GDS-15) were used. Twoexperiments simulated GPT responses to normal individuals and individuals withdepression. Compare GPT's responses with expected results, assess itsunderstanding of depressive symptoms, and performance differences underdifferent conditions. Results: GPT's performance in depression assessment wasevaluated. It aligned with scoring criteria for both individuals withdepression and normal individuals. Some performance differences were observedbased on depression severity. GPT performed better on scales with highersensitivity. Conclusion: GPT accurately simulates individuals with depressionand normal individuals during depression-related assessments. Deviations occurwhen simulating different degrees of depression, limiting understanding of mildand moderate cases. GPT performs better on scales with higher sensitivity,indicating potential for developing more effective depression scales. GPT hasimportant potential in depression assessment, supporting clinicians andpatients.","['Neurons and Cognition', 'Machine Learning']","['Sijin Cai', 'Nanfeng Zhang', 'Jiaying Zhu', 'Yanjie Liu', 'Yongjin Zhou']",http://arxiv.org/pdf/2307.08576v1,2023-07-17 15:44:13+00:00,標準化抑うつ症状尺度における生成的事前訓練変換器(GPT)の抑うつ状態シミュレーション性能に関する研究,背景うつ病は社会的・経済的負担の大きい一般的な精神疾患である。現在の診断は、信頼性に問題のある自己申告や評価尺度に依存している。うつ病の診断には客観的なアプローチが必要である。目的うつ病診断におけるGPT技術の可能性を評価する。うつ病患者をシミュレートする能力を評価し、うつ病尺度の影響を調査する。方法3種類のうつ病関連評価ツール（HAMD-17、SDS、GDS-15）を使用した。2つの実験では、健常者とうつ病患者に対するGPTの反応をシミュレートした。GPTの反応を期待される結果と比較し、GPTの抑うつ症状に対する理解、異なる条件下でのパフォーマンスの違いを評価する。結果うつ病評価におけるGPTの性能を評価した。その結果、GPTは、うつ病患者および健常者の採点基準と一致した。うつ病の重症度により、いくつかの成績差が観察された。GPTは、感度の高い尺度において良好な成績を示した。結論GPTは、うつ病関連評価において、うつ病患者と健常者を正確にシミュレートする。異なる程度のうつ病をシミュレートする際に偏差が生じ、軽度および中等度のケースの理解が制限される。GPTは感度の高い尺度においてより良い結果を示し、より効果的なうつ病尺度の開発の可能性を示す。GPTはうつ病評価において重要な可能性を持っており、臨床家と患者をサポートする。,"背景：うつ病は、とても大変な精神の病気です。社会やお金の問題もたくさんあります。現在の診断方法は、自分で言うことや評価の基準に頼っているので、信頼性が問題です。客観的な方法でうつ病を診断することが必要です。

目的：GPT技術がうつ病の診断に役立つかどうかを調べました。うつ病の症状をシミュレートする能力を評価し、うつ病の評価基準に与える影響を調べました。

方法：３つのうつ病の評価ツール（HAMD-17、SDS、GDS-15）を使って実験しました。健康な人とうつ病の人にGPTの反応をシミュレートさせました。GPTの反応を予想される結果と比べて、うつ病の症状を理解し、さまざまな条件下でのパフォーマンスの違いを評価しました。

結果：GPTの性能をうつ病の評価において評価しました。その結果、GPTはうつ病の人と健康な人の評価基準と一致しました。うつ病の重症度によって、いくつかの違いが見られました。GPTは感度の高い尺度で良い結果を示しました。

結論：GPTはうつ病の評価において、うつ病の人と健康な人を正確にシミュレートできます。ただし、うつ病の程度が違う場合には、ちょっと違いが生じることがあり、軽度や中程度のケースの理解には限界があります。GPTは感度の高い尺度で良い結果を示し、より効果的なうつ病の評価基準の開発の可能性を示しています。GPTはうつ病の評価において重要な役割を果たし、医者や患者をサポートすることができます。","[{'Keyword': 'うつ病', 'Description': 'うつ病は、一般的な精神疾患であり、社会的・経済的負担が大きい。現在の診断は自己申告や評価尺度に依存しており、客観的なアプローチが必要である。'}, {'Keyword': '診断', 'Description': '診断は、うつ病の存在とその重症度を判断するプロセスである。信頼性のある診断方法が求められており、GPT技術の可能性が評価されている。'}, {'Keyword': 'GPT', 'Description': 'GPT（Generative Pre-trained Transformer）は、うつ病患者をシミュレートする能力を持つ人工知能技術である。うつ病関連評価において正確なシミュレーションが可能であり、新たなうつ病尺度の開発にも貢献する可能性がある。'}, {'Keyword': '尺度', 'Description': '尺度は、うつ病の重症度を測定するための基準や指標である。GPTは感度の高い尺度であり、うつ病評価において良好な成績を示すことが確認されている。'}, {'Keyword': 'シミュレート', 'Description': 'シミュレートは、うつ病患者の状態や行動を模擬することである。GPTはうつ病患者および健常者の反応をシミュレートし、異なる条件下でのパフォーマンスの違いを評価することができる。'}]",23.76150393486023
http://arxiv.org/abs/2307.08191v1,Unleashing the Potential of LLMs for Quantum Computing: A Study in Quantum Architecture Design,"Large Language Models (LLMs) contribute significantly to the development ofconversational AI and has great potentials to assist the scientific research invarious areas. This paper attempts to address the following questions: Whatopportunities do the current generation of generative pre-trained transformers(GPTs) offer for the developments of noisy intermediate-scale quantum (NISQ)technologies? Additionally, what potentials does the forthcoming generation ofGPTs possess to push the frontier of research in fault-tolerant quantumcomputing (FTQC)? In this paper, we implement a QGAS model, which can rapidlypropose promising ansatz architectures and evaluate them with applicationbenchmarks including quantum chemistry and quantum finance tasks. Our resultsdemonstrate that after a limited number of prompt guidelines and iterations, wecan obtain a high-performance ansatz which is able to produce comparableresults that are achieved by state-of-the-art quantum architecture searchmethods. This study provides a simple overview of GPT's capabilities insupporting quantum computing research while highlighting the limitations of thecurrent GPT at the same time. Additionally, we discuss futuristic applicationsfor LLM in quantum research.",['Quantum Physics'],"['Zhiding Liang', 'Jinglei Cheng', 'Rui Yang', 'Hang Ren', 'Zhixin Song', 'Di Wu', 'Xuehai Qian', 'Tongyang Li', 'Yiyu Shi']",http://arxiv.org/pdf/2307.08191v1,2023-07-17 01:39:38+00:00,量子コンピューティングのためのLLMの可能性を解き放つ：量子アーキテクチャ設計の研究,大規模言語モデル（LLM）は会話AIの発展に大きく貢献し、様々な分野の科学研究を支援する大きな可能性を秘めている。本稿では、以下の問いを解決することを試みる：現在の世代の生成的事前訓練変換器（GPT）は、ノイズの多い中間量子（NISQ）技術の開発にどのような機会を提供するのか？さらに、来るべき世代のGPTは、耐故障量子計算（FTQC）研究のフロンティアを押し広げる可能性があるのか？本論文では、QGASモデルを実装し、有望なアンサッツアーキテクチャを迅速に提案し、量子化学や量子ファイナンスなどのアプリケーションベンチマークで評価する。その結果、限られた回数の迅速なガイドラインと反復により、最先端の量子アーキテクチャ探索手法と同等の結果を得ることができる高性能なアサッツを得ることができることを実証する。本研究では、量子計算研究を支援するGPTの機能を簡単に概観すると同時に、現在のGPTの限界を明らかにする。さらに、量子研究におけるLLMの将来的な応用についても議論する。,大きな言葉で言うと、大規模言語モデル（LLM）は、会話AIの進化やさまざまな科学研究のサポートに大いに役立つ可能性があります。この論文では、以下の問いに答えようとしています：現在のAIは、ノイズの多い技術の開発にどのようなチャンスを提供しているのか？また、将来のAIは、新しい研究の可能性を広げることができるのか？この研究では、新しいモデルを使って、さまざまなテストで評価しました。その結果、少ない回数でも高性能な結果を得ることができることがわかりました。この研究では、AIの機能を簡単に説明しながら、現在の限界も明らかにしています。さらに、将来の研究への応用についても話し合っています。,"[{'Keyword': '大規模言語モデル（LLM）', 'Description': '大量のテキストデータを基にした高度な自然言語処理モデル。会話AIの発展や科学研究への応用が期待される。'}, {'Keyword': '生成的事前訓練変換器（GPT）', 'Description': '大量のデータを用いて事前に訓練されたモデル。ノイズの多い中間量子技術の開発や耐故障量子計算研究に活用される可能性がある。'}, {'Keyword': '中間量子（NISQ）技術', 'Description': 'ノイズの多い量子システムを扱う技術。現在のGPTがNISQ技術の開発にどのような機会を提供するかが注目されている。'}, {'Keyword': '耐故障量子計算（FTQC）研究', 'Description': 'ノイズに対して頑健な量子計算を実現する研究領域。将来のGPTがFTQC研究のフロンティアを拡げる可能性がある。'}, {'Keyword': 'QGASモデル', 'Description': '量子アーキテクチャ探索手法の一つ。迅速なガイドラインと反復を組み合わせることで高性能なアーキテクチャを探索することができる。'}]",18.953856706619263
http://arxiv.org/abs/2307.07982v1,A Survey of Techniques for Optimizing Transformer Inference,"Recent years have seen a phenomenal rise in performance and applications oftransformer neural networks. The family of transformer networks, includingBidirectional Encoder Representations from Transformer (BERT), GenerativePretrained Transformer (GPT) and Vision Transformer (ViT), have shown theireffectiveness across Natural Language Processing (NLP) and Computer Vision (CV)domains. Transformer-based networks such as ChatGPT have impacted the lives ofcommon men. However, the quest for high predictive performance has led to anexponential increase in transformers' memory and compute footprint. Researchershave proposed techniques to optimize transformer inference at all levels ofabstraction. This paper presents a comprehensive survey of techniques foroptimizing the inference phase of transformer networks. We survey techniquessuch as knowledge distillation, pruning, quantization, neural architecturesearch and lightweight network design at the algorithmic level. We furtherreview hardware-level optimization techniques and the design of novel hardwareaccelerators for transformers. We summarize the quantitative results on thenumber of parameters/FLOPs and accuracy of several models/techniques toshowcase the tradeoff exercised by them. We also outline future directions inthis rapidly evolving field of research. We believe that this survey willeducate both novice and seasoned researchers and also spark a plethora ofresearch efforts in this field.","['Machine Learning', 'Hardware Architecture', 'Computation and Language', 'Computer Vision and Pattern Recognition']","['Krishna Teja Chitty-Venkata', 'Sparsh Mittal', 'Murali Emani', 'Venkatram Vishwanath', 'Arun K. Somani']",http://arxiv.org/pdf/2307.07982v1,2023-07-16 08:50:50+00:00,トランス推論を最適化する技術のサーベイ,近年、変換器ニューラルネットワークの性能と応用が驚異的に向上している。BERT（トランスフォーマーからの双方向エンコーダ表現）、GPT（GenerativePretrained Transformer）、ViT（Vision Transformer）などのトランスフォーマーネットワークファミリーは、自然言語処理（NLP）およびコンピュータビジョン（CV）ドメインにわたってその有効性を示している。ChatGPTのようなTransformerベースのネットワークは、庶民の生活に影響を与えてきた。しかし、高い予測性能を追求するあまり、トランスフォーマーのメモリと計算フットプリントは指数関数的に増加している。研究者たちは、あらゆる抽象化レベルでトランスフォーマの推論を最適化する技術を提案してきた。本稿では、変圧器ネットワークの推論フェーズを最適化する技術の包括的なサーベイを行う。知識抽出、刈り込み、量子化、ニューラルアーキテクチャ探索、アルゴリズムレベルでの軽量ネットワーク設計などの技術を調査する。さらに、ハードウェアレベルでの最適化技術や、トランスフォーマー用の新しいハードウェアアクセラレータの設計についてもレビューする。いくつかのモデル/手法のパラメータ数/FLOPsと精度に関する定量的な結果をまとめ、それらのトレードオフを示す。また、急速に発展しているこの研究分野における将来の方向性についても概説する。我々は、この調査が初心者と熟練研究者の両方を教育し、またこの分野における多くの研究努力を喚起すると信じている。,最近、変換器ニューラルネットワークという技術がとても進化してきました。BERTやGPT、ViTといったトランスフォーマーネットワークは、言葉や画像の処理に使われています。例えば、ChatGPTは私たちの日常生活にも影響を与えています。ただし、これらの技術は予測の精度を上げるために、メモリや計算量が大きくなってしまうことがあります。研究者たちは、トランスフォーマーの処理を最適化する方法を考えています。この論文では、その方法について調査しました。具体的には、知識の抽出や削減、量子化、軽量ネットワークの設計などについて調べました。また、ハードウェアの最適化や新しいアクセラレータの設計についても見ています。いくつかのモデルや手法のパラメータ数や計算量、精度に関する結果をまとめ、それらのトレードオフを示しました。さらに、将来の研究の方向性についても紹介しました。この調査は初心者や熟練者の研究者に役立つだけでなく、この分野の研究にも活気を与えることを目指しています。,"[{'Keyword': '変換器ニューラルネットワーク', 'Description': '変換器ニューラルネットワークは、BERT、GPT、ViTなどのトランスフォーマーネットワークファミリーによって示される性能と応用が向上している。自然言語処理（NLP）およびコンピュータビジョン（CV）ドメインで有効性を持つ。'}, {'Keyword': 'トランスフォーマーネットワークファミリー', 'Description': 'トランスフォーマーネットワークファミリーは、変換器ニューラルネットワークの一部であり、BERT、GPT、ViTなどが含まれる。これらのネットワークは自然言語処理（NLP）およびコンピュータビジョン（CV）ドメインで有効性を示している。'}, {'Keyword': '推論最適化技術', 'Description': '推論最適化技術は、トランスフォーマーネットワークの推論フェーズを最適化するための技術である。知識抽出、刈り込み、量子化、ニューラルアーキテクチャ探索、軽量ネットワーク設計などが含まれる。'}, {'Keyword': 'ハードウェアレベル最適化技術', 'Description': 'ハードウェアレベル最適化技術は、トランスフォーマーネットワークのハードウェアレベルでの最適化を目指す技術である。新しいハードウェアアクセラレータの設計などが含まれる。'}, {'Keyword': 'パラメータ数/FLOPsと精度のトレードオフ', 'Description': 'パラメータ数/FLOPsと精度のトレードオフは、モデルや手法のパラメータ数と演算量（FLOPs）と精度の関係を示すものである。これらの要素は最適なバランスを取る必要がある。'}]",24.473161935806274
http://arxiv.org/abs/2307.10234v1,SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning,"This study presents a thorough examination of various Generative PretrainedTransformer (GPT) methodologies in sentiment analysis, specifically in thecontext of Task 4 on the SemEval 2017 dataset. Three primary strategies areemployed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2)fine-tuning GPT models, and 3) an inventive approach to embeddingclassification. The research yields detailed comparative insights among thesestrategies and individual GPT models, revealing their unique strengths andpotential limitations. Additionally, the study compares these GPT-basedmethodologies with other contemporary, high-performing models previously usedwith the same dataset. The results illustrate the significant superiority ofthe GPT approaches in terms of predictive performance, more than 22% inF1-score compared to the state-of-the-art. Further, the paper addresses commonchallenges in sentiment analysis tasks, such as understanding context anddetecting sarcasm. It underscores the enhanced capabilities of the GPT modelsto effectively navigate these complexities. Collectively, these findingshighlight the promising potential of GPT models in sentiment analysis, settingthe stage for future research in this field. The code can be found athttps://github.com/DSAatUSU/SentimentGPT.","['Computation and Language', 'Artificial Intelligence', 'Machine Learning', 'Social and Information Networks']","['Kiana Kheiri', 'Hamid Karimi']",http://arxiv.org/pdf/2307.10234v1,2023-07-16 05:33:35+00:00,SentimentGPT：高度な感傷分析のためのGPTの活用と現在の機械学習からの逸脱,本研究は、センチメント分析における様々なGenerative PretrainedTransformer (GPT)手法の徹底的な検証を、特にSemEval 2017データセットのタスク4の文脈で行う。3つの主要な戦略が採用されている：1)先進的なGPT-3.5ターボを用いたプロンプトエンジニアリング、2)GPTモデルの微調整、3)埋め込み分類への独創的なアプローチ。研究により、これらの戦略と個々のGPTモデルの詳細な比較洞察が得られ、それぞれの独自の長所と潜在的な限界が明らかになった。さらに、これらのGPTベースの方法論と、以前に同じデータセットで使用された他の現代的で高性能なモデルとの比較も行っている。その結果、予測性能の点でGPTアプローチの有意な優位性が示され、最先端のものと比較してF1スコアが22%以上向上した。さらに、この論文では、文脈の理解や皮肉の検出など、感情分析タスクにおける一般的な課題に取り組んでいる。また、これらの複雑性を効果的にナビゲートするためのGPTモデルの強化された能力を強調している。これらの結果を総合すると、GPTモデルがセンチメント分析において有望な可能性を秘めていることが明らかになり、この分野における今後の研究の舞台が整ったことになる。コードはhttps://github.com/DSAatUSU/SentimentGPT。,この研究では、感情分析に使われる様々なGenerative Pretrained Transformer (GPT)の方法を詳しく調べました。特に、SemEval 2017データセットのタスク4を使って検証しました。私たちは3つの主要な戦略を使いました：1) GPT-3.5ターボを使ったプロンプトエンジニアリング、2) GPTモデルの微調整、3) 独自の方法で埋め込み分類を行いました。この研究によって、これらの戦略とGPTモデルの詳細な比較がわかり、それぞれの長所と限界も明らかになりました。また、他のモデルとの比較も行いました。その結果、GPTアプローチの予測性能が非常に高く、最先端のモデルと比べてF1スコアが22%以上向上しました。また、この論文では、感情分析の一般的な課題にも取り組んでいます。GPTモデルは、これらの課題をうまく解決する能力があります。これらの結果から、GPTモデルは感情分析において非常に有望であり、今後の研究に期待が持てることがわかりました。詳しいコードはhttps://github.com/DSAatUSU/SentimentGPTで見ることができます。,"[{'Keyword': 'センチメント分析', 'Description': 'テキストデータの感情や意見を分析する技術。'}, {'Keyword': 'Generative Pretrained Transformer (GPT)', 'Description': '事前学習済みのTransformerモデルで、文章生成や自然言語処理のタスクに使用される。'}, {'Keyword': 'プロンプトエンジニアリング', 'Description': 'GPTモデルの出力を制御するためのテキストの追加や修正の手法。'}, {'Keyword': '微調整', 'Description': '事前学習済みモデルを特定のタスクに適応させるための追加の学習ステップ。'}, {'Keyword': '埋め込み分類', 'Description': '文章の埋め込み表現を入力として、分類タスクを行う手法。'}]",16.962737798690796
http://arxiv.org/abs/2307.07930v1,GeoGPT: Understanding and Processing Geospatial Tasks through An Autonomous GPT,"Decision-makers in GIS need to combine a series of spatial algorithms andoperations to solve geospatial tasks. For example, in the task of facilitysiting, the Buffer tool is usually first used to locate areas close or awayfrom some specific entities; then, the Intersect or Erase tool is used toselect candidate areas satisfied multiple requirements. Though professionalscan easily understand and solve these geospatial tasks by sequentiallyutilizing relevant tools, it is difficult for non-professionals to handle theseproblems. Recently, Generative Pre-trained Transformer (e.g., ChatGPT) presentsstrong performance in semantic understanding and reasoning. Especially, AutoGPTcan further extend the capabilities of large language models (LLMs) byautomatically reasoning and calling externally defined tools. Inspired by thesestudies, we attempt to lower the threshold of non-professional users to solvegeospatial tasks by integrating the semantic understanding ability inherent inLLMs with mature tools within the GIS community. Specifically, we develop a newframework called GeoGPT that can conduct geospatial data collection,processing, and analysis in an autonomous manner with the instruction of onlynatural language. In other words, GeoGPT is used to understand the demands ofnon-professional users merely based on input natural language descriptions, andthen think, plan, and execute defined GIS tools to output final effectiveresults. Several cases including geospatial data crawling, spatial query,facility siting, and mapping validate the effectiveness of our framework.Though limited cases are presented in this paper, GeoGPT can be furtherextended to various tasks by equipping with more GIS tools, and we think theparadigm of ""foundational plus professional"" implied in GeoGPT provides aneffective way to develop next-generation GIS in this era of large foundationmodels.","['Computation and Language', 'Artificial Intelligence']","['Yifan Zhang', 'Cheng Wei', 'Shangyou Wu', 'Zhengting He', 'Wenhao Yu']",http://arxiv.org/pdf/2307.07930v1,2023-07-16 03:03:59+00:00,GeoGPT：自律型GPTによる地理空間タスクの理解と処理,GISの意思決定者は、地理空間タスクを解決するために、一連の空間アルゴリズムと操作を組み合わせる必要がある。例えば、施設立地のタスクでは、通常、最初にバッファツールを使用して、特定のエンティティに近い、または特定のエンティティから離れた領域を特定し、次に、交差または消去ツールを使用して、複数の要件を満たす候補領域を選択する。専門家であれば、これらの地理空間タスクを理解し、関連するツールを順次使用することで解決することは容易であるが、専門家でない人がこれらの問題を処理することは困難である。近年、Generative Pre-trained Transformer (例えば、ChatGPT) は、意味理解と推論において強力な性能を示している。特に、AutoGPTは、自動的に推論し、外部で定義されたツールを呼び出すことによって、大規模言語モデル（LLM）の機能をさらに拡張することができる。これらの研究に触発され、我々は、LLMに内在する意味理解能力をGISコミュニティ内の成熟したツールと統合することにより、非専門家ユーザが地理空間タスクを解決するための敷居を下げることを試みる。具体的には、GeoGPTと呼ばれる新しいフレームワークを開発し、自然言語のみの指示で自律的に地理空間データの収集、処理、分析を行うことができる。言い換えれば、GeoGPTは、入力された自然言語記述に基づくだけで、専門家ではないユーザの要求を理解し、最終的に効果的な結果を出力するために、定義されたGISツールを考え、計画し、実行するために使用される。本稿では、限られたケースを紹介したが、GeoGPT は、より多くの GIS ツールを装備することで、様々なタスクにさらに拡張することが可能であり、GeoGPT に含意される「基礎＋専門」のパラダイムは、大規模な基礎モデルの時代において、次世代 GIS を開発するための効果的な方法を提供すると考える。,GISの意思決定者は、地理空間タスクを解決するために、いくつかの手順やツールを使います。たとえば、施設を建てる場所を決めるときは、まず特定の場所から近い範囲や遠い範囲を見つけるためにバッファツールを使います。そして、交差や消去ツールを使って、いくつかの条件を満たす候補地を選びます。専門家はこれらの手順を理解して使うことができますが、専門家でない人にとっては難しいです。最近、Generative Pre-trained Transformerという技術が開発され、言葉の意味を理解して推論することが得意です。私たちは、この技術を使って、専門家でない人でも地理空間タスクを解決できるようにするフレームワークを開発しました。このフレームワークはGeoGPTと呼ばれています。GeoGPTは、自然言語の指示だけで地理空間データを集めたり処理したり分析したりすることができます。つまり、GeoGPTは専門家でない人の要求を理解し、効果的な結果を出すために必要なツールを考えて計画し、実行することができます。これまでの研究では限られたケースしか試していませんが、GeoGPTはさらに多くのGISツールを使えるようになり、様々なタスクに応用できる可能性があります。GeoGPTは、次世代のGISを開発するための有効な方法となると考えています。,"[{'Keyword': '地理空間タスク', 'Description': '地理空間タスクは、地理情報システム（GIS）において解決される特定の作業や問題のことを指します。これには、地理空間データの収集、処理、分析、可視化などが含まれます。'}, {'Keyword': 'バッファツール', 'Description': 'バッファツールは、地理空間データの特定のエンティティの周囲にある領域を作成するために使用されるGISツールです。たとえば、施設立地のタスクで使用され、特定のエンティティから一定の距離の範囲を特定するのに役立ちます。'}, {'Keyword': '交差ツール', 'Description': '交差ツールは、複数の地理空間データの交差や重なりを検出するために使用されるGISツールです。施設立地のタスクにおいては、複数の要件を満たす候補領域を選択するために使用されることがあります。'}, {'Keyword': 'Generative Pre-trained Transformer (GPT)', 'Description': 'Generative Pre-trained Transformer（GPT）は、自然言語処理の分野で使用される強力なモデルです。GPTは、大量のテキストデータを学習して、自然言語の生成、理解、推論などのタスクに使用することができます。'}, {'Keyword': 'GeoGPT', 'Description': 'GeoGPTは、地理空間タスクを解決するために開発された新しいフレームワークです。GeoGPTは、自然言語の指示に基づいて地理空間データの収集、処理、分析を自動的に行うことができます。非専門家ユーザが地理空間タスクを容易に解決できるよう支援します。'}]",22.5510470867157
http://arxiv.org/abs/2307.07359v1,From Multilayer Perceptron to GPT: A Reflection on Deep Learning Research for Wireless Physical Layer,"Most research studies on deep learning (DL) applied to the physical layer ofwireless communication do not put forward the critical role of theaccuracy-generalization trade-off in developing and evaluating practicalalgorithms. To highlight the disadvantage of this common practice, we revisit adata decoding example from one of the first papers introducing DL-basedend-to-end wireless communication systems to the research community andpromoting the use of artificial intelligence (AI)/DL for the wireless physicallayer. We then put forward two key trade-offs in designing DL models forcommunication, namely, accuracy versus generalization and compression versuslatency. We discuss their relevance in the context of wireless communicationsuse cases using emerging DL models including large language models (LLMs).Finally, we summarize our proposed evaluation guidelines to enhance theresearch impact of DL on wireless communications. These guidelines are anattempt to reconcile the empirical nature of DL research with the rigorousrequirement metrics of wireless communications systems.","['Information Theory', 'Information Theory']","['Mohamed Akrout', 'Amine Mezghani', 'Ekram Hossain', 'Faouzi Bellili', 'Robert W. Heath']",http://arxiv.org/pdf/2307.07359v1,2023-07-14 14:04:01+00:00,多層パーセプトロンからGPTへ：無線物理層のためのディープラーニング研究の考察,無線通信の物理層に適用される深層学習（DL）に関する研究のほとんどは、実用的なアルゴリズムの開発と評価において、精度と汎化のトレードオフの重要な役割を提唱していない。この一般的な慣行の欠点を強調するために、DLベースのエンド・ツー・エンドの無線通信システムを研究コミュニティに紹介し、無線物理層への人工知能（AI）/DLの利用を促進した最初の論文の1つから、データ復号の例を再検討する。次に、通信のためのDLモデル設計における2つの重要なトレードオフ、すなわち、精度対汎化、圧縮対遅延を提唱する。最後に、無線通信におけるDLの研究効果を高めるために提案する評価ガイドラインについてまとめる。これらのガイドラインは、DL研究の経験的性質と無線通信システムの厳密な要件測定基準との調和を図る試みである。,無線通信の勉強についてのほとんどの研究は、難しいアルゴリズムの開発や評価に焦点を当てています。しかし、この研究では、正確さと汎用性のバランスが大切だということを言っていません。私たちは、この問題を解決するために、人工知能（AI）や深層学習（DL）を使った無線通信システムの研究を紹介します。例えば、データの復号について考えます。また、通信のためのモデルを作る際には、正確さと圧縮のバランスや、遅延を考える必要があります。最後に、無線通信の研究を進めるために、評価のガイドラインを提案します。これらのガイドラインは、研究の経験と通信システムの要件を合わせるためのものです。,"[{'Keyword': '深層学習', 'Description': '深層学習は、多層のニューラルネットワークを用いた機械学習の手法です。大量のデータを用いて学習し、高度なパターン認識や予測を行うことができます。無線通信の物理層にも適用され、高速かつ高精度なデータ復号が可能です。'}, {'Keyword': 'エンド・ツー・エンド', 'Description': 'エンド・ツー・エンドは、通信システムの始点から終点までの全体を指す言葉です。無線通信システムにおいては、送信側から受信側までのすべてのプロセスや通信経路を含みます。DLベースのエンド・ツー・エンドの無線通信システムは、高度な人工知能（AI）/DL技術を活用して、通信の各段階で最適化を行います。'}, {'Keyword': '精度対汎化', 'Description': '精度対汎化は、機械学習モデルの性能評価において重要なトレードオフです。精度とは、学習データに対する予測の正確さを指し、汎化とは、未知のデータに対する予測の正確さを指します。DLモデルの設計においては、高い精度と汎化のバランスを取ることが求められます。'}, {'Keyword': '圧縮対遅延', 'Description': '圧縮対遅延は、データ通信における重要なトレードオフです。圧縮はデータのサイズを小さくすることで、通信帯域を節約する効果があります。一方、遅延はデータの伝送にかかる時間を指し、通信の速度を制約する要因です。DLモデルの設計においては、高い圧縮率と低い遅延を両立させることが求められます。'}, {'Keyword': '評価ガイドライン', 'Description': '評価ガイドラインは、研究や開発の過程で行われる評価の基準や手順をまとめたものです。無線通信におけるDLの研究効果を高めるためには、適切な評価ガイドラインを設けることが重要です。これにより、研究結果の再現性や比較性が向上し、より優れたシステムの開発が可能となります。'}]",31.131350994110107
http://arxiv.org/abs/2307.07262v1,MorphPiece : Moving away from Statistical Language Representation,"Tokenization is a critical part of modern NLP pipelines. However,contemporary tokenizers for Large Language Models are based on statisticalanalysis of text corpora, without much consideration to the linguisticfeatures. We propose a linguistically motivated tokenization scheme,MorphPiece, which is based partly on morphological segmentation of theunderlying text. A GPT-style causal language model trained on this tokenizer(called MorphGPT) shows superior convergence compared to the same architecturetrained on a standard BPE tokenizer. Specifically we get Language Modelingperformance comparable to a 6 times larger model. Additionally, we evaluateMorphGPT on a variety of NLP tasks in supervised and unsupervised settings andfind superior performance across the board, compared to GPT-2 model.",['Computation and Language'],['Haris Jabbar'],http://arxiv.org/pdf/2307.07262v1,2023-07-14 10:35:04+00:00,MorphPiece : 統計的言語表現からの脱却,トークン化は現代の自然言語処理パイプラインの重要な部分である。しかし、最近の大規模言語モデル用のトークン化は、テキストコーパスの統計的分析に基づいており、言語的特徴はあまり考慮されていない。我々は言語学的に動機づけられたトークン化スキームであるMorphPieceを提案する。このトークナイザで学習したGPTスタイルの因果言語モデル（MorphGPTと呼ぶ）は、標準的なBPEトークナイザで学習した同じアーキテクチャと比較して、優れた収束性を示す。具体的には、6倍大きなモデルに匹敵する言語モデリング性能が得られる。さらに、教師あり・教師なし設定の様々なNLPタスクでMorphGPTを評価したところ、GPT-2モデルと比較して、全体的に優れた性能が得られました。,トークン化は、言葉を処理する重要な方法です。最近の方法では、たくさんの文章を統計的に分析して、言語の特徴を考えずに処理しています。私たちは、言語学に基づいた新しい方法を提案します。この方法では、より良い結果が得られます。さらに、いろいろな言語の問題を解いてみると、今までの方法よりも優れた性能が見られました。,"[{'Keyword': 'トークン化', 'Description': '自然言語処理パイプラインの重要な部分であり、テキストをトークン（単語や文字など）に分割する処理のこと。'}, {'Keyword': '言語モデル', 'Description': '自然言語の統計的な特性を学習し、文章生成や文脈理解などのタスクに応用するモデル。'}, {'Keyword': 'MorphPiece', 'Description': '言語学的に動機づけられたトークン化スキームであり、MorphGPTという因果言語モデルに組み込まれている。'}, {'Keyword': 'BPEトークナイザ', 'Description': 'バイトペアエンコーディング（Byte Pair Encoding）を用いたトークナイザであり、テキストを部分文字列に分割する手法。'}, {'Keyword': '収束性', 'Description': 'モデルの学習が収束する性質であり、十分なデータや反復学習を行うことで正確な予測や生成が可能となる。'}]",14.343780040740967
http://arxiv.org/abs/2307.06524v1,Agreement Tracking for Multi-Issue Negotiation Dialogues,"Automated negotiation support systems aim to help human negotiators reachmore favorable outcomes in multi-issue negotiations (e.g., an employer and acandidate negotiating over issues such as salary, hours, and promotions beforea job offer). To be successful, these systems must accurately track agreementsreached by participants in real-time. Existing approaches either focus ontask-oriented dialogues or produce unstructured outputs, rendering themunsuitable for this objective. Our work introduces the novel task of agreementtracking for two-party multi-issue negotiations, which requires continuousmonitoring of agreements within a structured state space. To address thescarcity of annotated corpora with realistic multi-issue negotiation dialogues,we use GPT-3 to build GPT-Negochat, a synthesized dataset that we make publiclyavailable. We present a strong initial baseline for our task bytransfer-learning a T5 model trained on the MultiWOZ 2.4 corpus. Pre-trainingT5-small and T5-base on MultiWOZ 2.4's DST task enhances results by 21% and 9%respectively over training solely on GPT-Negochat. We validate our method'ssample-efficiency via smaller training subset experiments. By releasingGPT-Negochat and our baseline models, we aim to encourage further research inmulti-issue negotiation dialogue agreement tracking.",['Computation and Language'],"['Amogh Mannekote', 'Bonnie J. Dorr', 'Kristy Elizabeth Boyer']",http://arxiv.org/pdf/2307.06524v1,2023-07-13 02:00:27+00:00,複数イシューの交渉ダイアログにおける合意追跡,自動化された交渉支援システムは、複数の問題を抱える交渉（例えば、内定前に給与、勤務時間、昇進などの問題をめぐって雇用主と候補者が交渉する場合）において、人間の交渉者がより有利な結果に到達するのを支援することを目的としている。成功するためには、これらのシステムは、リアルタイムで参加者によって達成された合意を正確に追跡しなければならない。既存のアプローチは、タスク指向の対話に重点を置くか、構造化されていない出力を生成するかのどちらかであり、この目的には適していない。これは、構造化された状態空間内での合意の継続的な監視を必要とする。現実的なマルチイシュー交渉対話の注釈付きコーパスの希少性に対処するため、GPT-3を用いてGPT-Negochatを構築し、その合成データセットを公開する。我々は、MultiWOZ 2.4コーパスで訓練されたT5モデルを転送学習することにより、我々のタスクのための強力な初期ベースラインを提示する。T5-smallとT5-baseをMultiWOZ 2.4のDSTタスクで事前学習することで、GPT-Negochatのみで学習するよりも、それぞれ21%と9%結果が向上する。また、GPT-Negochatのみでの学習と比較して、21%と9%向上しました。GPT-Negochatと我々のベースラインモデルを公開することで、マルチイシュー交渉対話合意追跡のさらなる研究を促進することを目指す。,自動化された交渉支援システムは、人々が話し合いをする時に役立つものです。例えば、雇用主と候補者が仕事の条件について話し合う時に使われます。このシステムは、人間の交渉者がより良い結果を得るのを手助けします。成功するためには、システムは参加者が合意した内容を正確に記録しなければなりません。これまでの方法では、タスクに集中した会話をするか、整理されていない情報を出力するかのどちらかでしたが、この目的には適していませんでした。私たちは新しいシステムを作りました。このシステムは、合意を追跡するために使われます。私たちはデータを集めて、システムを訓練しました。その結果、システムがより良い結果を出すことができるようになりました。私たちはこのシステムを皆さんに公開し、さらなる研究が進むことを願っています。,"[{'Keyword': '交渉支援システム', 'Description': '複数の問題を抱える交渉において、人間の交渉者が有利な結果に到達するためのシステム。'}, {'Keyword': '合意の追跡', 'Description': 'リアルタイムで参加者によって達成された合意を正確に追跡すること。'}, {'Keyword': 'マルチイシュー交渉', 'Description': '複数の問題を含む交渉のこと。例えば、給与、勤務時間、昇進などの問題を同時に取り扱う。'}, {'Keyword': 'GPT-3', 'Description': 'OpenAIが開発した自然言語処理モデルで、テキスト生成や質問応答などのタスクに利用される。'}, {'Keyword': 'T5モデル', 'Description': 'Googleが開発した自然言語処理モデルで、機械翻訳や質問応答などのタスクに利用される。'}]",14.523725032806396
http://arxiv.org/abs/2307.06218v1,Ashaar: Automatic Analysis and Generation of Arabic Poetry Using Deep Learning Approaches,"Poetry holds immense significance within the cultural and traditional fabricof any nation. It serves as a vehicle for poets to articulate their emotions,preserve customs, and convey the essence of their culture. Arabic poetry is noexception, having played a cherished role in the heritage of the Arabiccommunity throughout history and maintaining its relevance in the present era.Typically, comprehending Arabic poetry necessitates the expertise of a linguistwho can analyze its content and assess its quality. This paper presents theintroduction of a framework called \textit{Ashaar}https://github.com/ARBML/Ashaar, which encompasses a collection of datasets andpre-trained models designed specifically for the analysis and generation ofArabic poetry. The pipeline established within our proposed approachencompasses various aspects of poetry, such as meter, theme, and eraclassification. It also incorporates automatic poetry diacritization, enablingmore intricate analyses like automated extraction of the \textit{Arudi} style.Additionally, we explore the feasibility of generating conditional poetrythrough the pre-training of a character-based GPT model. Furthermore, as partof this endeavor, we provide four datasets: one for poetry generation, anotherfor diacritization, and two for Arudi-style prediction. These datasets aim tofacilitate research and development in the field of Arabic poetry by enablingresearchers and enthusiasts to delve into the nuances of this rich literarytradition.",['Computation and Language'],"['Zaid Alyafeai', 'Maged S. Al-Shaibani', 'Moataz Ahmed']",http://arxiv.org/pdf/2307.06218v1,2023-07-12 15:07:16+00:00,アシャールディープラーニングアプローチによるアラビア語詩の自動解析と生成,詩は、どの国の文化や伝統的な構造においても、計り知れない重要性を持っている。詩は、詩人たちが自分たちの感情を表現し、習慣を守り、文化の本質を伝える手段として機能している。アラビア語の詩も例外ではなく、歴史を通じてアラビア語コミュニティの遺産として大切な役割を果たし、現代においてもその関連性を維持している。通常、アラビア語の詩を理解するには、その内容を分析し、その質を評価できる言語学者の専門知識が必要である。本論文では、アラビア語の詩の分析と生成のために特別に設計されたデータセットと事前に訓練されたモデルのコレクションを包含する、୧⃛(๑⃙⃘⁼̴̀꒳⁼̴́๑⃙⃘)୨⃛https://github.com/ARBML/Ashaar。私たちの提案するアプローチで確立されたパイプラインは、メーター、テーマ、エラ分類など、詩のさまざまな側面を含んでいます。さらに、文字ベースのGPTモデルの事前学習を通して、条件付き詩の生成の可能性を探る。さらに、この試みの一環として、4つのデータセットを提供する。1つは詩の生成用、もう1つは発音区分用、そして2つはアルディ風の予測用である。これらのデータセットは、研究者や愛好家がこの豊かな文学的伝統のニュアンスを掘り下げることを可能にすることで、アラビア語詩の分野における研究開発を促進することを目的としています。,詩は、とても大切なものです。どの国の文化や伝統にもあります。詩は、詩人たちが自分の気持ちを表現したり、習慣を守ったり、文化を伝えたりする手段です。アラビア語の詩も同じで、歴史を通じてアラビア語を話す人々の大切な遺産として役立っています。詩を理解するためには、言語学者の専門知識が必要です。この論文では、アラビア語の詩を分析し、生成するためのデータセットやモデルについて説明しています。また、詩のメーターやテーマ、エラ分類など、詩のさまざまな側面についても触れています。さらに、文字ベースのモデルを使って詩を生成する方法についても説明しています。この研究では、詩の生成や発音区分、予測のためのデータセットも提供しています。これらのデータセットは、研究者や詩の愛好家がアラビア語の詩を深く理解するのに役立ちます。アラビア語の詩の研究を進めるために、この論文が役立つことを願っています。,"[{'Keyword': '詩', 'Description': '詩は、感情や思考を表現するための文学的な形式であり、文化や伝統において重要な役割を果たしています。詩は言葉の響きやリズムによって美しさを追求し、読者や聴衆に感動や共感を与えることを目指しています。'}, {'Keyword': '詩人', 'Description': '詩を創作する人を指す言葉であり、詩の表現力や感情を豊かに表現する能力が求められます。詩人は言葉やイメージを巧みに組み合わせて、読者や聴衆に深い感銘を与えることを目指します。'}, {'Keyword': 'アラビア語の詩', 'Description': 'アラビア語で書かれた詩のことであり、アラビア語コミュニティの文化的な遺産として重要な役割を果たしています。アラビア語の詩は美しい言葉の響きやリズムによって特徴付けられ、感情や思考を深く表現する力を持っています。'}, {'Keyword': '言語学者', 'Description': '言語学を専門とする人を指す言葉であり、アラビア語の詩を理解し分析するために必要な専門知識を持っています。言語学者は詩の構造や意味を解釈し、その質を評価することができます。'}, {'Keyword': 'データセット', 'Description': '詩の分析や生成のために使用されるデータの集合体です。データセットには詩のテキストや詩人の情報などが含まれており、詩の研究やモデルの開発に活用されます。'}]",21.912431955337524
http://arxiv.org/abs/2307.06187v1,Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems,"In autonomic computing, self-adaptation has been proposed as a fundamentalparadigm to manage the complexity of multiagent systems (MASs). This achievedby extending a system with support to monitor and adapt itself to achievespecific concerns of interest. Communication in these systems is key given thatin scenarios involving agent interaction, it enhances cooperation and reducescoordination challenges by enabling direct, clear information exchange.However, improving the expressiveness of the interaction communication withMASs is not without challenges. In this sense, the interplay betweenself-adaptive systems and effective communication is crucial for future MASadvancements. In this paper, we propose the integration of large languagemodels (LLMs) such as GPT-based technologies into multiagent systems. We anchorour methodology on the MAPE-K model, which is renowned for its robust supportin monitoring, analyzing, planning, and executing system adaptations inresponse to dynamic environments. We also present a practical illustration ofthe proposed approach, in which we implement and assess a basic MAS-basedapplication. The approach significantly advances the state-of-the-art ofself-adaptive systems by proposing a new paradigm for MAS self-adaptation ofautonomous systems based on LLM capabilities.","['Multiagent Systems', 'Artificial Intelligence', 'Computation and Language']","['Nathalia Nascimento', 'Paulo Alencar', 'Donald Cowan']",http://arxiv.org/pdf/2307.06187v1,2023-07-12 14:26:46+00:00,自己適応型大規模言語モデル（LLM）に基づくマルチエージェントシステム,オートノミックコンピューティングでは、マルチエージェントシステム（MAS）の複雑性を管理するための基本的なパラダイムとして自己適応が提案されている。これは、関心のある特定の関心事を達成するために、それ自身を監視し適応させるサポートによってシステムを拡張することによって達成される。これらのシステムにおけるコミュニケーションは、エージェントの相互作用を含むシナリオにおいて、直接的で明確な情報交換を可能にすることで協力を強化し、調整の課題を軽減することを考えると、重要な鍵となる。この意味で、自己適応システムと効果的なコミュニケーションの相互作用は、将来のMASの進歩にとって極めて重要である。本論文では、GPTに基づく技術のような大規模言語モデル（LLM）をマルチエージェントシステムに統合することを提案する。本論文では、動的環境に対応したシステム適応の監視、分析、計画、実行をロバストにサポートすることで有名なMAPE-Kモデルを基礎とした手法を提案する。また、基本的なMASベースのアプリケーションを実装し評価することで、提案するアプローチの実用的な例証を示す。本アプローチは、LLM能力に基づく自律システムのMAS自己適応のための新しいパラダイムを提案することにより、自己適応システムの最先端を大きく前進させる。,"オートノミックコンピューティングでは、マルチエージェントシステム（MAS）の複雑性を管理するために、自己適応が重要な役割を果たしています。自己適応とは、システムが自分自身を監視し、必要な変化を行って目標を達成することです。MASでは、エージェント同士のコミュニケーションも重要です。コミュニケーションがスムーズに行われることで、協力が強化され、調整の問題も解決できます。このような自己適応とコミュニケーションの相互作用は、MASの進歩にとって非常に重要です。

この論文では、大規模な言語モデル（LLM）をマルチエージェントシステムに統合する方法を提案しています。また、動的な環境に対応するためのシステム適応をサポートする手法も提案しています。さらに、実際のアプリケーションを使って、提案したアプローチの有用性を評価しています。このアプローチにより、自律システムの自己適応が大きく進歩することが期待されます。","[{'Keyword': 'オートノミックコンピューティング', 'Description': 'マルチエージェントシステム（MAS）の複雑性を管理するための基本的なパラダイムとして自己適応が提案されている。'}, {'Keyword': '自己適応', 'Description': '関心のある特定の関心事を達成するために、それ自身を監視し適応させるサポートによってシステムを拡張すること。'}, {'Keyword': 'マルチエージェントシステム', 'Description': '複数のエージェントが相互に協力し、目標を達成するために相互作用するシステム。'}, {'Keyword': 'コミュニケーション', 'Description': 'エージェントの相互作用を含むシナリオにおいて、直接的で明確な情報交換を可能にすることで協力を強化し、調整の課題を軽減すること。'}, {'Keyword': '大規模言語モデル（LLM）', 'Description': 'GPTに基づく技術のような大規模な言語モデルを指す。'}]",15.065987825393677
http://arxiv.org/abs/2307.05782v1,Large Language Models,"Artificial intelligence is making spectacular progress, and one of the bestexamples is the development of large language models (LLMs) such as OpenAI'sGPT series. In these lectures, written for readers with a background inmathematics or physics, we give a brief history and survey of the state of theart, and describe the underlying transformer architecture in detail. We thenexplore some current ideas on how LLMs work and how models trained to predictthe next word in a text are able to perform other tasks displayingintelligence.","['Computation and Language', 'High Energy Physics - Theory', 'History and Overview', 'Computational Physics']",['Michael R. Douglas'],http://arxiv.org/pdf/2307.05782v1,2023-07-11 20:21:02+00:00,大規模言語モデル,人工知能は目覚ましい進歩を遂げているが、その最たる例の一つがOpenAIのGPTシリーズのような大規模言語モデル（LLM）の開発である。本講演では、数学または物理学のバックグラウンドを持つ読者向けに、その歴史と現状を簡単に説明し、基礎となる変換器アーキテクチャについて詳しく説明する。さらに、LLMがどのように機能するのか、また、テキストの次の単語を予測するように訓練されたモデルが、どのように知性を示す他のタスクを実行することができるのかについて、現在のアイデアをいくつか紹介する。,人工知能はすごい進化を遂げています。その中でも、OpenAIのGPTシリーズという大きな言語モデルの開発が特に注目されています。この講演では、数学や物理学に詳しくない人でも理解できるように、その歴史や現在の状況を簡単に説明します。さらに、この言語モデルはどのように動いているのか、次に来る単語を予測するだけでなく、他の知的なタスクもこなすことができるのかについて、いくつかのアイデアを紹介します。,"[{'Keyword': '人工知能', 'Description': '人工知能は、人間の知能をコンピュータやシステムに模倣し、問題解決や学習能力を持たせる技術のことです。機械学習や深層学習などの手法を用いて、データから自動的に学習し、知識を獲得します。'}, {'Keyword': '大規模言語モデル', 'Description': '大規模言語モデル（LLM）は、大量のテキストデータを用いて学習された言語モデルのことです。GPTシリーズなどのLLMは、自然言語処理のタスクにおいて高い性能を発揮し、文章生成や文章の意味理解などの応用が可能です。'}, {'Keyword': '変換器アーキテクチャ', 'Description': '変換器アーキテクチャは、自然言語処理のためのニューラルネットワークのアーキテクチャの一種です。特に、Transformerと呼ばれるモデルが代表的で、文章中の単語や文の関係性を考慮しながら処理を行います。'}, {'Keyword': '機械学習', 'Description': '機械学習は、コンピュータがデータから自動的に学習し、予測や判断を行う技術のことです。統計学や最適化手法などの理論を応用し、データのパターンや関係性を抽出してモデルを構築します。'}, {'Keyword': '深層学習', 'Description': '深層学習は、多層のニューラルネットワークを用いて学習や予測を行う機械学習の手法の一つです。特に、畳み込みニューラルネットワークやリカレントニューラルネットワークなどを用いて、高度な表現学習を行います。'}]",23.961537837982178
http://arxiv.org/abs/2307.07420v1,Named entity recognition using GPT for identifying comparable companies,"For both public and private firms, comparable companies analysis is widelyused as a method for company valuation. In particular, the method is of greatvalue for valuation of private equity companies. The several approaches to thecomparable companies method usually rely on a qualitative approach toidentifying similar peer companies, which tends to use established industryclassification schemes and/or analyst intuition and knowledge. However, morequantitative methods have started being used in the literature and in theprivate equity industry, in particular, machine learning clustering, andnatural language processing (NLP). For NLP methods, the process consists ofextracting product entities from e.g., the company's website or companydescriptions from some financial database system and then to perform similarityanalysis. Here, using companies descriptions/summaries from publicly availablecompanies' Wikipedia websites, we show that using large language models (LLMs),such as GPT from openaAI, has a much higher precision and success rate thanusing the standard named entity recognition (NER) which uses manual annotation.We demonstrate quantitatively a higher precision rate, and show that,qualitatively, it can be used to create appropriate comparable companies peergroups which can then be used for equity valuation.","['Computation and Language', 'Artificial Intelligence', 'Neural and Evolutionary Computing']",['Eurico Covas'],http://arxiv.org/pdf/2307.07420v1,2023-07-11 16:48:16+00:00,類似企業識別のためのGPTを用いた固有表現認識,類似企業比較分析は、公開企業、非公開企業を問わず、企業評価の手法として広く利用されている。特に、プライベート・エクイティ企業のバリュエーションにおいて大きな価値を持つ。類似会社比較法へのいくつかのアプローチは、通常、類似同業他社を特定するための定性的アプローチに依存しており、確立された業界分類スキームやアナリストの直感や知識を使用する傾向がある。しかし、文献やプライベート・エクイティ業界では、より定量的な手法、特に機械学習によるクラスタリングや自然言語処理（NLP）が使用され始めている。NLP法では、例えば企業のウェブサイトや金融データベース・システムからの企業説明から製品エンティティを抽出し、類似性分析を行う。ここでは、公開されている企業のウィキペディアのウェブサイトから企業の説明／要約を使用し、openaAIのGPTのような大規模言語モデル（LLM）を使用することで、手動アノテーションを使用する標準的な名前付きエンティティ認識（NER）を使用するよりもはるかに高い精度と成功率を持つことを示す。,似たような会社同士を比べて分析する方法は、公開されている会社も非公開の会社も関係なく、会社の評価に広く使われています。特に、プライベート・エクイティ（民間資本）会社の価値を評価する際に重要な役割を果たします。類似会社比較法には、いくつかのアプローチがありますが、通常は同じ業界の会社を探すために、業界の分類やアナリストの知識を使います。しかし、最近では、より数値的な方法、特に機械学習や自然言語処理を使った手法が使われ始めています。自然言語処理では、企業のウェブサイトや金融データベースから企業の説明や製品情報を抽出し、類似性を分析します。この研究では、ウィキペディアの企業の説明を使って、大規模な言語モデルを使うことで、従来の方法よりも高い精度で類似性を認識できることを示しています。,"[{'Keyword': '類似企業比較分析', 'Description': '類似企業比較分析は、公開企業、非公開企業を問わず、企業評価の手法として広く利用されている。特に、プライベート・エクイティ企業のバリュエーションにおいて大きな価値を持つ。'}, {'Keyword': '類似会社比較法', 'Description': '類似会社比較法へのいくつかのアプローチは、通常、類似同業他社を特定するための定性的アプローチに依存しており、確立された業界分類スキームやアナリストの直感や知識を使用する傾向がある。'}, {'Keyword': '機械学習', 'Description': '機械学習は、データからパターンや規則性を学習し、予測や意思決定を行うためのアルゴリズムや手法の総称である。類似企業比較分析においては、クラスタリングや自然言語処理（NLP）などの機械学習手法が使用されることがある。'}, {'Keyword': '自然言語処理（NLP）', 'Description': '自然言語処理（NLP）は、人間が日常的に使用する自然言語（例：日本語）をコンピュータが処理するための技術の総称である。類似企業比較分析においては、企業のウェブサイトや金融データベースからの情報を抽出し、類似性分析を行う際に使用される。'}, {'Keyword': '大規模言語モデル（LLM）', 'Description': '大規模言語モデル（LLM）は、巨大なテキストデータを学習して自然言語の理解や生成を行うモデルである。類似企業比較分析においては、企業の説明や要約を処理し、名前付きエンティティ認識（NER）などのタスクに使用される。'}]",25.830618858337402
http://arxiv.org/abs/2307.05081v1,Argumentative Segmentation Enhancement for Legal Summarization,"We use the combination of argumentative zoning [1] and a legal argumentativescheme to create legal argumentative segments. Based on the argumentativesegmentation, we propose a novel task of classifying argumentative segments oflegal case decisions. GPT-3.5 is used to generate summaries based onargumentative segments. In terms of automatic evaluation metrics, our methodgenerates higher quality argumentative summaries while leaving out lessrelevant context as compared to GPT-4 and non-GPT models.",['Computation and Language'],"['Huihui Xu', 'Kevin Ashley']",http://arxiv.org/pdf/2307.05081v1,2023-07-11 07:29:18+00:00,法的要約のための論証的セグメンテーションの強化,本稿では、論証ゾーニング[1]と法的論証スキームを組み合わせて、法的論証セグメントを作成する。このargumentative segmentationに基づき、判例のargumentative segmentを分類するという新しいタスクを提案する。GPT-3.5は論証セグメントに基づいて要約を生成するために使用される。自動評価指標の観点から、本手法はGPT-4や非GPTモデルと比較して、関連性の低い文脈を省きつつ、より質の高い論証的要約を生成する。,この論文では、法律の議論を分かりやすくするために、論証ゾーニングと法的論証スキームを使って法的な議論を整理します。そして、その整理した議論を使って、新しいタスクを提案します。このタスクでは、判例（法律の例）の議論を分類します。また、GPT-3.5というコンピュータープログラムを使って、議論の要点をまとめることもできます。この手法は、GPT-4や他のプログラムと比べて、関係のない情報を省いて、より良い要約を作ることができます。,"[{'Keyword': '論証ゾーニング', 'Description': '論証の構造を分析し、論証の要素を適切に区別する手法。'}, {'Keyword': '法的論証スキーム', 'Description': '法的な論証の構造を表現するための枠組みやモデル。'}, {'Keyword': 'argumentative segmentation', 'Description': 'テキストを論証のセグメントに分割すること。'}, {'Keyword': 'GPT-3.5', 'Description': 'OpenAIが開発した自然言語処理モデルのバージョン。'}, {'Keyword': '論証的要約', 'Description': '論証の要点を短くまとめた文章。'}]",11.239234209060669
http://arxiv.org/abs/2307.05628v1,DNAGPT: A Generalized Pretrained Tool for Multiple DNA Sequence Analysis Tasks,"The success of the GPT series proves that GPT can extract general informationfrom sequences, thereby benefiting all downstream tasks. This motivates us touse pre-trained models to explore the hidden information in DNA sequences.However, data and task requirements in DNA sequence analysis are complexity anddiversity as DNA relevant data includes different types of information, such assequences, expression levels, etc, while there is currently no modelspecifically designed for these characteristics. Hereby, we present DNAGPT, ageneralized foundation model pre-trained on over 10 billion base pairs from 9species which can be fine-tuned for any DNA sequence analysis task. Our modelcan simultaneously process or output DNA sequences and numbers. In addition,our unique token design allows users to design prompts according to their owntask requirements, making it applicable to any type of task. We have evaluatedour model on classification, regression, and generation tasks. We demonstratethat DNAGPT benefits from pre-training, and therefore can bring performancegains to any downstream task. Our model is not only a new attempt in the fieldof genomes analysis, but also provides a new direction for the application offoundation models in biology.","['Genomics', 'Machine Learning']","['Daoan Zhang', 'Weitong Zhang', 'Bing He', 'Jianguo Zhang', 'Chenchen Qin', 'Jianhua Yao']",http://arxiv.org/pdf/2307.05628v1,2023-07-11 06:30:43+00:00,DNAGPT：複数のDNA配列解析タスクのための一般化された事前学習ツール,GPTシリーズの成功は、GPTが配列から一般的な情報を抽出できることを証明しており、それによって下流のすべてのタスクに利益をもたらす。しかし、DNA配列解析におけるデータおよびタスクの要件は、DNA関連データには配列、発現レベルなどの様々なタイプの情報が含まれるため、複雑かつ多様である。本論文では、9種100億塩基対以上で事前学習された一般化基礎モデルDNAGPTを紹介する。このモデルはDNA配列と数値を同時に処理・出力することができる。また、独自のトークン設計により、ユーザは自分のタスク要件に応じてプロンプトを設計することができ、あらゆるタイプのタスクに適用可能です。このモデルを分類、回帰、生成タスクで評価した。その結果、DNAGPTは事前学習から恩恵を受け、あらゆる下流タスクに性能向上をもたらすことが実証された。我々のモデルは、ゲノム解析の分野での新しい試みであるだけでなく、生物学における基礎モデルの応用に新しい方向性を与えるものである。,GPTシリーズの成功は、GPTがいろんな情報を抽出できることを証明していて、それが他のタスクにも役に立っていることを意味しています。でも、DNAのデータとタスクは難しくていろんな種類の情報が含まれているんです。この論文では、DNAGPTというモデルを紹介します。このモデルはDNAのデータと数字を同時に処理できるんです。また、ユーザーは自分のタスクに合わせてプロンプトを作ることができます。このモデルは分類や回帰、生成のタスクで評価されました。その結果、DNAGPTは事前学習からいい結果を出して、いろんなタスクで性能が向上することがわかりました。このモデルはゲノム解析の分野で新しい試みであり、生物学においても新しい方向性を与えるものです。,"[{'Keyword': 'GPTシリーズ', 'Description': 'GPTシリーズは、自然言語処理のためのトランスフォーマーモデルのシリーズであり、大規模なテキストデータを学習して生成やタスク解決に利用することができる。'}, {'Keyword': 'DNA配列解析', 'Description': 'DNA配列解析は、DNAの塩基配列を解読し、その情報を解析するプロセスであり、遺伝子の機能や疾患の関連性を調査するために重要な手法である。'}, {'Keyword': 'DNAGPT', 'Description': 'DNAGPTは、DNA配列解析において事前学習された一般化基礎モデルであり、DNA配列と数値を同時に処理・出力することができる。'}, {'Keyword': 'トークン設計', 'Description': 'トークン設計は、テキストデータをトークンと呼ばれる小さな単位に分割する方法であり、モデルがテキストを理解しやすくするために重要な要素である。'}, {'Keyword': '下流タスク', 'Description': '下流タスクは、モデルが学習した知識や能力を活用して、具体的な問題を解決するタスクのことであり、GPTシリーズやDNAGPTの性能向上の評価に利用される。'}]",16.681107997894287
http://arxiv.org/abs/2307.10195v1,"ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown","The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety ofdomains has become a topic of much discussion in the scientific community andsociety at large. Large Language Models (LLMs), e.g., BERT, Bard, GenerativePre-trained Transformers (GPTs), LLaMA, etc., have the ability to takeinstructions, or prompts, from users and generate answers and solutions basedon very large volumes of text-based training data. This paper assesses theimpact and potential impact of ChatGPT on the field of digital forensics,specifically looking at its latest pre-trained LLM, GPT-4. A series ofexperiments are conducted to assess its capability across several digitalforensic use cases including artefact understanding, evidence searching, codegeneration, anomaly detection, incident response, and education. Across thesetopics, its strengths and risks are outlined and a number of generalconclusions are drawn. Overall this paper concludes that while there are somepotential low-risk applications of ChatGPT within digital forensics, many areeither unsuitable at present, since the evidence would need to be uploaded tothe service, or they require sufficient knowledge of the topic being asked ofthe tool to identify incorrect assumptions, inaccuracies, and mistakes.However, to an appropriately knowledgeable user, it could act as a usefulsupporting tool in some circumstances.","['Cryptography and Security', 'Artificial Intelligence', 'Computation and Language']","['Mark Scanlon', 'Frank Breitinger', 'Christopher Hargreaves', 'Jan-Niclas Hilgert', 'John Sheppard']",http://arxiv.org/pdf/2307.10195v1,2023-07-10 20:07:30+00:00,デジタル・フォレンジック調査のためのChatGPT：良いこと、悪いこと、そして未知のこと,"ChatGPT(GPT-3.5,GPT-4)の様々な領域への破壊的な応用は、科学コミュニティや社会全体で多くの議論のトピックとなっている。BERT、Bard、GenerativePre-trained Transformers (GPTs)、LLaMAなどの大規模言語モデル(LLMs)は、ユーザからの指示(プロンプト)を受け取り、非常に大量のテキストベースの学習データに基づいて回答や解答を生成する能力を持っている。本稿では、ChatGPTがデジタル・フォレンジックの分野に与える影響とその可能性を評価し、特に最新の事前学習済みLLMであるGPT-4に注目する。一連の実験では、人工物の理解、証拠検索、コード生成、異常検知、インシデント対応、教育など、いくつかのデジタルフォレンジックのユースケースにわたってその能力を評価する。これらのトピックについて、その長所とリスクを概説し、多くの一般的結論を導き出す。全体として本稿では、デジタル・フォレンジック内でChatGPTを低リスクで利用できる可能性はあるものの、その多くは、証拠をサービスにアップロードする必要があるため、現時点では適さないか、誤った仮定、不正確さ、間違いを特定するために、ツールに求められるトピックに関する十分な知識が必要であると結論付けている。",ChatGPT（GPT-3.5、GPT-4）は、科学のコミュニティや社会でたくさん話題になっているんだよ。大きな言語モデル（LLMs）の一つであるBERTやBard、Generative Pre-trained Transformers（GPTs）、LLaMAは、たくさんのテキストを学習して、ユーザーの指示に基づいて答えや解答を生成することができるんだ。この論文では、ChatGPTがデジタル・フォレンジックという分野にどのような影響を与えるかを評価しているんだ。具体的には、人工物の理解や証拠の検索、コードの生成、異常検知、インシデント対応、教育など、デジタル・フォレンジックのいくつかの使い方を評価しているんだ。この論文では、ChatGPTを使う利点やリスクについてまとめていて、結論として、低リスクでChatGPTを使うことは可能だけど、証拠をアップロードする必要があるため、現時点では適していないことや、ツールを使うには十分な知識が必要だと述べているんだ。,"[{'Keyword': 'ChatGPT', 'Description': 'ChatGPTは、GPT-3.5やGPT-4などの大規模言語モデルの一種であり、ユーザからの指示を受け取り、テキストベースの回答や解答を生成する能力を持っている。'}, {'Keyword': '大規模言語モデル', 'Description': '大規模言語モデルは、BERT、Bard、GPTなどのようなモデルであり、非常に大量のテキストベースの学習データに基づいて回答や解答を生成する能力を持っている。'}, {'Keyword': 'デジタル・フォレンジック', 'Description': 'デジタル・フォレンジックは、コンピュータやデジタルデバイスから証拠を収集し、解析するプロセスであり、ChatGPTの能力をデジタル証拠の理解や異常検知などの分野で評価することができる。'}, {'Keyword': '事前学習済みLLM', 'Description': '事前学習済みLLMは、大規模なテキストデータセットで学習された言語モデルであり、ChatGPTのようなモデルが含まれる。これらのモデルは、指示に基づいて回答や解答を生成する能力を持っている。'}, {'Keyword': 'ユースケース', 'Description': 'ユースケースは、ChatGPTの適用範囲や使用方法の具体的な例であり、デジタル・フォレンジックのユースケースにおいては、人工物の理解、証拠検索、コード生成、異常検知、インシデント対応、教育などが評価される。'}]",21.30477285385132
http://arxiv.org/abs/2307.04858v1,AmadeusGPT: a natural language interface for interactive animal behavioral analysis,"The process of quantifying and analyzing animal behavior involves translatingthe naturally occurring descriptive language of their actions intomachine-readable code. Yet, codifying behavior analysis is often challengingwithout deep understanding of animal behavior and technical machine learningknowledge. To limit this gap, we introduce AmadeusGPT: a natural languageinterface that turns natural language descriptions of behaviors intomachine-executable code. Large-language models (LLMs) such as GPT3.5 and GPT4allow for interactive language-based queries that are potentially well suitedfor making interactive behavior analysis. However, the comprehension capabilityof these LLMs is limited by the context window size, which prevents it fromremembering distant conversations. To overcome the context window limitation,we implement a novel dual-memory mechanism to allow communication betweenshort-term and long-term memory using symbols as context pointers for retrievaland saving. Concretely, users directly use language-based definitions ofbehavior and our augmented GPT develops code based on the core AmadeusGPT API,which contains machine learning, computer vision, spatio-temporal reasoning,and visualization modules. Users then can interactively refine results, andseamlessly add new behavioral modules as needed. We benchmark AmadeusGPT andshow we can produce state-of-the-art performance on the MABE 2022 behaviorchallenge tasks. Note, an end-user would not need to write any code to achievethis. Thus, collectively AmadeusGPT presents a novel way to merge deepbiological knowledge, large-language models, and core computer vision modulesinto a more naturally intelligent system. Code and demos can be found at:https://github.com/AdaptiveMotorControlLab/AmadeusGPT.","['Human-Computer Interaction', 'Computer Vision and Pattern Recognition', 'Neurons and Cognition']","['Shaokai Ye', 'Jessy Lauer', 'Mu Zhou', 'Alexander Mathis', 'Mackenzie W. Mathis']",http://arxiv.org/pdf/2307.04858v1,2023-07-10 19:15:17+00:00,AmadeusGPT：対話型動物行動分析のための自然言語インターフェース,動物の行動を定量化し分析するプロセスでは、自然界に存在する動物の行動の記述言語を、機械が読み取り可能なコードに変換する必要がある。しかし、行動分析をコード化することは、動物の行動に対する深い理解と機械学習の技術的知識がなければ困難な場合が多い。このギャップをなくすために、我々はAmadeusGPTを紹介する。AmadeusGPTは、行動の自然言語記述を機械で実行可能なコードに変換する自然言語インターフェースである。GPT3.5やGPT4のような大規模言語モデル（LLM）は、対話的な言語ベースのクエリーを可能にし、対話的な行動分析を行うのに適している可能性があります。しかし、これらのLLMの理解能力はコンテキストウィンドウの大きさによって制限されており、遠くの会話を記憶することができない。コンテキストウィンドウの制限を克服するために、我々は、検索と保存のためのコンテキストポインタとしてシンボルを用いて、短期記憶と長期記憶の間の通信を可能にする新しいデュアルメモリ機構を実装する。具体的には、ユーザーは言語ベースの行動定義を直接使用し、我々の拡張GPTは、機械学習、コンピュータビジョン、時空間推論、および視覚化モジュールを含むコアAmadeusGPT APIに基づいてコードを開発します。ユーザーは結果をインタラクティブに改良し、必要に応じて新しい行動モジュールをシームレスに追加することができます。AmadeusGPT のベンチマークを行い、MABE 2022 ビヘイビアチャレンジタスクで最先端のパフォーマンスを発揮できることを示しました。なお、エンドユーザーはこれを達成するためにコードを書く必要はありません。このように、アマデウスGPTは、深い生物学的知識、大規模な言語モデル、およびコアコンピュータビジョンモジュールを、より自然なインテリジェントシステムに統合する新しい方法を提示しています。コードとデモはhttps://github.com/AdaptiveMotorControlLab/AmadeusGPT。,動物の行動を調べるためには、動物の行動をコンピュータが理解できる形に変換する必要があります。しかし、それは難しいことです。そこで、私たちはAmadeusGPTという新しいシステムを使います。AmadeusGPTは、動物の行動を自然な言葉で説明し、コンピュータが理解できるコードに変換することができます。大きな言語モデルを使って、対話的な質問や分析ができます。ただし、このモデルには限界があり、長い会話を覚えることはできません。そのため、私たちは新しいデュアルメモリ機構を使って、情報を保存し、使いやすくします。ユーザーは自分の言葉で行動を定義し、AmadeusGPTはそれをコードに変換します。さらに、結果を修正したり、新しい行動を追加したりすることもできます。AmadeusGPTは、MABE 2022 ビヘイビアチャレンジタスクで最高のパフォーマンスを示しました。エンドユーザーはコードを書く必要はありません。AmadeusGPTは、生物学の知識と言語モデルを組み合わせて、より自然なインテリジェントシステムを作るための新しい方法です。詳細はhttps://github.com/AdaptiveMotorControlLab/AmadeusGPTをご覧ください。,"[{'Keyword': '行動分析', 'Description': '動物の行動を定量化し分析するプロセス。動物の行動の記述言語を機械が読み取り可能なコードに変換する必要がある。'}, {'Keyword': '自然言語インターフェース', 'Description': '行動の自然言語記述を機械で実行可能なコードに変換するインターフェース。AmadeusGPTはその一例。'}, {'Keyword': '大規模言語モデル（LLM）', 'Description': 'GPT3.5やGPT4のような大規模な言語モデル。対話的な言語ベースのクエリーを可能にし、対話的な行動分析に適している。'}, {'Keyword': 'デュアルメモリ機構', 'Description': '短期記憶と長期記憶の間の通信を可能にする新しいメモリ機構。コンテキストポインタとしてシンボルを用いる。'}, {'Keyword': '拡張GPT', 'Description': '機械学習、コンピュータビジョン、時空間推論、および視覚化モジュールを含むAmadeusGPTの拡張版。'}]",17.171844959259033
http://arxiv.org/abs/2307.04346v1,Can Large Language Models Write Good Property-Based Tests?,"Property-based testing (PBT), while an established technique in the softwaretesting research community, is still relatively underused in real-worldsoftware. Pain points in writing property-based tests include implementingdiverse random input generators and thinking of meaningful properties to test.Developers, however, are more amenable to writing documentation; plenty oflibrary API documentation is available and can be used as natural languagespecifications for property-based tests. As large language models (LLMs) haverecently shown promise in a variety of coding tasks, we explore the potentialof using LLMs to synthesize property-based tests. We call our approach PBT-GPT,and propose three different strategies of prompting the LLM for PBT. Wecharacterize various failure modes of PBT-GPT and detail an evaluationmethodology for automatically synthesized property-based tests. PBT-GPTachieves promising results in our preliminary studies on sample Python libraryAPIs in $\texttt{numpy}$, $\texttt{networkx}$, and $\texttt{datetime}$.",['Software Engineering'],"['Vasudev Vikram', 'Caroline Lemieux', 'Rohan Padhye']",http://arxiv.org/pdf/2307.04346v1,2023-07-10 05:09:33+00:00,大規模言語モデルは優れた特性テストを書けるか？,プロパティベースのテスト（PBT）は、ソフトウェアテストの研究コミュニティでは確立された手法であるが、実世界のソフトウェアではまだあまり使用されていない。しかし、開発者は、ドキュメントを書くことに従順である。多くのライブラリAPIドキュメントが利用可能であり、プロパティベースのテストのための自然言語仕様として使用することができる。最近、大規模言語モデル（LLM）が様々なコーディングタスクにおいて有望であることが示されたので、我々は、プロパティベースのテストを合成するためにLLMを使用する可能性を探る。我々のアプローチをPBT-GPTと呼び、PBTのためにLLMを促す3つの異なる戦略を提案する。PBT-GPTの様々な失敗モードを特徴付け、自動的に合成された特性ベースのテストの評価方法を詳述する。PBT-GPTは、$texttt{numpy}$、$texttt{networkx}$、$texttt{datetime}$のサンプルPythonライブラリAPIに対する予備研究で有望な結果を得た。,プロパティベースのテスト（PBT）は、ソフトウェアのテスト方法の一つだよ。でも、まだ実際のソフトウェアであまり使われていないんだ。でも、開発者たちはドキュメントを書くのが得意なんだ。たくさんのライブラリAPIのドキュメントがあって、それを使ってプロパティベースのテストのためのルールを作ることができるんだ。最近、大きな言語モデル（LLM）が、いろんなプログラミングの仕事で使えることがわかったから、LLMを使ってプロパティベースのテストを作る方法を考えてみようと思う。私たちのアプローチはPBT-GPTと呼ばれていて、PBTのためにLLMを使う３つの戦略を提案するんだ。PBT-GPTのいろんな失敗の仕方を調べて、自動的に作られたプロパティベースのテストを評価する方法を詳しく説明するよ。PBT-GPTは、サンプルのPythonライブラリAPIである「numpy」や「networkx」、「datetime」に対して、初期の研究でいい結果が出ているんだ。,"[{'Keyword': 'プロパティベースのテスト', 'Description': 'ソフトウェアのテスト手法で、プロパティに基づいてテストケースを生成し、ソフトウェアの正確性を検証する手法。'}, {'Keyword': 'ドキュメント', 'Description': 'ソフトウェア開発者が作成するテキストファイルで、ソフトウェアの機能や使用方法などを記述する。'}, {'Keyword': 'APIドキュメント', 'Description': 'ソフトウェアのライブラリやフレームワークの機能や使い方を説明したドキュメント。プロパティベースのテストにおいて自然言語仕様として利用できる。'}, {'Keyword': '大規模言語モデル', 'Description': '巨大なデータセットを用いて訓練された機械学習モデルで、自然言語処理やコーディングなどのタスクにおいて高い性能を発揮する。'}, {'Keyword': 'PBT-GPT', 'Description': 'プロパティベースのテストを合成するために大規模言語モデルを使用するアプローチ。3つの異なる戦略を提案し、自動的に合成された特性ベースのテストを評価する。'}]",17.33473825454712
http://arxiv.org/abs/2307.03489v1,Every non-signalling channel is common-cause realizable,"In this work we show that the set of non-signalling resources of alocally-tomographic generalised probabilistic theory (GPT), such as quantum andclassical theory, coincides with its set of GPT-common-cause realizableresources, where the common causes come from an associated GPT. From a causalperspective, this result provides a reason for, in the study of resourcetheories of common-cause processes, taking the non-signalling channels as theresources of the enveloping theory. This answers a critical open question inRef.~\cite{schmid2020postquantum}. An immediate corollary of our result is thatevery non-signalling assemblage is realizable in a GPT, answering in theaffirmative the question posed in Ref.~\cite{cavalcanti2022post}.",['Quantum Physics'],"['Paulo J. Cavalcanti', 'John H. Selby', 'Ana Belén Sainz']",http://arxiv.org/pdf/2307.03489v1,2023-07-07 09:56:14+00:00,すべての非シグナリングチャネルは共通原因実現可能,本研究では、量子論や古典論のような局所的トモグラフィーの一般化確率論(GPT)の非シグナリング資源の集合は、GPT-共通原因実現可能資源の集合と一致することを示す。この結果は、因果論的な観点から、共通原因過程のリソース理論の研究において、非シグナリングチャネルを包絡理論のリソースとする理由を与える。これは、Ref.~cite{schmid2020postquantum}における重要な未解決問題の答えである。この結果の直接的な帰結は、すべての非シグナリング集合がGPTで実現可能であるということであり、Ref.~cite{cavalcanti2022post}で提起された疑問の肯定的な答えとなります。,この研究では、量子物理学や古典物理学のような特定の理論の一般化された確率の考え方を調べました。その結果、非シグナリングと呼ばれる特殊な資源の集まりは、共通の原因によって起こる現象の資源の集まりと同じだということがわかりました。この結果は、共通の原因によるプロセスを研究する際に、非シグナリングのチャネルが重要な資源となる理由を示しています。これは、以前の研究で提起された問題に対する重要な答えとなります。具体的な結果は、非シグナリングの集まりはすべて一般化された確率の理論で実現することができるということです。これは、以前の研究で提起された疑問に肯定的な答えとなります。,"[{'Keyword': '局所的トモグラフィー', 'Description': '局所的トモグラフィーは、量子論や古典論における物理的な現象を測定する手法です。この手法は、物理系の状態を特定するために使用され、量子情報処理や量子通信などの分野で重要な役割を果たしています。'}, {'Keyword': '一般化確率論', 'Description': '一般化確率論（GPT）は、古典論や量子論のような物理理論の一般化です。GPTは、確率的な現象を記述するための枠組みを提供し、量子力学以外の理論を統一的に扱うことができます。GPTは、量子情報理論や量子グラフィティなどの研究で広く使用されています。'}, {'Keyword': '非シグナリング資源', 'Description': '非シグナリング資源は、情報の伝達においてシグナルの送信を行わない資源です。これは、情報の伝達における因果関係を超えた相関を表現するために使用されます。非シグナリング資源は、量子通信や量子暗号などの分野で重要な役割を果たしています。'}, {'Keyword': 'GPT-共通原因実現可能資源', 'Description': 'GPT-共通原因実現可能資源は、一般化確率論（GPT）において共通原因過程を実現するための資源です。これは、非シグナリング資源としての特性を持ちながら、GPTの枠組みで因果関係を表現することができます。GPT-共通原因実現可能資源は、量子情報理論や因果論的な観点からの研究で重要な役割を果たしています。'}, {'Keyword': '包絡理論', 'Description': '包絡理論は、物理的な現象を包括的かつ一般的に記述するための理論です。包絡理論は、異なる物理理論やモデルを統一的に扱うことができ、因果論的な観点からの研究において重要な役割を果たしています。包絡理論は、量子情報理論や統計力学などの分野で広く使用されています。'}]",29.504313707351685
http://arxiv.org/abs/2307.03351v1,Augmented Reality for Maintenance Tasks with ChatGPT for Automated Text-to-Action,"Advancements in sensor technology, artificial intelligence (AI), andaugmented reality (AR) have unlocked opportunities across various domains. ARand large language models like GPT have witnessed substantial progress and areincreasingly being employed in diverse fields. One such promising applicationis in operations and maintenance (O&M). O&M tasks often involve complexprocedures and sequences that can be challenging to memorize and executecorrectly, particularly for novices or under high-stress situations. Bymarrying the advantages of superimposing virtual objects onto the physicalworld, and generating human-like text using GPT, we can revolutionize O&Moperations. This study introduces a system that combines AR, Optical CharacterRecognition (OCR), and the GPT language model to optimize user performancewhile offering trustworthy interactions and alleviating workload in O&M tasks.This system provides an interactive virtual environment controlled by the Unitygame engine, facilitating a seamless interaction between virtual and physicalrealities. A case study (N=15) is conducted to illustrate the findings andanswer the research questions. The results indicate that users can completesimilarly challenging tasks in less time using our proposed AR and AI system.Moreover, the collected data also suggests a reduction in cognitive load and anincrease in trust when executing the same operations using the AR and AIsystem.",['Human-Computer Interaction'],"['Fang Xu', 'Tri Nguyen', 'Jing Du']",http://arxiv.org/pdf/2307.03351v1,2023-07-07 02:18:17+00:00,ChatGPTによるテキストからアクションへの自動化により、メンテナンスタスクの拡張現実を実現,センサー技術、人工知能(AI)、拡張現実(AR)の進歩は、様々な領域でチャンスを引き出している。ARやGPTのような大規模言語モデルは大きな進歩を遂げ、様々な分野で採用されるようになってきている。そのような有望なアプリケーションの1つは、運用と保守（O&M）である。O&Mタスクは、複雑な手順やシーケンスを含むことが多く、特に初心者や高ストレス状況下では、記憶し、正しく実行することが困難な場合がある。物理世界に仮想物体を重ね合わせ、GPTを用いて人間のようなテキストを生成するという利点を生かすことで、O&M業務に革命をもたらすことができる。本研究では、AR、光学式文字認識(OCR)、GPT言語モデルを組み合わせることで、ユーザのパフォーマンスを最適化しつつ、信頼できるインタラクションを提供し、O&M作業における作業負荷を軽減するシステムを紹介する。このシステムは、Unitygameエンジンによって制御されるインタラクティブな仮想環境を提供し、仮想現実と物理現実の間のシームレスなインタラクションを促進する。本システムは、Unityゲームエンジンによって制御されるインタラクティブな仮想環境を提供し、仮想現実と物理現実のシームレスなインタラクションを促進する。その結果、提案したAR・AIシステムを用いることで、ユーザはより短時間で同様の難易度のタスクを完了できることが示された。さらに、収集されたデータは、AR・AIシステムを用いて同じ操作を実行する際の認知的負荷の軽減と信頼のincreaseも示唆している。,センサーの技術や人工知能（AI）、拡張現実（AR）は、たくさんの分野で新しいチャンスを生み出しています。ARやGPTといった言語モデルは、とても進化してきていて、いろんな場所で使われるようになりました。その中でも、O&Mという仕事に応用することが期待されています。O&Mの仕事は、手順や順番が複雑で、初心者やストレスのある状況では、覚えたり正しく実行したりするのが難しいことがあります。しかし、ARを使って仮想の物体を現実の世界に重ねたり、GPTを使って人間のようなテキストを作ったりすることで、O&Mの仕事に革新をもたらすことができます。この研究では、ARや光学式文字認識（OCR）、GPTの言語モデルを組み合わせて、ユーザーのパフォーマンスを向上させながら、信頼できるインタラクションを提供し、O&Mの作業負荷を軽くするシステムを紹介します。このシステムは、Unityというゲームのエンジンを使って、仮想の環境を作り出し、仮想と現実の間でスムーズにやり取りできるようにします。実際にこのシステムを使ってみると、同じ難しい仕事でも、時間を短縮できることがわかりました。また、データの収集結果からも、このAR・AIシステムを使うことで、認識の負荷が軽くなり、信頼性も高まることが示されました。,"[{'Keyword': 'センサー技術', 'Description': 'センサー技術は、物理的な変化や状態を検知し、それに応じて情報を収集する技術です。センサーは、温度、圧力、光、音などのさまざまなパラメータを検出することができます。センサー技術は、自動車、医療、環境モニタリングなどのさまざまな分野で利用されています。'}, {'Keyword': '人工知能(AI)', 'Description': '人工知能（AI）は、コンピュータシステムが人間のような知能を持つことを可能にする技術です。AIは、機械学習、深層学習、自然言語処理などの手法を使用して、データを解析し、意思決定を行います。AIは、自動運転、音声認識、画像認識などのさまざまな応用分野で活用されています。'}, {'Keyword': '拡張現実(AR)', 'Description': '拡張現実（AR）は、現実の環境に仮想的な情報やオブジェクトを重ね合わせる技術です。ARは、スマートフォンやヘッドセットなどのデバイスを使用して、現実世界と仮想世界を結びつけます。ARは、ゲーム、教育、訓練などのさまざまな分野で活用されています。'}, {'Keyword': '運用と保守（O&M）', 'Description': '運用と保守（O&M）は、システムや設備の正常な運営や保守を行う活動です。O&Mタスクには、監視、トラブルシューティング、予防保守などが含まれます。O&Mは、製造業、エネルギー業界、情報技術などのさまざまな分野で重要な役割を果たしています。'}, {'Keyword': '光学式文字認識(OCR)', 'Description': '光学式文字認識（OCR）は、印刷されたテキストをデジタルデータに変換する技術です。OCRは、スキャナやカメラを使用して、紙の文書や画像から文字を読み取ります。OCRは、文書のデジタル化やテキストの翻訳などのさまざまな応用分野で利用されています。'}]",29.628801107406616
http://arxiv.org/abs/2307.03027v1,Improving Retrieval-Augmented Large Language Models via Data Importance Learning,"Retrieval augmentation enables large language models to take advantage ofexternal knowledge, for example on tasks like question answering and dataimputation. However, the performance of such retrieval-augmented models islimited by the data quality of their underlying retrieval corpus. In thispaper, we propose an algorithm based on multilinear extension for evaluatingthe data importance of retrieved data points. There are exponentially manyterms in the multilinear extension, and one key contribution of this paper is apolynomial time algorithm that computes exactly, given a retrieval-augmentedmodel with an additive utility function and a validation set, the dataimportance of data points in the retrieval corpus using the multilinearextension of the model's utility function. We further proposed an even moreefficient ({\epsilon}, {\delta})-approximation algorithm. Our experimentalresults illustrate that we can enhance the performance of large language modelsby only pruning or reweighting the retrieval corpus, without requiring furthertraining. For some tasks, this even allows a small model (e.g., GPT-JT),augmented with a search engine API, to outperform GPT-3.5 (without retrievalaugmentation). Moreover, we show that weights based on multilinear extensioncan be computed efficiently in practice (e.g., in less than ten minutes for acorpus with 100 million elements).","['Machine Learning', 'Computation and Language', 'Information Retrieval']","['Xiaozhong Lyu', 'Stefan Grafberger', 'Samantha Biegel', 'Shaopeng Wei', 'Meng Cao', 'Sebastian Schelter', 'Ce Zhang']",http://arxiv.org/pdf/2307.03027v1,2023-07-06 14:44:07+00:00,データ重要度学習による検索支援大規模言語モデルの改善,"検索補強は、例えば質問応答やデータ入力のようなタスクにおいて、大規模な言語モデルが外部の知識を利用することを可能にする。しかし、このような検索補強モデルの性能は、その基礎となる検索コーパスのデータ品質によって制限される。本論文では、検索されたデータ点のデータ重要度を評価するための、多重線形拡張に基づくアルゴリズムを提案する。多直線拡張には指数関数的に多くの項があり、本論文の重要な貢献の一つは、加法的効用関数を持つ検索補遺モデルと検証集合が与えられた場合に、モデルの効用関数の多直線拡張を用いて、検索コーパス中のデータ点のデータ重要度を正確に計算する多項式時間アルゴリズムである。さらに、さらに効率的な({epsilon}, {δ})近似アルゴリズムを提案した。我々の実験結果は、更なる学習を必要とせず、検索コーパスの刈り込みや重み付けを行うだけで、大規模言語モデルの性能を向上できることを示している。いくつかのタスクでは、これにより、検索エンジンAPIで拡張された小さなモデル（例えばGPT-JT）が、GPT-3.5（検索拡張なし）を上回ることさえできる。さらに、マルチリニア拡張に基づく重みは、実際に効率的に計算できることを示す（例えば、1億の要素を持つコーパスでは10分以内）。",検索補強とは、質問応答やデータ入力などの仕事で、大きな言語モデルが外部の知識を使って助けてくれることです。しかし、その助けを受けるモデルの性能は、使われるデータの品質によって制限されます。この論文では、データの重要度を評価するための新しい方法を提案しています。この方法は、たくさんの計算を効率的に行うことができます。実験の結果から、この方法を使うと、大きな言語モデルの性能を向上させることができることがわかりました。例えば、小さなモデルでも、大きなモデルを上回ることができます。また、この方法は、実際にはとても速く計算することができます。,"[{'Keyword': '検索補強', 'Description': '検索補強は、外部の知識を利用することを可能にする大規模な言語モデルが、質問応答やデータ入力などのタスクにおいて使用される手法です。'}, {'Keyword': 'データ品質', 'Description': '検索補強モデルの性能は、その基礎となる検索コーパスのデータ品質によって制限されます。データ品質の向上により、モデルの精度や性能を向上させることができます。'}, {'Keyword': '多重線形拡張', 'Description': '検索されたデータ点のデータ重要度を評価するためのアルゴリズムであり、指数関数的に多くの項を持ちます。加法的効用関数と検証集合が与えられた場合に、検索コーパス中のデータ点のデータ重要度を正確に計算することができます。'}, {'Keyword': '({epsilon}, {δ})近似アルゴリズム', 'Description': '効率的な近似アルゴリズムであり、({epsilon}, {δ})の制約下で正確な結果を得ることができます。このアルゴリズムを使用することで、計算時間を短縮しながらも正確な結果を得ることができます。'}, {'Keyword': '重み付け', 'Description': '検索コーパスのデータ点に重みを付けることで、データの重要度を表現します。重要なデータに高い重みを付けることで、検索補強モデルの性能を向上させることができます。'}]",18.457200288772583
http://arxiv.org/abs/2307.04683v1,"CORE-GPT: Combining Open Access research and large language models for credible, trustworthy question answering","In this paper, we present CORE-GPT, a novel question-answering platform thatcombines GPT-based language models and more than 32 million full-text openaccess scientific articles from CORE. We first demonstrate that GPT3.5 and GPT4cannot be relied upon to provide references or citations for generated text. Wethen introduce CORE-GPT which delivers evidence-based answers to questions,along with citations and links to the cited papers, greatly increasing thetrustworthiness of the answers and reducing the risk of hallucinations.CORE-GPT's performance was evaluated on a dataset of 100 questions covering thetop 20 scientific domains in CORE, resulting in 100 answers and links to 500relevant articles. The quality of the provided answers and and relevance of thelinks were assessed by two annotators. Our results demonstrate that CORE-GPTcan produce comprehensive and trustworthy answers across the majority ofscientific domains, complete with links to genuine, relevant scientificarticles.","['Computation and Language', 'Artificial Intelligence']","['David Pride', 'Matteo Cancellieri', 'Petr Knoth']",http://arxiv.org/pdf/2307.04683v1,2023-07-06 13:41:36+00:00,CORE-GPT：オープンアクセスリサーチと大規模言語モデルを組み合わせて、信頼できる質問応答を実現する,"この論文では、GPTベースの言語モデルとCOREにある3,200万件以上のフルテキストのオープンアクセス科学論文を組み合わせた新しい質問応答プラットフォームであるCORE-GPTを紹介する。まず、GPT3.5とGPT4は、生成されたテキストの参考文献や引用文献を提供するのに信頼できないことを示す。CORE-GPTの性能は、COREの上位20の科学領域をカバーする100の質問からなるデータセットで評価され、その結果、100の回答と500の関連論文へのリンクが得られた。提供された回答の品質とリンクの関連性は、2人のアノテーターによって評価された。その結果、CORE-GPTは、大半の科学的ドメインにおいて、包括的で信頼できる回答を、本物の関連する科学論文へのリンクとともに作成できることが実証された。","この論文では、新しい質問応答プラットフォームであるCORE-GPTについて紹介します。CORE-GPTは、GPTベースの言語モデルとCOREというデータベースを組み合わせています。COREには3,200万件以上のフルテキストの科学論文があります。

まず、GPT3.5とGPT4は、生成されたテキストの参考文献や引用文献が信頼できないことがわかりました。それでCORE-GPTを作りました。CORE-GPTの性能を評価するために、100の質問を使ってテストしました。これらの質問は、科学のさまざまな分野に関するものでした。

結果として、CORE-GPTは、ほとんどの科学の分野で正確で信頼できる回答を作成することができました。さらに、回答には関連する科学論文へのリンクも付けられました。このプラットフォームは、アノテーターと呼ばれる人たちによって評価されました。

つまり、CORE-GPTは、科学の質問に対して本物の情報を提供することができるのです。","[{'Keyword': 'GPTベースの言語モデル', 'Description': 'GPTベースの言語モデルは、Generative Pre-trained Transformerの略であり、自然言語処理タスクにおいて高い性能を発揮するニューラルネットワークモデルです。大量のテキストデータを学習することで、文脈を理解し、文章を生成する能力を持ちます。'}, {'Keyword': 'オープンアクセス科学論文', 'Description': 'オープンアクセス科学論文とは、誰でも自由にアクセスできる形式で公開されている科学論文のことです。従来の有料の学術雑誌に比べて、より多くの人々に科学の知識を提供することができます。'}, {'Keyword': '質問応答プラットフォーム', 'Description': '質問応答プラットフォームは、ユーザーが質問を投げかけると、適切な回答を生成するシステムです。CORE-GPTは、GPTベースの言語モデルとオープンアクセス科学論文を組み合わせた新しい質問応答プラットフォームです。'}, {'Keyword': '参考文献', 'Description': '参考文献は、論文や研究において引用された文献のことです。参考文献は、信頼性や情報の裏付けとして重要な役割を果たします。しかし、GPTベースの言語モデルによって生成されたテキストの参考文献は信頼性に欠けることがあります。'}, {'Keyword': '関連論文', 'Description': '関連論文は、特定のテーマや研究に関連する科学論文のことです。CORE-GPTは、質問に対する回答とともに関連論文へのリンクを提供します。これにより、ユーザーはより詳細な情報や関連研究を参照することができます。'}]",25.272775888442993
http://arxiv.org/abs/2307.02779v1,Large Language Models Empowered Autonomous Edge AI for Connected Intelligence,"The evolution of wireless networks gravitates towards connected intelligence,a concept that envisions seamless interconnectivity among humans, objects, andintelligence in a hyper-connected cyber-physical world. Edge AI emerges as apromising solution to achieve connected intelligence by deliveringhigh-quality, low-latency, and privacy-preserving AI services at the networkedge. In this article, we introduce an autonomous edge AI system thatautomatically organizes, adapts, and optimizes itself to meet users' diverserequirements. The system employs a cloud-edge-client hierarchical architecture,where the large language model, i.e., Generative Pretrained Transformer (GPT),resides in the cloud, and other AI models are co-deployed on devices and edgeservers. By leveraging the powerful abilities of GPT in language understanding,planning, and code generation, we present a versatile framework thatefficiently coordinates edge AI models to cater to users' personal demandswhile automatically generating code to train new models via edge federatedlearning. Experimental results demonstrate the system's remarkable ability toaccurately comprehend user demands, efficiently execute AI models with minimalcost, and effectively create high-performance AI models through federatedlearning.","['Information Theory', 'Machine Learning', 'Networking and Internet Architecture', 'Signal Processing', 'Information Theory']","['Yifei Shen', 'Jiawei Shao', 'Xinjie Zhang', 'Zehong Lin', 'Hao Pan', 'Dongsheng Li', 'Jun Zhang', 'Khaled B. Letaief']",http://arxiv.org/pdf/2307.02779v1,2023-07-06 05:16:55+00:00,コネクテッド・インテリジェンスのための大規模言語モデルによる自律的エッジAI,ワイヤレス・ネットワークの進化はコネクテッド・インテリジェンス（超接続型サイバー・フィジカル世界における人間、モノ、インテリジェンス間のシームレスな相互接続を想定したコンセプト）に向かっています。エッジAIは、高品質、低遅延、プライバシー保護AIサービスをネットワークエッジで提供することで、コネクテッド・インテリジェンスを実現する有望なソリューションとして浮上している。本稿では、ユーザーの多様な要求を満たすために、自動的に組織化、適応、最適化を行う自律型エッジAIシステムを紹介する。このシステムは、クラウド-エッジ-クライアントの階層型アーキテクチャを採用しており、大規模な言語モデルであるGenerative Pretrained Transformer (GPT)はクラウドに存在し、その他のAIモデルはデバイスやエッジサーバーに共同配置される。言語理解、プランニング、コード生成におけるGPTの強力な能力を活用することで、エッジ連携学習によって新しいモデルを学習するためのコードを自動生成しながら、ユーザーの個人的な要求に応えるためにエッジAIモデルを効率的に調整する汎用的なフレームワークを提示する。実験結果は、システムがユーザの要求を正確に理解し、最小限のコストでAIモデルを効率的に実行し、連携学習を通じて高性能AIモデルを効率的に作成する顕著な能力を実証している。,ワイヤレス・ネットワークは、人々やものがつながっている未来の世界を作るために進化しています。エッジAIという技術は、高品質で遅延が少なく、プライバシーも守られたAIサービスを提供することで、つながった未来を実現するための有望な解決策として注目されています。この技術は、自動的に組織化や最適化ができるシステムで、クラウドとデバイスの間でAIのモデルを効率的に使うことができます。実験の結果からも、このシステムはユーザーの要求を正確に理解し、少ないコストで高性能なAIモデルを作ることができることがわかりました。,"[{'Keyword': 'ワイヤレス・ネットワーク', 'Description': 'ワイヤレス通信技術を使用して相互に接続されたデバイスやコンピュータネットワークのこと。'}, {'Keyword': 'コネクテッド・インテリジェンス', 'Description': '人間、モノ、インテリジェンスがシームレスに相互接続された超接続型サイバー・フィジカル世界を指す概念。'}, {'Keyword': 'エッジAI', 'Description': 'ネットワークのエッジで動作する人工知能（AI）システム。高品質、低遅延、プライバシー保護などの特徴を持つ。'}, {'Keyword': '自律型エッジAIシステム', 'Description': '組織化、適応、最適化を自動的に行うエッジAIシステム。ユーザーの多様な要求に応えることができる。'}, {'Keyword': 'Generative Pretrained Transformer (GPT)', 'Description': '大規模な言語モデルであり、クラウドに存在し、エッジ連携学習に活用される。言語理解、プランニング、コード生成などの能力を持つ。'}]",16.041942834854126
http://arxiv.org/abs/2307.02514v1,Exploring Multimodal Approaches for Alzheimer's Disease Detection Using Patient Speech Transcript and Audio Data,"Alzheimer's disease (AD) is a common form of dementia that severely impactspatient health. As AD impairs the patient's language understanding andexpression ability, the speech of AD patients can serve as an indicator of thisdisease. This study investigates various methods for detecting AD usingpatients' speech and transcripts data from the DementiaBank Pitt database. Theproposed approach involves pre-trained language models and Graph Neural Network(GNN) that constructs a graph from the speech transcript, and extracts featuresusing GNN for AD detection. Data augmentation techniques, including synonymreplacement, GPT-based augmenter, and so on, were used to address the smalldataset size. Audio data was also introduced, and WavLM model was used toextract audio features. These features were then fused with text features usingvarious methods. Finally, a contrastive learning approach was attempted byconverting speech transcripts back to audio and using it for contrastivelearning with the original audio. We conducted intensive experiments andanalysis on the above methods. Our findings shed light on the challenges andpotential solutions in AD detection using speech and audio data.","['Audio and Speech Processing', 'Artificial Intelligence', 'Sound']","['Hongmin Cai', 'Xiaoke Huang', 'Zhengliang Liu', 'Wenxiong Liao', 'Haixing Dai', 'Zihao Wu', 'Dajiang Zhu', 'Hui Ren', 'Quanzheng Li', 'Tianming Liu', 'Xiang Li']",http://arxiv.org/pdf/2307.02514v1,2023-07-05 12:40:11+00:00,患者の発話記録と音声データを用いたアルツハイマー病検出のためのマルチモーダルアプローチの探求,アルツハイマー病（AD）は、患者の健康に深刻な影響を与える一般的な認知症である。ADは患者の言語理解と表現能力を低下させるため、AD患者の発話はこの疾患の指標となり得る。本研究では、DementiaBank Pittデータベースの患者の発話とトランスクリプトデータを用いて、ADを検出するための様々な方法を検討する。提案する手法は、事前に訓練された言語モデルとGraph Neural Network(GNN)を含み、発話記録からグラフを構築し、AD検出のためにGNNを用いて特徴を抽出する。また、同義語置換、GPTベースのオーグメンターなどのデータ補強技術により、データセットサイズの小ささに対応した。音声データも導入され、WavLMモデルが音声特徴の抽出に用いられた。これらの特徴は、様々な方法を用いてテキスト特徴と融合された。最後に、音声トランスクリプトを音声に変換し、元の音声との対比学習に使用することで、対比学習アプローチを試みた。我々は上記の方法について集中的な実験と分析を行った。その結果、音声・音声データを用いたAD検出における課題と潜在的な解決策が明らかになった。,アルツハイマー病（AD）は、ひとつの病気で、患者の頭の中がうまく働かなくなるんだよ。ADの患者さんは、言葉を理解したり話すことが難しくなってしまうんだ。この研究では、ADを見つけるためのいろんな方法を考えてみたんだ。私たちは、患者さんの話し方や書き方を調べて、特徴を見つけるためにコンピューターを使いました。また、データの数が少ないという問題に対して、いくつかの補強技術を使ってデータを増やしました。音声データも使って、特徴を見つけるのに役立てました。最後に、音声を書き起こして、元の音声と比べることで、新しいアプローチを試してみました。私たちは、たくさんの実験や分析を行いました。その結果、音声や音声データを使ったADの検出について、問題や解決策がわかりました。,"[{'Keyword': 'アルツハイマー病', 'Description': 'アルツハイマー病（AD）は、認知症の一種であり、患者の健康に深刻な影響を与える疾患です。ADは患者の言語理解と表現能力を低下させるため、発話の特徴はADの指標となります。'}, {'Keyword': 'DementiaBank Pittデータベース', 'Description': 'DementiaBank Pittデータベースは、AD患者の発話とトランスクリプトデータを収集したデータベースです。このデータベースを使用して、ADを検出するための様々な方法が研究されています。'}, {'Keyword': 'Graph Neural Network', 'Description': 'Graph Neural Network（GNN）は、グラフ構造を持つデータに対して効果的な特徴抽出を行うためのニューラルネットワークの一種です。本研究では、GNNを使用して発話記録から特徴を抽出し、ADの検出に利用しています。'}, {'Keyword': 'データ補強技術', 'Description': 'データ補強技術は、データセットのサイズが小さい場合に、追加のデータを生成してデータセットを拡張する手法です。本研究では、同義語置換やGPTベースのオーグメンターなどのデータ補強技術を使用しています。'}, {'Keyword': 'WavLMモデル', 'Description': 'WavLMモデルは、音声データから特徴を抽出するための言語モデルです。本研究では、WavLMモデルを使用して音声特徴を抽出し、テキスト特徴と組み合わせてADの検出に利用しています。'}]",22.515469789505005

Paper_ID,Title_En,Content_En,Categories,Authors,Pdf_url,Published,Title_Ja,Content_Ja,Content_plain,Keywords,Time
http://arxiv.org/abs/2307.10811v1,"""It Felt Like Having a Second Mind"": Investigating Human-AI Co-creativity in Prewriting with Large Language Models","Prewriting is the process of discovering and developing ideas before a firstdraft, which requires divergent thinking and often implies unstructuredstrategies such as diagramming, outlining, free-writing, etc. Although largelanguage models (LLMs) have been demonstrated to be useful for a variety oftasks including creative writing, little is known about how users wouldcollaborate with LLMs to support prewriting. The preferred collaborative roleand initiative of LLMs during such a creativity process is also unclear. Toinvestigate human-LLM collaboration patterns and dynamics during prewriting, weconducted a three-session qualitative study with 15 participants in twocreative tasks: story writing and slogan writing. The findings indicated thatduring collaborative prewriting, there appears to be a three-stage iterativeHuman-AI Co-creativity process that includes Ideation, Illumination, andImplementation stages. This collaborative process champions the human in adominant role, in addition to mixed and shifting levels of initiative thatexist between humans and LLMs. This research also reports on collaborationbreakdowns that occur during this process, user perceptions of using existingLLMs during Human-AI Co-creativity, and discusses design implications tosupport this co-creativity process.","['Human-Computer Interaction', 'Artificial Intelligence', 'Computation and Language']","['Qian Wan', 'Siying Hu', 'Yu Zhang', 'Piaohong Wang', 'Bo Wen', 'Zhicong Lu']",http://arxiv.org/pdf/2307.10811v1,2023-07-20 16:55:25+00:00,「第二の心を持つように感じた」：大規模言語モデルを用いたプリライティングにおける人間とAIの共創性の調査,プリライティングとは、初稿の前にアイデアを発見し、発展させるプロセスであり、発散的思考を必要とし、多くの場合、ダイアグラム作成、アウトライニング、フリーライティングなどの非構造化戦略を意味する。ラージ・ランゲージ・モデル（LLM）は、クリエイティブ・ライティングを含む様々なタスクに有用であることが実証されているが、プリライティングをサポートするためにユーザーがLLMとどのようにコラボレーションするかについてはほとんど知られていない。また、このような創作過程におけるLLMの望ましい協調的役割や主導権についても不明である。本研究では、プリライティング時の人間とLLMの協働パターンとダイナミクスを調査するため、15人の参加者を対象に3セッションの質的研究を実施した。その結果、コラボレーティブなプリライティング時には、Ideation、Illumination、Implementationの3段階の反復的なHuman-AI Co-creativityプロセスが存在することが示された。この共同作業プロセスでは、人間とLLMの間に存在する混合的で移り変わる主導権のレベルに加え、人間が優位な役割を担っている。また、本研究では、このプロセスで発生するコラボレーションのブレークダウン、人間とLLMの共創における既存のLLMの使用に関するユーザーの認識、およびこの共創プロセスをサポートするためのデザイン上の意味についても報告する。,プリライティングは、アイデアを発見し発展させるプロセスであり、ラージ・ランゲージ・モデル（LLM）はこのプロセスをサポートするために有用です。しかし、LLMとユーザーのコラボレーションやLLMの役割についてはほとんど知られていません。本研究では、15人の参加者を対象に質的研究を行い、プリライティング時の人間とLLMの協働パターンとダイナミクスを調査しました。その結果、Ideation、Illumination、Implementationの3つの反復的なプロセスが存在することが示されました。この共同作業プロセスでは、人間が主導権を持ちながら、LLMとの混合的な役割があります。また、コラボレーションのブレークダウンや既存のLLMの使用に関するユーザーの認識、デザイン上の意味についても報告しています。,"[{'Keyword': 'プリライティング', 'Description': '初稿の前にアイデアを発見し、発展させるプロセス。ダイアグラム作成、アウトライニング、フリーライティングなどの非構造化戦略を用いる。'}, {'Keyword': 'ラージ・ランゲージ・モデル', 'Description': 'クリエイティブ・ライティングを含む様々なタスクに有用なモデル。プリライティングをサポートするためのユーザーとのコラボレーション方法は不明。'}, {'Keyword': '協働パターン', 'Description': 'プリライティング時の人間とラージ・ランゲージ・モデル（LLM）の協働のパターンとダイナミクスを調査。Ideation、Illumination、Implementationの3段階の反復的なHuman-AI Co-creativityプロセスが存在することが示された。'}, {'Keyword': '主導権', 'Description': 'プリライティング時の人間とラージ・ランゲージ・モデル（LLM）の間で存在する混合的で移り変わる主導権のレベル。人間が優位な役割を担っている。'}, {'Keyword': '共同作業プロセス', 'Description': 'プリライティング時の人間とラージ・ランゲージ・モデル（LLM）の間の共同作業プロセス。コラボレーションのブレークダウン、既存のLLMの使用に関するユーザーの認識、デザイン上の意味についても報告する。'}]",17.19285488128662
http://arxiv.org/abs/2307.11019v1,Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation,"Knowledge-intensive tasks (e.g., open-domain question answering (QA)) requirea substantial amount of factual knowledge and often rely on externalinformation for assistance. Recently, large language models (LLMs) (e.g.,ChatGPT), have demonstrated impressive prowess in solving a wide range of taskswith world knowledge, including knowledge-intensive tasks. However, it remainsunclear how well LLMs are able to perceive their factual knowledge boundaries,particularly how they behave when incorporating retrieval augmentation. In thisstudy, we present an initial analysis of the factual knowledge boundaries ofLLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially,we focus on three primary research questions and analyze them by examining QAperformance, priori judgement and posteriori judgement of LLMs. We showevidence that LLMs possess unwavering confidence in their capabilities torespond to questions and the accuracy of their responses. Furthermore,retrieval augmentation proves to be an effective approach in enhancing LLMs'awareness of knowledge boundaries, thereby improving their judgementalabilities. Additionally, we also find that LLMs have a propensity to rely onthe provided retrieval results when formulating answers, while the quality ofthese results significantly impacts their reliance. The code to reproduce thiswork is available at https://github.com/RUCAIBox/LLM-Knowledge-Boundary.","['Computation and Language', 'Information Retrieval']","['Ruiyang Ren', 'Yuhao Wang', 'Yingqi Qu', 'Wayne Xin Zhao', 'Jing Liu', 'Hao Tian', 'Hua Wu', 'Ji-Rong Wen', 'Haifeng Wang']",http://arxiv.org/pdf/2307.11019v1,2023-07-20 16:46:10+00:00,検索補強による大規模言語モデルの事実知識境界の調査,知識集約的なタスク（例えば、オープンドメインの質問応答（QA））は、かなりの量の事実知識を必要とし、しばしば外部情報に依存する。近年、大規模言語モデル(LLM)(ChatGPTなど)は、知識集約的なタスクを含む、世界知識を持つ様々なタスクを解くのに優れた能力を発揮している。しかし、LLMが事実知識の境界をどの程度認識できるのか、特に検索補強を取り入れた場合にどのような挙動を示すのかについては不明な点が多い。本研究では、LLMの事実知識境界と、検索補強がオープンドメインのQAにおいてLLMにどのような影響を与えるかについての初期分析を行う。特に、3つの主要な研究課題に焦点を当て、LLMのQAパフォーマンス、先験的判断、後験的判断を調べることによって分析する。その結果、LLMが質問に対する能力とその回答の正確さに揺るぎない自信を持っていることを示す。さらに、検索補強は、LLMの知識境界に対する認識を高め、それによって彼らの判断能力を向上させる効果的なアプローチであることが証明された。さらに、LLMは回答を作成する際に提供された検索結果に依存する傾向があるが、これらの検索結果の質はその依存度に大きく影響することもわかった。この研究を再現するコードはhttps://github.com/RUCAIBox/LLM-Knowledge-Boundary。,知識集約的なタスクにおいて、大規模言語モデル（LLM）は優れた能力を発揮しています。しかし、LLMが事実知識の境界をどの程度認識できるのか、検索補強がどのような影響を与えるのかは不明です。本研究では、LLMの事実知識境界と検索補強の影響について初期分析を行いました。その結果、LLMは質問に対する能力と回答の正確さに自信を持っています。また、検索補強はLLMの知識境界の認識を高め、判断能力を向上させる効果的なアプローチであることがわかりました。さらに、LLMは回答作成において検索結果に依存する傾向がありますが、その質は依存度に大きく影響します。,"[{'Keyword': '知識集約的なタスク', 'Description': '知識集約的なタスクは、オープンドメインの質問応答など、多くの事実知識を必要とするタスクのことです。これらのタスクはしばしば外部情報に依存しています。'}, {'Keyword': '大規模言語モデル', 'Description': '大規模言語モデルは、ChatGPTなどのモデルのことで、世界知識を持つ様々なタスクを解く能力があります。知識集約的なタスクにおいても優れたパフォーマンスを発揮します。'}, {'Keyword': '事実知識の境界', 'Description': '事実知識の境界とは、大規模言語モデルがどの程度事実知識を認識できるかを指します。この境界は、検索補強を取り入れた場合にどのように変化するかについても研究されています。'}, {'Keyword': '検索補強', 'Description': '検索補強は、大規模言語モデルの知識境界を高めるための手法です。検索結果を利用することで、モデルの判断能力を向上させることができます。'}, {'Keyword': 'QAパフォーマンス', 'Description': 'QAパフォーマンスは、大規模言語モデルの質問応答の能力を指します。大規模言語モデルは質問に対する能力と回答の正確さに自信を持っています。'}]",17.824486017227173
http://arxiv.org/abs/2307.10930v1,MediaGPT : A Large Language Model Target Chinese Media,"The development of large language models (LLMs) has seen rapid progress inrecent years. One of the most widely used LLMs is the Generative Pre-trainedTransformer (GPT) series, which has been applied in various fields, includingthe media domain. However, in practical applications, the differences betweenthe media's use cases and the general-purpose applications of LLMs have becomeincreasingly apparent, especially Chinese. As a result, there is a growing needto develop LLM that are specifically tailored to the unique requirements of themedia domain. In this paper, we present MediaGPT, a large language modeltraining on variety of media data and addressing the practical needs of Chinesemedia. We have designed a diverse set of task instruction types to cater to thespecific requirements of the domain. To further validate the effectiveness ofour proposed LLM, we have constructed unique datasets that are tailored to themedia domain and have also developed verification methods that are specificallydesigned for generative-type tasks. By doing so, we aim to bridge the gapbetween the general-purpose LLM and the requirements of the media domain, andto pave the way for more effective and efficient use of LLM in this field. Thispaper aims to explore the challenges and opportunities of developing LLM formedia applications and to propose potential solutions for addressing thesechallenges.","['Computation and Language', 'Artificial Intelligence']",['Zhonghao Wang'],http://arxiv.org/pdf/2307.10930v1,2023-07-20 14:59:02+00:00,MediaGPT : 中国メディアを対象とした大規模言語モデル,近年、大規模言語モデル（LLM）の開発が急速に進んでいる。最も広く利用されているLLMの1つにGPT(Generative Pre-trainedTransformer)シリーズがあり、メディア領域を含む様々な分野で応用されている。しかし、実用化においては、中国を中心に、メディアのユースケースとLLMの汎用的な応用との違いが顕在化してきている。その結果、メディア領域特有の要件に特化したLLMを開発する必要性が高まっている。本論文では、様々なメディアデータで学習し、中国メディアの実用的なニーズに対応する大規模言語モデルMediaGPTを紹介する。本論文では、中国メディアの実用的なニーズに対応し、様々なメディアデータで学習する大規模言語モデルMediaGPTを紹介する。さらに、提案するLLMの有効性を検証するために、メディア領域に合わせた独自のデータセットを構築し、生成型タスクに特化した検証手法も開発した。これにより、汎用的なLLMとメディア領域の要求とのギャップを埋め、この分野でLLMをより効果的かつ効率的に利用する道を開くことを目指す。本稿の目的は、メディアアプリケーションをLLMで開発する際の課題と機会を探り、これらの課題に対処するための潜在的な解決策を提案することである。,近年、大規模言語モデル（LLM）の開発が進んでいます。特にGPT（Generative Pre-trained Transformer）シリーズは、メディア領域を含むさまざまな分野で広く利用されています。しかし、実際の応用において、中国を中心に、メディアのユースケースとLLMの一般的な応用との違いが明らかになってきました。そのため、メディア領域に特化したLLMの開発が求められています。本論文では、中国のメディアの実用的なニーズに対応するために、さまざまなメディアデータで学習された大規模言語モデルであるMediaGPTを紹介します。さらに、提案されたLLMの有効性を検証するために、メディア領域に特化した独自のデータセットを構築し、生成タスクに特化した検証手法も開発しました。これにより、一般的なLLMとメディア領域の要件とのギャップを埋め、この分野でLLMをより効果的かつ効率的に活用することを目指しています。本論文では、LLMを使用してメディアアプリケーションを開発する際の課題と機会を探り、これらの課題に対処するための潜在的な解決策を提案しています。,"[{'Keyword': '大規模言語モデル', 'Description': '大規模なデータセットを用いて学習された言語モデル。GPTなどが代表的。'}, {'Keyword': 'LLM', 'Description': 'Large Language Modelの略。大規模言語モデルのことを指す。'}, {'Keyword': 'GPT', 'Description': 'Generative Pre-trained Transformerの略。大規模言語モデルの一種で、様々な分野で応用されている。'}, {'Keyword': 'MediaGPT', 'Description': 'メディア領域に特化した大規模言語モデル。中国メディアのニーズに対応するために開発された。'}, {'Keyword': '生成型タスク', 'Description': '与えられた情報から新しい情報を生成するタスク。MediaGPTは生成型タスクに特化している。'}]",11.518815994262695
http://arxiv.org/abs/2307.10928v1,FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets,"Evaluation of Large Language Models (LLMs) is challenging because aligning tohuman values requires the composition of multiple skills and the required setof skills varies depending on the instruction. Recent studies have evaluatedthe performance of LLMs in two ways, (1) automatic evaluation on severalindependent benchmarks and (2) human or machined-based evaluation giving anoverall score to the response. However, both settings are coarse-grainedevaluations, not considering the nature of user instructions that requireinstance-wise skill composition, which limits the interpretation of the truecapabilities of LLMs. In this paper, we introduce FLASK (Fine-grained LanguageModel Evaluation based on Alignment SKill Sets), a fine-grained evaluationprotocol that can be used for both model-based and human-based evaluation whichdecomposes coarse-level scoring to an instance-wise skill set-level.Specifically, we define 12 fine-grained skills needed for LLMs to followopen-ended user instructions and construct an evaluation set by allocating aset of skills for each instance. Additionally, by annotating the target domainsand difficulty level for each instance, FLASK provides a holistic view with acomprehensive analysis of a model's performance depending on skill, domain, anddifficulty. Through using FLASK, we compare multiple open-sourced andproprietary LLMs and observe highly-correlated findings between model-based andhuman-based evaluations. FLASK enables developers to more accurately measurethe model performance and how it can be improved by analyzing factors that makeLLMs proficient in particular skills. For practitioners, FLASK can be used torecommend suitable models for particular situations through comprehensivecomparison among various LLMs. We release the evaluation data and codeimplementation at https://github.com/kaistAI/FLASK.","['Computation and Language', 'Artificial Intelligence']","['Seonghyeon Ye', 'Doyoung Kim', 'Sungdong Kim', 'Hyeonbin Hwang', 'Seungone Kim', 'Yongrae Jo', 'James Thorne', 'Juho Kim', 'Minjoon Seo']",http://arxiv.org/pdf/2307.10928v1,2023-07-20 14:56:35+00:00,FLASK：アライメントスキルセットに基づくきめ細かな言語モデル評価,大規模言語モデル(Large Language Models: LLM)の評価は、人間の価値観に合わせるためには複数のスキルの組み合わせが必要であり、必要なスキルのセットは命令によって異なるため、困難である。最近の研究では、(1)複数の独立したベンチマークによる自動評価と、(2)人間または機械による総合評価という2つの方法でLLMの性能を評価している。しかし、いずれの設定も、インスタンス単位のスキル合成を必要とするユーザ命令の性質を考慮しない粗い評価であり、LLMの真の能力の解釈に限界がある。本論文では、FLASK (Fine-grained LanguageModel Evaluation based on Alignment SKill Sets)を紹介する。FLASKは、モデルベース評価とヒューマンベース評価の両方に利用可能であり、粗いレベルのスコアリングをインスタンス単位のスキルセットレベルに分解する。さらに、各インスタンスに対象ドメインと難易度をアノテーションすることで、FLASKは、スキル、ドメイン、難易度に応じたモデルのパフォーマンスを総合的に分析し、全体的な視点を提供する。FLASKを使用することで、オープンソースとプロプライエタリの複数のLLMを比較し、モデルベースと人間ベースの評価の間に高い相関性があることを確認しました。FLASKにより、開発者は、LLMが特定のスキルに習熟する要因を分析することで、モデルの性能とその改善方法をより正確に測定することができる。実務家にとっては、FLASKは様々なLLMを包括的に比較することで、特定の状況に適したモデルを推奨するために使用することができます。評価データとコード実装は、https://github.com/kaistAI/FLASK。,大規模言語モデル（LLM）の評価は、複数のスキルの組み合わせが必要であり、評価方法も限界があります。本論文では、FLASKという評価手法を提案します。FLASKは、モデルベース評価とヒューマンベース評価の両方を組み合わせ、インスタンス単位のスキルセットレベルで評価します。さらに、各インスタンスに対してドメインと難易度をアノテーションすることで、モデルのパフォーマンスを総合的に分析し、全体的な視点を提供します。FLASKを使用することで、複数のLLMを比較し、モデルベースと人間ベースの評価の相関性を確認しました。FLASKは、モデルの性能と改善方法を正確に測定するために開発者に役立ち、実務家には特定の状況に適したモデルを推奨するために使用できます。,"[{'Keyword': '大規模言語モデル', 'Description': '大量のデータを用いてトレーニングされた言語モデルのこと。'}, {'Keyword': '評価', 'Description': '性能や効果を測定すること。'}, {'Keyword': 'ベンチマーク', 'Description': '性能を評価するための基準や基準データセット。'}, {'Keyword': 'スキル', 'Description': '特定の能力や技術。'}, {'Keyword': 'FLASK', 'Description': 'Fine-grained LanguageModel Evaluation based on Alignment SKill Setsの略で、言語モデルの評価を細かいレベルで行う手法。'}]",8.658150911331177
http://arxiv.org/abs/2307.10778v1,Extreme Multi-Label Skill Extraction Training using Large Language Models,"Online job ads serve as a valuable source of information for skillrequirements, playing a crucial role in labor market analysis and e-recruitmentprocesses. Since such ads are typically formatted in free text, naturallanguage processing (NLP) technologies are required to automatically processthem. We specifically focus on the task of detecting skills (mentionedliterally, or implicitly described) and linking them to a large skill ontology,making it a challenging case of extreme multi-label classification (XMLC).Given that there is no sizable labeled (training) dataset are available forthis specific XMLC task, we propose techniques to leverage general LargeLanguage Models (LLMs). We describe a cost-effective approach to generate anaccurate, fully synthetic labeled dataset for skill extraction, and present acontrastive learning strategy that proves effective in the task. Our resultsacross three skill extraction benchmarks show a consistent increase of between15 to 25 percentage points in \textit{R-Precision@5} compared to previouslypublished results that relied solely on distant supervision through literalmatches.",['Computation and Language'],"['Jens-Joris Decorte', 'Severine Verlinden', 'Jeroen Van Hautte', 'Johannes Deleu', 'Chris Develder', 'Thomas Demeester']",http://arxiv.org/pdf/2307.10778v1,2023-07-20 11:29:15+00:00,大規模言語モデルを用いた極端なマルチラベル・スキル抽出トレーニング,オンライン求人広告は、スキル要件に関する貴重な情報源として機能し、労働市場分析やe-recruitmentprocessにおいて重要な役割を果たしている。このような広告は通常フリーテキストでフォーマットされているため、それらを自動的に処理するためには自然言語処理（NLP）技術が必要である。我々は特に、スキル（文字通り、あるいは暗黙的に記述されたもの）を検出し、それらを大規模なスキルオントロジーにリンクさせるというタスクに焦点を当て、これは極端な多ラベル分類（XMLC）の困難なケースである。スキル抽出のための正確で完全に合成されたラベル付きデータセットを生成するための費用対効果の高いアプローチを説明し、このタスクにおいて効果的であることが証明された対照学習戦略を提示する。3つのスキル抽出ベンチマークの結果は、リテラルマッチによる遠隔監視にのみ頼った既発表の結果と比較して、 \textit{R-Precision@5} において15～25%ポイントの一貫した増加を示している。,オンライン求人広告は、労働市場分析やe-recruitmentprocessにおいて重要な役割を果たしています。しかし、これらの広告はフリーテキストでフォーマットされているため、自然言語処理（NLP）技術が必要です。本論文では、スキルを検出し、大規模なスキルオントロジーにリンクさせるというタスクに焦点を当てています。このタスクは極端な多ラベル分類（XMLC）の困難なケースです。我々は、費用対効果の高いアプローチを提案し、対照学習戦略を使用して正確で完全なラベル付きデータセットを生成する方法を説明します。3つのスキル抽出ベンチマークの結果は、既発表の結果と比較して、一貫した増加を示しています。,"[{'Keyword': 'オンライン求人広告', 'Description': 'インターネット上で公開される求人広告のこと。スキル要件などの情報が含まれており、労働市場分析やe-recruitmentprocessにおいて重要な役割を果たしている。'}, {'Keyword': '自然言語処理（NLP）技術', 'Description': 'コンピュータが自然言語を理解し、処理するための技術。オンライン求人広告などのフリーテキストを自動的に処理するために使用される。'}, {'Keyword': 'スキルオントロジー', 'Description': 'スキルの階層的な体系を表現したもの。スキル要件を検出したり、スキルの関連性を分析する際に使用される。'}, {'Keyword': '多ラベル分類（XMLC）', 'Description': '複数のラベルを持つデータを分類するタスク。オンライン求人広告のスキル要件を正確に抽出するために使用される。'}, {'Keyword': '対照学習戦略', 'Description': '正確で完全に合成されたラベル付きデータセットを生成するための効果的なアプローチ。スキル抽出タスクにおいて有効であることが証明されている。'}]",15.854055881500244
http://arxiv.org/abs/2307.10747v1,Enhancing Job Recommendation through LLM-based Generative Adversarial Networks,"Recommending suitable jobs to users is a critical task in online recruitmentplatforms, as it can enhance users' satisfaction and the platforms'profitability. While existing job recommendation methods encounter challengessuch as the low quality of users' resumes, which hampers their accuracy andpractical effectiveness. With the rapid development of large language models(LLMs), utilizing the rich external knowledge encapsulated within them, as wellas their powerful capabilities of text processing and reasoning, is a promisingway to complete users' resumes for more accurate recommendations. However,directly leveraging LLMs to enhance recommendation results is not aone-size-fits-all solution, as LLMs may suffer from fabricated generation andfew-shot problems, which degrade the quality of resume completion. In thispaper, we propose a novel LLM-based approach for job recommendation. Toalleviate the limitation of fabricated generation for LLMs, we extract accurateand valuable information beyond users' self-description, which helps the LLMsbetter profile users for resume completion. Specifically, we not only extractusers' explicit properties (e.g., skills, interests) from theirself-description but also infer users' implicit characteristics from theirbehaviors for more accurate and meaningful resume completion. Nevertheless,some users still suffer from few-shot problems, which arise due to scarceinteraction records, leading to limited guidance for the models in generatinghigh-quality resumes. To address this issue, we propose aligning unpairedlow-quality with high-quality generated resumes by Generative AdversarialNetworks (GANs), which can refine the resume representations for betterrecommendation results. Extensive experiments on three large real-worldrecruitment datasets demonstrate the effectiveness of our proposed method.",['Information Retrieval'],"['Yingpeng Du', 'Di Luo', 'Rui Yan', 'Hongzhi Liu', 'Yang Song', 'Hengshu Zhu', 'Jie Zhang']",http://arxiv.org/pdf/2307.10747v1,2023-07-20 10:19:47+00:00,LLMベースの生成的逆数ネットワークによる求人推薦の強化,オンライン求人プラットフォームにおいて、ユーザーに適した仕事を推薦することは、ユーザーの満足度とプラットフォームの収益性を向上させることができるため、非常に重要なタスクである。しかし、既存の求人情報推薦手法には、ユーザーの履歴書の質が低いなどの課題があり、その精度と実用的な有効性を妨げている。大規模言語モデル(LLM)の急速な発展に伴い、LLMに内包された豊富な外部知識、およびテキスト処理と推論の強力な能力を活用することは、より正確な推薦のためにユーザーの履歴書を完成させる有望な方法である。しかしながら、推薦結果を向上させるためにLLMを直接活用することは、万能な解決策ではない。LLMは、履歴書補完の質を低下させる、捏造された生成や少数ショットの問題に悩まされる可能性があるからである。本論文では、LLMを用いた新しい推薦手法を提案する。LLMの捏造生成の制限を緩和するために、我々はユーザの自己記述以外の正確で価値のある情報を抽出し、LLMが履歴書補完のためにユーザをより良くプロファイリングすることを支援する。具体的には、利用者の自己記述から利用者の明示的な特性（例：スキル、興味）を抽出するだけでなく、利用者の行動から利用者の暗黙的な特性を推論することで、より正確で有意義な履歴書補完を実現する。とはいえ、一部のユーザはまだ、少ない対話記録から生じる数ショット問題に悩まされており、質の高い履歴書を生成する上でのモデルの指針が限られている。この問題に対処するため、我々はGenerative Adversarial Networks (GAN)を用いて、ペアリングされていない低品質な履歴書と高品質な履歴書を整合させることを提案する。3つの大規模な実世界の採用データセットを用いた広範な実験により、提案手法の有効性を実証する。,オンライン求人プラットフォームでは、ユーザーに適した仕事を推薦することが重要です。しかし、既存の推薦手法では、ユーザーの履歴書の質が低いという問題があります。大規模言語モデル(LLM)を活用することで、ユーザーの履歴書を補完し、より正確な推薦を行うことができます。しかし、LLMを直接活用することには制限があります。本論文では、LLMを用いた新しい推薦手法を提案します。具体的には、ユーザーの自己記述以外の情報を抽出し、LLMが履歴書補完をより良く行えるように支援します。さらに、少ない対話記録から生じる問題に対処するために、Generative Adversarial Networks (GAN)を使用して、低品質な履歴書と高品質な履歴書を整合させます。実験により、提案手法の有効性が実証されました。,"[{'Keyword': 'オンライン求人プラットフォーム', 'Description': 'インターネット上で求人情報を提供し、ユーザーに適した仕事を推薦するプラットフォーム。ユーザーの満足度とプラットフォームの収益性を向上させることが目的。'}, {'Keyword': '求人情報推薦手法', 'Description': 'ユーザーに適した求人情報を推薦するための手法。既存の手法では、ユーザーの履歴書の質が低いなどの課題があり、精度と実用的な有効性が妨げられている。'}, {'Keyword': '大規模言語モデル(LLM)', 'Description': '大規模なテキストデータを学習し、自然言語処理のタスクに利用するモデル。LLMには豊富な外部知識が内包されており、テキスト処理と推論の能力が強力である。'}, {'Keyword': '履歴書補完', 'Description': 'ユーザーの履歴書に不足している情報を補完すること。LLMを活用してユーザーの履歴書を完成させる方法が提案されているが、LLMを直接活用することには課題がある。'}, {'Keyword': 'Generative Adversarial Networks (GAN)', 'Description': '生成モデルと識別モデルを競わせることで、高品質なデータを生成するためのモデル。低品質な履歴書と高品質な履歴書を整合させるために使用される。'}]",19.614741802215576
http://arxiv.org/abs/2307.10719v1,LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?,"Large language models (LLMs) have exhibited impressive capabilities incomprehending complex instructions. However, their blind adherence to providedinstructions has led to concerns regarding risks of malicious use. Existingdefence mechanisms, such as model fine-tuning or output censorship using LLMs,have proven to be fallible, as LLMs can still generate problematic responses.Commonly employed censorship approaches treat the issue as a machine learningproblem and rely on another LM to detect undesirable content in LLM outputs. Inthis paper, we present the theoretical limitations of such semantic censorshipapproaches. Specifically, we demonstrate that semantic censorship can beperceived as an undecidable problem, highlighting the inherent challenges incensorship that arise due to LLMs' programmatic and instruction-followingcapabilities. Furthermore, we argue that the challenges extend beyond semanticcensorship, as knowledgeable attackers can reconstruct impermissible outputsfrom a collection of permissible ones. As a result, we propose that the problemof censorship needs to be reevaluated; it should be treated as a securityproblem which warrants the adaptation of security-based approaches to mitigatepotential risks.","['Artificial Intelligence', 'Cryptography and Security']","['David Glukhov', 'Ilia Shumailov', 'Yarin Gal', 'Nicolas Papernot', 'Vardan Papyan']",http://arxiv.org/pdf/2307.10719v1,2023-07-20 09:25:02+00:00,LLMの検閲：機械学習の課題か、コンピューターセキュリティの問題か？,大規模言語モデル（LLM）は、複雑な命令を理解できない素晴らしい能力を発揮してきた。しかし、与えられた命令に盲目的に従うため、悪意のある使用のリスクが懸念されている。LLMを用いたモデルの微調整や出力検閲などの既存の防御メカニズムは、LLMが依然として問題のある応答を生成する可能性があるため、誤りやすいことが証明されている。一般的に採用されている検閲アプローチは、この問題を機械学習の問題として扱い、LLMの出力に含まれる望ましくないコンテンツを検出するために別のLMに依存する。本稿では、このような意味的検閲アプローチの理論的限界を示す。具体的には、セマンティック検閲が決定不可能な問題として認識される可能性があることを示し、LLMのプログラム能力と命令追従能力によって生じる検閲固有の課題を強調する。さらに、知識ある攻撃者は、許容される出力の集合から許容されない出力を再構成することができるため、課題は意味的検閲にとどまらないと主張する。その結果、我々は検閲の問題を再評価する必要があることを提案する。検閲はセキュリティ問題として扱われるべきであり、潜在的なリスクを軽減するためにセキュリティベースのアプローチを適応することを保証するものである。,大規模言語モデル（LLM）は、複雑な命令を理解できる能力を持っていますが、悪意のある使用のリスクがあります。既存の防御メカニズムは、LLMが誤った応答を生成する可能性があるため、効果が限定的です。本論文では、意味的な検閲アプローチの理論的な限界を示し、セキュリティベースのアプローチを提案します。検閲はセキュリティ問題として扱われるべきであり、リスクを軽減するためにセキュリティベースのアプローチが必要です。,"[{'Keyword': '大規模言語モデル', 'Description': '大規模なデータセットを用いてトレーニングされた言語モデル。複雑な命令を理解する能力があり、様々なタスクに応用される。'}, {'Keyword': '悪意のある使用', 'Description': '意図的な悪意を持って大規模言語モデルを使用すること。個人や組織への攻撃や不正行為に利用される可能性がある。'}, {'Keyword': '微調整', 'Description': '大規模言語モデルのパラメータを調整して、特定のタスクに最適化すること。性能向上や応用範囲の拡大に役立つ。'}, {'Keyword': '出力検閲', 'Description': '大規模言語モデルの生成する出力を監視・検査すること。望ましくないコンテンツや攻撃的な表現を避けるために行われる。'}, {'Keyword': 'セキュリティベースのアプローチ', 'Description': 'セキュリティを最優先に考慮したアプローチ。潜在的なリスクを軽減し、安全性を確保するために使用される。'}]",14.616570234298706
http://arxiv.org/abs/2307.10700v1,Large language models shape and are shaped by society: A survey of arXiv publication patterns,"There has been a steep recent increase in the number of large language model(LLM) papers, producing a dramatic shift in the scientific landscape whichremains largely undocumented through bibliometric analysis. Here, we analyze388K papers posted on the CS and Stat arXivs, focusing on changes inpublication patterns in 2023 vs. 2018-2022. We analyze how the proportion ofLLM papers is increasing; the LLM-related topics receiving the most attention;the authors writing LLM papers; how authors' research topics correlate withtheir backgrounds; the factors distinguishing highly cited LLM papers; and thepatterns of international collaboration. We show that LLM research increasinglyfocuses on societal impacts: there has been an 18x increase in the proportionof LLM-related papers on the Computers and Society sub-arXiv, and authors newlypublishing on LLMs are more likely to focus on applications and societalimpacts than more experienced authors. LLM research is also shaped by socialdynamics: we document gender and academic/industry disparities in the topicsLLM authors focus on, and a US/China schism in the collaboration network.Overall, our analysis documents the profound ways in which LLM research bothshapes and is shaped by society, attesting to the necessity of sociotechnicallenses.","['Digital Libraries', 'Computation and Language', 'Computers and Society']","['Rajiv Movva', 'Sidhika Balachandar', 'Kenny Peng', 'Gabriel Agostini', 'Nikhil Garg', 'Emma Pierson']",http://arxiv.org/pdf/2307.10700v1,2023-07-20 08:45:00+00:00,大きな言語モデルは社会を形成し、社会によって形成される：arXivの出版パターンの調査,最近、大規模言語モデル（LLM）の論文数が急増しており、科学的状況に劇的な変化をもたらしているが、書誌分析ではほとんど記録されていない。ここでは、CSとStatのarXivに投稿された388Kの論文を分析し、2023年と2018-2022年の出版パターンの変化に焦点を当てる。LLM論文の割合がどのように増加しているのか、最も注目されているLLM関連のトピック、LLM論文を執筆している著者、著者の研究トピックと経歴の相関関係、高被引用されたLLM論文を区別する要因、国際共同研究のパターンなどを分析した。また、LLM論文を新たに発表した著者は、経験豊富な著者に比べ、応用や社会的影響に焦点を当てる傾向が強い。全体として、我々の分析は、LLM研究が社会を形成し、また社会によって形成される深遠な方法を記録しており、社会技術者ライセンスの必要性を証明している。,最近、大規模言語モデル（LLM）の論文数が急増しており、科学的状況に劇的な変化をもたらしています。本研究では、CSとStatのarXivに投稿された388Kの論文を分析し、2023年と2018-2022年の出版パターンの変化に焦点を当てました。分析の結果、LLM論文の割合が増加していること、注目されているLLM関連のトピック、LLM論文を執筆している著者、著者の研究トピックと経歴の相関関係、高被引用されたLLM論文を区別する要因、国際共同研究のパターンなどが明らかになりました。また、LLM論文を新たに発表した著者は、経験豊富な著者に比べ、応用や社会的影響に焦点を当てる傾向があることも分かりました。この分析は、LLM研究が社会を形成し、また社会によって形成される深遠な方法を記録しており、社会技術者ライセンスの必要性を証明しています。,"[{'Keyword': '大規模言語モデル', 'Description': '大規模なデータセットを使用してトレーニングされた言語モデル。自然言語処理のタスクで高い性能を発揮する。'}, {'Keyword': '書誌分析', 'Description': '学術論文や研究の文献情報を収集し、分析するプロセス。論文の出版パターンやトレンドを把握するために用いられる。'}, {'Keyword': '注目度', 'Description': '特定のトピックや研究領域がどれだけ注目されているかを示す指標。論文の引用数やダウンロード数などが考慮されることがある。'}, {'Keyword': '相関関係', 'Description': '2つ以上の変数や要素の間に存在する関係。相互の影響や依存関係を分析することで、パターンや傾向を明らかにすることができる。'}, {'Keyword': '社会技術者ライセンス', 'Description': '社会において技術的な問題や倫理的な課題に対処するために必要なスキルや知識を持つことを証明する資格。社会的な影響を考慮した技術の開発や利用が求められる。'}]",17.143802165985107
http://arxiv.org/abs/2307.10690v1,Bridging Intelligence and Instinct: A New Control Paradigm for Autonomous Robots,"As the advent of artificial general intelligence (AGI) progresses at abreathtaking pace, the application of large language models (LLMs) as AI Agentsin robotics remains in its nascent stage. A significant concern that hampersthe seamless integration of these AI Agents into robotics is theunpredictability of the content they generate, a phenomena known as``hallucination''. Drawing inspiration from biological neural systems, wepropose a novel, layered architecture for autonomous robotics, bridging AIagent intelligence and robot instinct. In this context, we define RobotInstinct as the innate or learned set of responses and priorities in anautonomous robotic system that ensures survival-essential tasks, such as safetyassurance and obstacle avoidance, are carried out in a timely and effectivemanner. This paradigm harmoniously combines the intelligence of LLMs with theinstinct of robotic behaviors, contributing to a more safe and versatileautonomous robotic system. As a case study, we illustrate this paradigm withinthe context of a mobile robot, demonstrating its potential to significantlyenhance autonomous robotics and enabling a future where robots can operateindependently and safely across diverse environments.",['Robotics'],['Shimian Zhang'],http://arxiv.org/pdf/2307.10690v1,2023-07-20 08:35:13+00:00,知性と本能の融合：自律型ロボットの新しい制御パラダイム,人工知能(AGI)の出現が驚異的なスピードで進む中、AIエージェントとしての大規模言語モデル(LLM)のロボット工学への応用は、まだ初期段階にとどまっている。これらのAIエージェントのロボット工学へのシームレスな統合を妨げる重大な懸念は、それらが生成するコンテンツの予測不可能性であり、「幻覚」として知られる現象である。我々は、生物学的な神経システムからヒントを得て、AIエージェントの知能とロボットの本能を橋渡しする、自律型ロボティクスのための斬新で階層的なアーキテクチャを提案する。この文脈において、我々はロボット本能を、安全確保や障害物回避といった生存に不可欠なタスクをタイムリーかつ効果的な方法で確実に実行するための、自律型ロボットシステムにおける生得的または学習された一連の反応と優先順位と定義する。このパラダイムは、LLMの知能とロボット行動の本能を調和させ、より安全で多目的な自律ロボットシステムに貢献する。ケーススタディとして、移動ロボットの文脈でこのパラダイムを説明し、自律ロボット工学を大幅に向上させ、ロボットが多様な環境で自立的かつ安全に動作する未来を可能にする可能性を示す。,人工知能（AGI）の進化に伴い、大規模言語モデル（LLM）をAIエージェントとしてロボット工学に統合する取り組みが進んでいます。しかし、これらのAIエージェントが生成するコンテンツの予測不可能性や「幻覚」と呼ばれる現象が、シームレスな統合を妨げる重要な問題です。本論文では、生物学的な神経システムからのヒントを得て、AIエージェントの知能とロボットの本能を結びつけるための階層的なアーキテクチャを提案します。具体的には、ロボットの本能を、生存に不可欠なタスクを効果的かつタイムリーに実行するための一連の反応と優先順位と定義します。このアーキテクチャは、LLMの知能とロボットの本能を調和させ、より安全で多目的な自律ロボットシステムに貢献することが期待されます。移動ロボットをケーススタディとして取り上げ、このアーキテクチャが自律ロボット工学を大幅に向上させ、ロボットが様々な環境で安全かつ自立的に動作する未来を可能にする可能性を示します。,"[{'Keyword': '人工知能', 'Description': '人工知能（AI）は、コンピューターシステムに人間の知能を模倣させる技術です。AIは、学習、推論、問題解決などの能力を持ち、様々なタスクを自動化することができます。'}, {'Keyword': '大規模言語モデル', 'Description': '大規模言語モデル（LLM）は、巨大なデータセットを使用してトレーニングされた言語処理モデルです。LLMは、文章の生成、文章の理解、文章の要約などの自然言語処理タスクにおいて高い性能を発揮します。'}, {'Keyword': 'ロボット工学', 'Description': 'ロボット工学は、ロボットの設計、制御、センシングなどの研究領域です。ロボット工学は、人間の能力を模倣するロボットの開発や、ロボットの動作計画、制御、センシング技術の開発などを目指しています。'}, {'Keyword': '自律型ロボティクス', 'Description': '自律型ロボティクスは、自律的に行動するロボットシステムの研究領域です。自律型ロボティクスは、環境の変化に応じて自己判断し、タスクを実行するロボットの開発を目指しています。'}, {'Keyword': '安全確保', 'Description': '安全確保は、ロボットが自身や周囲の人や物に危害を加えないようにするための対策です。安全確保は、ロボットの制御やセンシング技術の開発、障害物回避のアルゴリズムの実装などによって実現されます。'}]",19.614618062973022
http://arxiv.org/abs/2307.10635v1,SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models,"Recent advances in large language models (LLMs) have demonstrated notableprogress on many mathematical benchmarks. However, most of these benchmarksonly feature problems grounded in junior and senior high school subjects,contain only multiple-choice questions, and are confined to a limited scope ofelementary arithmetic operations. To address these issues, this paperintroduces an expansive benchmark suite SciBench that aims to systematicallyexamine the reasoning capabilities required for complex scientific problemsolving. SciBench contains two carefully curated datasets: an open setfeaturing a range of collegiate-level scientific problems drawn frommathematics, chemistry, and physics textbooks, and a closed set comprisingproblems from undergraduate-level exams in computer science and mathematics.Based on the two datasets, we conduct an in-depth benchmark study of tworepresentative LLMs with various prompting strategies. The results reveal thatcurrent LLMs fall short of delivering satisfactory performance, with an overallscore of merely 35.80%. Furthermore, through a detailed user study, wecategorize the errors made by LLMs into ten problem-solving abilities. Ouranalysis indicates that no single prompting strategy significantly outperformsothers and some strategies that demonstrate improvements in certainproblem-solving skills result in declines in other skills. We envision thatSciBench will catalyze further developments in the reasoning abilities of LLMs,thereby ultimately contributing to scientific research and discovery.","['Computation and Language', 'Artificial Intelligence', 'Machine Learning']","['Xiaoxuan Wang', 'Ziniu Hu', 'Pan Lu', 'Yanqiao Zhu', 'Jieyu Zhang', 'Satyen Subramaniam', 'Arjun R. Loomba', 'Shichang Zhang', 'Yizhou Sun', 'Wei Wang']",http://arxiv.org/pdf/2307.10635v1,2023-07-20 07:01:57+00:00,SciBench：大規模言語モデルの大学レベルの科学的問題解決能力の評価,近年の大規模言語モデル（LLM）の進歩は、多くの数学ベンチマークにおいて顕著な成果を示している。しかし、これらのベンチマークのほとんどは、中学・高校の教科に基づく問題しか扱っておらず、多肢選択問題しか含まれておらず、初等的な算術演算の限られた範囲に限られている。これらの問題に対処するため、本稿では、複雑な科学的問題解決に必要な推論能力を体系的に検証することを目的とした広範なベンチマーク群SciBenchを紹介する。SciBenchには、数学、化学、物理の教科書から抽出された大学レベルの科学問題を集めたオープンセットと、コンピュータサイエンスと数学の学部レベルの試験問題からなるクローズドセットの2つのデータセットが含まれている。2つのデータセットに基づいて、様々なプロンプト戦略を持つ2つの代表的なLLMの詳細なベンチマーク研究を実施した。その結果、現在のLLMは満足のいくパフォーマンスを提供できておらず、総合スコアはわずか35.80%であることが明らかになった。さらに、詳細なユーザー調査を通じて、LLMが犯したエラーを10の問題解決能力に分類した。我々の分析によれば、単一のプロンプト戦略が他の戦略を大きく上回ることはなく、ある問題解決能力において改善を示す戦略でも、他の能力においては低下をもたらすものもある。我々は、SciBenchがLLMの推論能力のさらなる発展を触媒し、最終的に科学的研究と発見に貢献することを想定している。,近年の大規模言語モデル（LLM）の進歩は、数学の問題に関して顕著な成果を示しています。しかし、これらのモデルは主に中学・高校の教科に基づく問題を扱っており、初等的な算術演算に限定されています。そこで、本論文では、複雑な科学的問題解決に必要な推論能力を検証するための広範なベンチマークであるSciBenchを紹介します。SciBenchには、大学レベルの数学、化学、物理の問題を含むオープンセットと、コンピュータサイエンスと数学の学部レベルの試験問題を含むクローズドセットの2つのデータセットがあります。これらのデータセットを使用して、2つの代表的なLLMモデルの詳細なベンチマーク研究を行いました。その結果、現在のLLMは満足のいくパフォーマンスを提供できておらず、総合スコアはわずか35.80%であることがわかりました。さらに、ユーザー調査を通じて、LLMが犯したエラーを10の問題解決能力に分類しました。分析の結果、単一のプロンプト戦略が他の戦略を上回ることはなく、ある能力において改善を示す戦略でも他の能力においては低下をもたらすことがわかりました。SciBenchはLLMの推論能力の発展を促進し、科学的研究と発見に貢献することを期待しています。,"[{'Keyword': '大規模言語モデル', 'Description': '大規模な自然言語処理モデルのことで、多くの数学ベンチマークで高い性能を示している。'}, {'Keyword': 'ベンチマーク', 'Description': '性能評価のために使用される基準やテストのことで、言語モデルの能力を測るために利用される。'}, {'Keyword': '推論能力', 'Description': '与えられた情報から結論を導く能力のことで、複雑な科学的問題解決に必要な能力を指す。'}, {'Keyword': 'プロンプト戦略', 'Description': '言語モデルに対して与える入力の形式や戦略のことで、モデルの応答を制御するために使用される。'}, {'Keyword': 'パフォーマンス', 'Description': 'モデルの性能や能力のことで、正確性や処理速度などが評価される。'}]",12.00292706489563
